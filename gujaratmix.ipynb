{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"gujaratf.csv\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "      <th>Var</th>\n",
       "      <th>KUR</th>\n",
       "      <th>SKEW</th>\n",
       "      <th>Entr</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.900000e+02</td>\n",
       "      <td>9.900000e+02</td>\n",
       "      <td>9.900000e+02</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.301053e+04</td>\n",
       "      <td>4.185282e+06</td>\n",
       "      <td>3.400413e+14</td>\n",
       "      <td>249.748397</td>\n",
       "      <td>413.479864</td>\n",
       "      <td>45.124923</td>\n",
       "      <td>0.648485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.615081e+05</td>\n",
       "      <td>3.200846e+07</td>\n",
       "      <td>4.279302e+15</td>\n",
       "      <td>93.557358</td>\n",
       "      <td>169.564285</td>\n",
       "      <td>21.727197</td>\n",
       "      <td>0.706515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.713131e-02</td>\n",
       "      <td>8.951112e+00</td>\n",
       "      <td>4.006120e+01</td>\n",
       "      <td>56.917872</td>\n",
       "      <td>146.731560</td>\n",
       "      <td>3.583205</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.389027e+00</td>\n",
       "      <td>5.229229e+02</td>\n",
       "      <td>1.384827e+05</td>\n",
       "      <td>170.555956</td>\n",
       "      <td>243.382564</td>\n",
       "      <td>21.669666</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.919035e+01</td>\n",
       "      <td>4.459963e+03</td>\n",
       "      <td>1.405669e+07</td>\n",
       "      <td>256.146109</td>\n",
       "      <td>445.307349</td>\n",
       "      <td>55.360266</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.029551e+03</td>\n",
       "      <td>1.410842e+05</td>\n",
       "      <td>1.190718e+10</td>\n",
       "      <td>312.243231</td>\n",
       "      <td>501.119003</td>\n",
       "      <td>59.240462</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.635434e+06</td>\n",
       "      <td>4.608146e+08</td>\n",
       "      <td>9.650000e+16</td>\n",
       "      <td>700.123181</td>\n",
       "      <td>1008.577053</td>\n",
       "      <td>97.910728</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Mean            SD           Var         KUR         SKEW  \\\n",
       "count  9.900000e+02  9.900000e+02  9.900000e+02  990.000000   990.000000   \n",
       "mean   3.301053e+04  4.185282e+06  3.400413e+14  249.748397   413.479864   \n",
       "std    2.615081e+05  3.200846e+07  4.279302e+15   93.557358   169.564285   \n",
       "min    5.713131e-02  8.951112e+00  4.006120e+01   56.917872   146.731560   \n",
       "25%    3.389027e+00  5.229229e+02  1.384827e+05  170.555956   243.382564   \n",
       "50%    2.919035e+01  4.459963e+03  1.405669e+07  256.146109   445.307349   \n",
       "75%    1.029551e+03  1.410842e+05  1.190718e+10  312.243231   501.119003   \n",
       "max    4.635434e+06  4.608146e+08  9.650000e+16  700.123181  1008.577053   \n",
       "\n",
       "             Entr       Class  \n",
       "count  990.000000  990.000000  \n",
       "mean    45.124923    0.648485  \n",
       "std     21.727197    0.706515  \n",
       "min      3.583205    0.000000  \n",
       "25%     21.669666    0.000000  \n",
       "50%     55.360266    1.000000  \n",
       "75%     59.240462    1.000000  \n",
       "max     97.910728    2.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y=data.pop(\"Class\")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_2d = tsne.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAE/CAYAAABLrsQiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDxX660uEUWS+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a32037c048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_names=[\"0\",\"1\",\"2\"]\n",
    "target_ids = range(len(target_names))\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(6, 5))\n",
    "colors = 'r', 'g', 'b', 'c', 'm', 'y', 'k', 'silver', 'orange', 'purple'\n",
    "for i, c, label in zip(target_ids, colors, target_names):\n",
    "    plt.scatter(X_2d[Y == i, 0], X_2d[Y == i, 1], c=c, label=label)\n",
    "plt.legend( loc='lower left')\n",
    "plt.savefig('t-SNE.fig', format='eps', dpi=1000)\n",
    "plt.savefig('t-SNE.eps', format='eps', dpi=1000)\n",
    "plt.title('t-SNE plot for the data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from numpy import nan\n",
    "\n",
    "now = datetime.datetime.now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import argmax\n",
    "from keras.utils import to_categorical\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, Y, random_state = 42)\n",
    "nb_classes = 10\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742\n",
      "248\n",
      "6 dims\n",
      "Building model...\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[0])\n",
    "print(X_test.shape[0])\n",
    "dims = X_train.shape[1]\n",
    "print(dims, 'dims')\n",
    "print(\"Building model...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_train = X_train.min(axis=0)\n",
    "range_train = (X_train - min_train).max(axis=0)\n",
    "\n",
    "X_train_scaled = (X_train - min_train)/range_train\n",
    "\n",
    "#print('Minimum per feature\\n{}'.format(X_train_scaled.min(axis=0)))\n",
    "#print('Maximum per feature\\n{}'.format(X_train_scaled.max(axis=0)))\n",
    "\n",
    "X_test_scaled = (X_test - min_train)/range_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAE/CAYAAABFK3gIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a320396f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_2d = tsne.fit_transform(X_train_scaled)\n",
    "target_names=[\"0\",\"1\",\"2\"]\n",
    "target_ids = range(len(target_names))\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(6, 5))\n",
    "colors = 'r', 'g', 'b', 'c', 'm', 'y', 'k', 'silver', 'orange', 'purple'\n",
    "for i, c, label in zip(target_ids, colors, target_names):\n",
    "    plt.scatter(X_2d[y_train == i, 0], X_2d[y_train == i, 1], c=c, label=label)\n",
    "plt.legend( loc='lower left')\n",
    "plt.savefig('t-SNE_for_scaled.fig', format='eps', dpi=1000)\n",
    "plt.savefig('t-SNE_for_scaled.eps', format='eps', dpi=1000)\n",
    "plt.title('t-SNE plot for the data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAE/CAYAAABFK3gIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKCMY8ImIMoIBn4goI/4/cgTMiAUjbdIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a320306320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_2d = tsne.fit_transform(X_test_scaled)\n",
    "target_names=[\"0\",\"1\",\"2\"]\n",
    "target_ids = range(len(target_names))\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(6, 5))\n",
    "colors = 'r', 'g', 'b', 'c', 'm', 'y', 'k', 'silver', 'orange', 'purple'\n",
    "for i, c, label in zip(target_ids, colors, target_names):\n",
    "    plt.scatter(X_2d[y_test == i, 0], X_2d[y_test == i, 1], c=c, label=label)\n",
    "plt.legend( loc='lower left')\n",
    "plt.savefig('t-SNE_for_scaled_testdata.fig', format='eps', dpi=1000)\n",
    "plt.savefig('t-SNE_for_scaled_testdata.eps', format='eps', dpi=1000)\n",
    "plt.title('t-SNE plot for the data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 742 samples, validate on 248 samples\n",
      "Epoch 1/3000\n",
      "742/742 [==============================] - 1s 745us/step - loss: 2.1576 - acc: 0.2884 - val_loss: 1.9616 - val_acc: 0.5282\n",
      "Epoch 2/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.7987 - acc: 0.4784 - val_loss: 1.5381 - val_acc: 0.5282\n",
      "Epoch 3/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.4047 - acc: 0.4784 - val_loss: 1.1744 - val_acc: 0.5242\n",
      "Epoch 4/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.1253 - acc: 0.4811 - val_loss: 0.9715 - val_acc: 0.5484\n",
      "Epoch 5/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.9526 - acc: 0.5741 - val_loss: 0.8492 - val_acc: 0.7258\n",
      "Epoch 6/3000\n",
      "742/742 [==============================] - 0s 127us/step - loss: 0.8247 - acc: 0.7844 - val_loss: 0.7391 - val_acc: 0.8750\n",
      "Epoch 7/3000\n",
      "742/742 [==============================] - 0s 128us/step - loss: 0.7024 - acc: 0.8679 - val_loss: 0.6268 - val_acc: 0.8831\n",
      "Epoch 8/3000\n",
      "742/742 [==============================] - 0s 112us/step - loss: 0.5849 - acc: 0.8693 - val_loss: 0.5271 - val_acc: 0.8831\n",
      "Epoch 9/3000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 0.4759 - acc: 0.8706 - val_loss: 0.4291 - val_acc: 0.8831\n",
      "Epoch 10/3000\n",
      "742/742 [==============================] - 0s 85us/step - loss: 0.3820 - acc: 0.8760 - val_loss: 0.3558 - val_acc: 0.8871\n",
      "Epoch 11/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.3105 - acc: 0.9057 - val_loss: 0.3008 - val_acc: 0.9153\n",
      "Epoch 12/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 0.2569 - acc: 0.9245 - val_loss: 0.2584 - val_acc: 0.9355\n",
      "Epoch 13/3000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 0.2144 - acc: 0.9447 - val_loss: 0.2266 - val_acc: 0.9758\n",
      "Epoch 14/3000\n",
      "742/742 [==============================] - 0s 109us/step - loss: 0.1816 - acc: 0.9663 - val_loss: 0.1971 - val_acc: 0.9798\n",
      "Epoch 15/3000\n",
      "742/742 [==============================] - 0s 101us/step - loss: 0.1506 - acc: 0.9852 - val_loss: 0.1733 - val_acc: 0.9839\n",
      "Epoch 16/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 0.1295 - acc: 0.9852 - val_loss: 0.1544 - val_acc: 0.9839\n",
      "Epoch 17/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.1081 - acc: 0.9892 - val_loss: 0.1414 - val_acc: 0.9919\n",
      "Epoch 18/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0904 - acc: 0.9906 - val_loss: 0.1344 - val_acc: 0.9919\n",
      "Epoch 19/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 0.0797 - acc: 0.9933 - val_loss: 0.1211 - val_acc: 0.9919\n",
      "Epoch 20/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0678 - acc: 0.9933 - val_loss: 0.1160 - val_acc: 0.9919\n",
      "Epoch 21/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0596 - acc: 0.9933 - val_loss: 0.1094 - val_acc: 0.9919\n",
      "Epoch 22/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 0.0524 - acc: 0.9946 - val_loss: 0.1057 - val_acc: 0.9919\n",
      "Epoch 23/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 0.0464 - acc: 0.9933 - val_loss: 0.1037 - val_acc: 0.9919\n",
      "Epoch 24/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0416 - acc: 0.9946 - val_loss: 0.1015 - val_acc: 0.9919\n",
      "Epoch 25/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 0.0373 - acc: 0.9960 - val_loss: 0.0990 - val_acc: 0.9919\n",
      "Epoch 26/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0338 - acc: 0.9973 - val_loss: 0.0971 - val_acc: 0.9919\n",
      "Epoch 27/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0304 - acc: 0.9973 - val_loss: 0.0954 - val_acc: 0.9919\n",
      "Epoch 28/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0280 - acc: 0.9973 - val_loss: 0.0929 - val_acc: 0.9919\n",
      "Epoch 29/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0257 - acc: 0.9987 - val_loss: 0.0896 - val_acc: 0.9919\n",
      "Epoch 30/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0230 - acc: 0.9973 - val_loss: 0.0877 - val_acc: 0.9919\n",
      "Epoch 31/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0207 - acc: 0.9987 - val_loss: 0.0859 - val_acc: 0.9919\n",
      "Epoch 32/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.0191 - acc: 0.9987 - val_loss: 0.0848 - val_acc: 0.9919\n",
      "Epoch 33/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0176 - acc: 0.9987 - val_loss: 0.0829 - val_acc: 0.9919\n",
      "Epoch 34/3000\n",
      "742/742 [==============================] - 0s 57us/step - loss: 0.0162 - acc: 0.9987 - val_loss: 0.0818 - val_acc: 0.9919\n",
      "Epoch 35/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 0.0150 - acc: 1.0000 - val_loss: 0.0806 - val_acc: 0.9919\n",
      "Epoch 36/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0142 - acc: 0.9987 - val_loss: 0.0796 - val_acc: 0.9919\n",
      "Epoch 37/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 0.0131 - acc: 1.0000 - val_loss: 0.0785 - val_acc: 0.9919\n",
      "Epoch 38/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.0776 - val_acc: 0.9919\n",
      "Epoch 39/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 0.0769 - val_acc: 0.9919\n",
      "Epoch 40/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.0761 - val_acc: 0.9960\n",
      "Epoch 41/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.0754 - val_acc: 0.9960\n",
      "Epoch 42/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.0748 - val_acc: 0.9960\n",
      "Epoch 43/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.0742 - val_acc: 0.9960\n",
      "Epoch 44/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 0.0737 - val_acc: 0.9960\n",
      "Epoch 45/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0732 - val_acc: 0.9960\n",
      "Epoch 46/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0728 - val_acc: 0.9960\n",
      "Epoch 47/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0724 - val_acc: 0.9960\n",
      "Epoch 48/3000\n",
      "742/742 [==============================] - 0s 61us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0719 - val_acc: 0.9960\n",
      "Epoch 49/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0716 - val_acc: 0.9960\n",
      "Epoch 50/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0713 - val_acc: 0.9960\n",
      "Epoch 51/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0710 - val_acc: 0.9960\n",
      "Epoch 52/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0707 - val_acc: 0.9960\n",
      "Epoch 53/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0705 - val_acc: 0.9960\n",
      "Epoch 54/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0701 - val_acc: 0.9960\n",
      "Epoch 55/3000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0700 - val_acc: 0.9960\n",
      "Epoch 56/3000\n",
      "742/742 [==============================] - 0s 97us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0697 - val_acc: 0.9960\n",
      "Epoch 57/3000\n",
      "742/742 [==============================] - ETA: 0s - loss: 0.0044 - acc: 1.000 - 0s 70us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0695 - val_acc: 0.9960\n",
      "Epoch 58/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0693 - val_acc: 0.9960\n",
      "Epoch 59/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0691 - val_acc: 0.9960\n",
      "Epoch 60/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0689 - val_acc: 0.9960\n",
      "Epoch 61/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0688 - val_acc: 0.9960\n",
      "Epoch 62/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0686 - val_acc: 0.9960\n",
      "Epoch 63/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0685 - val_acc: 0.9960\n",
      "Epoch 64/3000\n",
      "742/742 [==============================] - 0s 128us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0683 - val_acc: 0.9960\n",
      "Epoch 65/3000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0682 - val_acc: 0.9960\n",
      "Epoch 66/3000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0681 - val_acc: 0.9960\n",
      "Epoch 67/3000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0679 - val_acc: 0.9960\n",
      "Epoch 68/3000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0678 - val_acc: 0.9960\n",
      "Epoch 69/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0677 - val_acc: 0.9960\n",
      "Epoch 70/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0676 - val_acc: 0.9960\n",
      "Epoch 71/3000\n",
      "742/742 [==============================] - 0s 59us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0675 - val_acc: 0.9960\n",
      "Epoch 72/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0674 - val_acc: 0.9960\n",
      "Epoch 73/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0673 - val_acc: 0.9960\n",
      "Epoch 74/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0673 - val_acc: 0.9960\n",
      "Epoch 75/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0672 - val_acc: 0.9960\n",
      "Epoch 76/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0671 - val_acc: 0.9960\n",
      "Epoch 77/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0671 - val_acc: 0.9960\n",
      "Epoch 78/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0670 - val_acc: 0.9960\n",
      "Epoch 79/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0669 - val_acc: 0.9960\n",
      "Epoch 80/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0669 - val_acc: 0.9960\n",
      "Epoch 81/3000\n",
      "742/742 [==============================] - 0s 61us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0668 - val_acc: 0.9960\n",
      "Epoch 82/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0667 - val_acc: 0.9960\n",
      "Epoch 83/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0667 - val_acc: 0.9960\n",
      "Epoch 84/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0666 - val_acc: 0.9960\n",
      "Epoch 85/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0666 - val_acc: 0.9960\n",
      "Epoch 86/3000\n",
      "742/742 [==============================] - 0s 58us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0665 - val_acc: 0.9960\n",
      "Epoch 87/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0665 - val_acc: 0.9960\n",
      "Epoch 88/3000\n",
      "742/742 [==============================] - 0s 57us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0664 - val_acc: 0.9960\n",
      "Epoch 89/3000\n",
      "742/742 [==============================] - 0s 61us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0664 - val_acc: 0.9960\n",
      "Epoch 90/3000\n",
      "742/742 [==============================] - 0s 58us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0663 - val_acc: 0.9960\n",
      "Epoch 91/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0663 - val_acc: 0.9960\n",
      "Epoch 92/3000\n",
      "742/742 [==============================] - 0s 59us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0663 - val_acc: 0.9960\n",
      "Epoch 93/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0662 - val_acc: 0.9960\n",
      "Epoch 94/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0662 - val_acc: 0.9960\n",
      "Epoch 95/3000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0662 - val_acc: 0.9960\n",
      "Epoch 96/3000\n",
      "742/742 [==============================] - 0s 113us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0661 - val_acc: 0.9960\n",
      "Epoch 97/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0661 - val_acc: 0.9960\n",
      "Epoch 98/3000\n",
      "742/742 [==============================] - 0s 101us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0661 - val_acc: 0.9960\n",
      "Epoch 99/3000\n",
      "742/742 [==============================] - 0s 106us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0661 - val_acc: 0.9960\n",
      "Epoch 100/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0660 - val_acc: 0.9960\n",
      "Epoch 101/3000\n",
      "742/742 [==============================] - 0s 104us/step - loss: 9.7371e-04 - acc: 1.0000 - val_loss: 0.0660 - val_acc: 0.9960\n",
      "Epoch 102/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 9.4910e-04 - acc: 1.0000 - val_loss: 0.0660 - val_acc: 0.9960\n",
      "Epoch 103/3000\n",
      "742/742 [==============================] - 0s 108us/step - loss: 9.2261e-04 - acc: 1.0000 - val_loss: 0.0659 - val_acc: 0.9960\n",
      "Epoch 104/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 9.0403e-04 - acc: 1.0000 - val_loss: 0.0659 - val_acc: 0.9960\n",
      "Epoch 105/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 8.8641e-04 - acc: 1.0000 - val_loss: 0.0659 - val_acc: 0.9960\n",
      "Epoch 106/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 8.5412e-04 - acc: 1.0000 - val_loss: 0.0659 - val_acc: 0.9960\n",
      "Epoch 107/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 8.3608e-04 - acc: 1.0000 - val_loss: 0.0659 - val_acc: 0.9960\n",
      "Epoch 108/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 8.1853e-04 - acc: 1.0000 - val_loss: 0.0658 - val_acc: 0.9960\n",
      "Epoch 109/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 7.9575e-04 - acc: 1.0000 - val_loss: 0.0658 - val_acc: 0.9960\n",
      "Epoch 110/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 7.8167e-04 - acc: 1.0000 - val_loss: 0.0658 - val_acc: 0.9960\n",
      "Epoch 111/3000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 7.6140e-04 - acc: 1.0000 - val_loss: 0.0658 - val_acc: 0.9960\n",
      "Epoch 112/3000\n",
      "742/742 [==============================] - 0s 100us/step - loss: 7.4084e-04 - acc: 1.0000 - val_loss: 0.0658 - val_acc: 0.9960\n",
      "Epoch 113/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 7.3080e-04 - acc: 1.0000 - val_loss: 0.0657 - val_acc: 0.9960\n",
      "Epoch 114/3000\n",
      "742/742 [==============================] - 0s 98us/step - loss: 7.1319e-04 - acc: 1.0000 - val_loss: 0.0658 - val_acc: 0.9960\n",
      "Epoch 115/3000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 6.9935e-04 - acc: 1.0000 - val_loss: 0.0657 - val_acc: 0.9960\n",
      "Epoch 116/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 6.8666e-04 - acc: 1.0000 - val_loss: 0.0657 - val_acc: 0.9960\n",
      "Epoch 117/3000\n",
      "742/742 [==============================] - 0s 170us/step - loss: 6.5715e-04 - acc: 1.0000 - val_loss: 0.0657 - val_acc: 0.9960\n",
      "Epoch 118/3000\n",
      "742/742 [==============================] - 0s 116us/step - loss: 6.4664e-04 - acc: 1.0000 - val_loss: 0.0657 - val_acc: 0.9960\n",
      "Epoch 119/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 73us/step - loss: 6.3008e-04 - acc: 1.0000 - val_loss: 0.0657 - val_acc: 0.9960\n",
      "Epoch 120/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 6.1121e-04 - acc: 1.0000 - val_loss: 0.0656 - val_acc: 0.9960\n",
      "Epoch 121/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 5.9888e-04 - acc: 1.0000 - val_loss: 0.0656 - val_acc: 0.9960\n",
      "Epoch 122/3000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 5.8903e-04 - acc: 1.0000 - val_loss: 0.0656 - val_acc: 0.9960\n",
      "Epoch 123/3000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 5.7222e-04 - acc: 1.0000 - val_loss: 0.0656 - val_acc: 0.9960\n",
      "Epoch 124/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 5.6474e-04 - acc: 1.0000 - val_loss: 0.0656 - val_acc: 0.9960\n",
      "Epoch 125/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 5.4931e-04 - acc: 1.0000 - val_loss: 0.0656 - val_acc: 0.9960\n",
      "Epoch 126/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 5.4037e-04 - acc: 1.0000 - val_loss: 0.0655 - val_acc: 0.9960\n",
      "Epoch 127/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 5.2476e-04 - acc: 1.0000 - val_loss: 0.0655 - val_acc: 0.9960\n",
      "Epoch 128/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 5.1480e-04 - acc: 1.0000 - val_loss: 0.0655 - val_acc: 0.9960\n",
      "Epoch 129/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 5.0659e-04 - acc: 1.0000 - val_loss: 0.0655 - val_acc: 0.9960\n",
      "Epoch 130/3000\n",
      "742/742 [==============================] - 0s 61us/step - loss: 4.9384e-04 - acc: 1.0000 - val_loss: 0.0655 - val_acc: 0.9960\n",
      "Epoch 131/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 4.8334e-04 - acc: 1.0000 - val_loss: 0.0655 - val_acc: 0.9960\n",
      "Epoch 132/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 4.7257e-04 - acc: 1.0000 - val_loss: 0.0655 - val_acc: 0.9960\n",
      "Epoch 133/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 4.6487e-04 - acc: 1.0000 - val_loss: 0.0655 - val_acc: 0.9960\n",
      "Epoch 134/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 4.5432e-04 - acc: 1.0000 - val_loss: 0.0655 - val_acc: 0.9960\n",
      "Epoch 135/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 4.4691e-04 - acc: 1.0000 - val_loss: 0.0655 - val_acc: 0.9960\n",
      "Epoch 136/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 4.3729e-04 - acc: 1.0000 - val_loss: 0.0654 - val_acc: 0.9960\n",
      "Epoch 137/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 4.2677e-04 - acc: 1.0000 - val_loss: 0.0654 - val_acc: 0.9960\n",
      "Epoch 138/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 4.1926e-04 - acc: 1.0000 - val_loss: 0.0654 - val_acc: 0.9960\n",
      "Epoch 139/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 4.1133e-04 - acc: 1.0000 - val_loss: 0.0654 - val_acc: 0.9960\n",
      "Epoch 140/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 4.0124e-04 - acc: 1.0000 - val_loss: 0.0654 - val_acc: 0.9960\n",
      "Epoch 141/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 3.9531e-04 - acc: 1.0000 - val_loss: 0.0654 - val_acc: 0.9960\n",
      "Epoch 142/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 3.8645e-04 - acc: 1.0000 - val_loss: 0.0654 - val_acc: 0.9960\n",
      "Epoch 143/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 3.8000e-04 - acc: 1.0000 - val_loss: 0.0654 - val_acc: 0.9960\n",
      "Epoch 144/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 3.7427e-04 - acc: 1.0000 - val_loss: 0.0654 - val_acc: 0.9960\n",
      "Epoch 145/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 3.6516e-04 - acc: 1.0000 - val_loss: 0.0654 - val_acc: 0.9960\n",
      "Epoch 146/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 3.5961e-04 - acc: 1.0000 - val_loss: 0.0654 - val_acc: 0.9960\n",
      "Epoch 147/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 3.4949e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 148/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 3.4566e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 149/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 3.3581e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 150/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 3.3213e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 151/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 3.2393e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 152/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 3.1700e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 153/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 3.1221e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 154/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 3.0775e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 155/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 3.0045e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 156/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 2.9671e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 157/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 2.9067e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 158/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 2.8615e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 159/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 2.7854e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 160/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 2.7230e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 161/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 2.6894e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 162/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 2.6281e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 163/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 2.5813e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 164/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 2.5327e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 165/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 2.5214e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 166/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 2.4496e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 167/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 2.4127e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 168/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 2.3637e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 169/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 2.3092e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 170/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 2.2867e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 171/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 2.2397e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 172/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 2.2084e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 173/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 2.1574e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 174/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 2.1224e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 175/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 2.0891e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 176/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 2.0439e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 177/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 2.0089e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 178/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.9854e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 179/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.9393e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 180/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 1.9071e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 181/3000\n",
      "742/742 [==============================] - 0s 98us/step - loss: 1.8741e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 182/3000\n",
      "742/742 [==============================] - 0s 97us/step - loss: 1.8481e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 183/3000\n",
      "742/742 [==============================] - 0s 102us/step - loss: 1.8159e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 184/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.7771e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 185/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.7484e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 186/3000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 1.7190e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 187/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.6958e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 188/3000\n",
      "742/742 [==============================] - 0s 85us/step - loss: 1.6758e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 189/3000\n",
      "742/742 [==============================] - ETA: 0s - loss: 1.5782e-04 - acc: 1.000 - 0s 101us/step - loss: 1.6405e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 190/3000\n",
      "742/742 [==============================] - 0s 100us/step - loss: 1.6056e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 191/3000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 1.5824e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 192/3000\n",
      "742/742 [==============================] - 0s 104us/step - loss: 1.5530e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 193/3000\n",
      "742/742 [==============================] - 0s 98us/step - loss: 1.5250e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 194/3000\n",
      "742/742 [==============================] - 0s 108us/step - loss: 1.5047e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 195/3000\n",
      "742/742 [==============================] - 0s 100us/step - loss: 1.4804e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 196/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.4481e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 197/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.4279e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 198/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.4042e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 199/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.3890e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 200/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.3597e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 201/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.3334e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 202/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.3123e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 203/3000\n",
      "742/742 [==============================] - 0s 108us/step - loss: 1.2913e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 204/3000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 1.2811e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 205/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.2472e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 206/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.2300e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 207/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.2086e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 208/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.2085e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 209/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.1760e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 210/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.1735e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 211/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.1331e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 212/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.1232e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 213/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.0910e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 214/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.0772e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 215/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 1.0622e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 216/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.0413e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 217/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 1.0273e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 218/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.0144e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 219/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 9.9739e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 220/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 9.7820e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 221/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 9.6470e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 222/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 9.4658e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 223/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 9.4135e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 224/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 9.2521e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 225/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 9.0315e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 226/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 8.9279e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 227/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 8.7535e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 228/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 8.6238e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 229/3000\n",
      "742/742 [==============================] - 0s 86us/step - loss: 8.5238e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 230/3000\n",
      "742/742 [==============================] - 0s 105us/step - loss: 8.4163e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 231/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 8.2246e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 232/3000\n",
      "742/742 [==============================] - 0s 101us/step - loss: 8.1232e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 233/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 8.0437e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 234/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 7.9111e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235/3000\n",
      "742/742 [==============================] - 0s 104us/step - loss: 7.7187e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 236/3000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 7.6117e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 237/3000\n",
      "742/742 [==============================] - 0s 128us/step - loss: 7.5040e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 238/3000\n",
      "742/742 [==============================] - 0s 143us/step - loss: 7.3871e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 239/3000\n",
      "742/742 [==============================] - 0s 129us/step - loss: 7.2626e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 240/3000\n",
      "742/742 [==============================] - 0s 105us/step - loss: 7.1675e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 241/3000\n",
      "742/742 [==============================] - 0s 135us/step - loss: 7.0741e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 242/3000\n",
      "742/742 [==============================] - 0s 139us/step - loss: 6.9425e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 243/3000\n",
      "742/742 [==============================] - 0s 128us/step - loss: 6.8250e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 244/3000\n",
      "742/742 [==============================] - 0s 123us/step - loss: 6.7446e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 245/3000\n",
      "742/742 [==============================] - ETA: 0s - loss: 7.8119e-05 - acc: 1.000 - 0s 136us/step - loss: 6.6535e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 246/3000\n",
      "742/742 [==============================] - 0s 140us/step - loss: 6.5027e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 247/3000\n",
      "742/742 [==============================] - 0s 117us/step - loss: 6.4204e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 248/3000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 6.3328e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 249/3000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 6.2236e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 250/3000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 6.1656e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 251/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 6.0249e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 252/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 5.9585e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 253/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 5.8481e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 254/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 5.7988e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 255/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 5.6747e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 256/3000\n",
      "742/742 [==============================] - 0s 128us/step - loss: 5.6099e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 257/3000\n",
      "742/742 [==============================] - 0s 117us/step - loss: 5.5628e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 258/3000\n",
      "742/742 [==============================] - 0s 115us/step - loss: 5.4420e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 259/3000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 5.5604e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 260/3000\n",
      "742/742 [==============================] - 0s 125us/step - loss: 5.4016e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 261/3000\n",
      "742/742 [==============================] - 0s 127us/step - loss: 5.2055e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 262/3000\n",
      "742/742 [==============================] - 0s 120us/step - loss: 5.1747e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 263/3000\n",
      "742/742 [==============================] - 0s 117us/step - loss: 5.0163e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 264/3000\n",
      "742/742 [==============================] - 0s 117us/step - loss: 4.9499e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 265/3000\n",
      "742/742 [==============================] - 0s 100us/step - loss: 4.8573e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 266/3000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 4.7895e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 267/3000\n",
      "742/742 [==============================] - 0s 119us/step - loss: 4.6948e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 268/3000\n",
      "742/742 [==============================] - 0s 115us/step - loss: 4.6369e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 269/3000\n",
      "742/742 [==============================] - 0s 119us/step - loss: 4.5654e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 270/3000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 4.4986e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 271/3000\n",
      "742/742 [==============================] - 0s 108us/step - loss: 4.4235e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 272/3000\n",
      "742/742 [==============================] - 0s 86us/step - loss: 4.3631e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 273/3000\n",
      "742/742 [==============================] - 0s 97us/step - loss: 4.3058e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 274/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 4.2373e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 275/3000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 4.1812e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 276/3000\n",
      "742/742 [==============================] - 0s 127us/step - loss: 4.1248e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 277/3000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 4.0492e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 278/3000\n",
      "742/742 [==============================] - 0s 102us/step - loss: 3.9859e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 279/3000\n",
      "742/742 [==============================] - 0s 98us/step - loss: 3.9536e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 280/3000\n",
      "742/742 [==============================] - 0s 112us/step - loss: 3.8798e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 281/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 3.8172e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 282/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 3.7773e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 283/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 3.7122e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 284/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 3.6918e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 285/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 3.5934e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 286/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 3.5595e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 287/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 3.5675e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 288/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 3.4608e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 289/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 3.3922e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 290/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 3.3667e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 291/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 3.2934e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 292/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 3.2500e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 293/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 3.2208e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 294/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 3.1697e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 295/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 3.1066e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 296/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 3.0628e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 297/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 3.0264e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 298/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 2.9799e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 299/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 2.9198e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 300/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 2.8982e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 301/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 2.8500e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 302/3000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 2.8065e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 303/3000\n",
      "742/742 [==============================] - 0s 119us/step - loss: 2.7596e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 304/3000\n",
      "742/742 [==============================] - 0s 121us/step - loss: 2.7288e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 305/3000\n",
      "742/742 [==============================] - 0s 129us/step - loss: 2.6846e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 306/3000\n",
      "742/742 [==============================] - 0s 148us/step - loss: 2.6602e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 307/3000\n",
      "742/742 [==============================] - 0s 121us/step - loss: 2.6118e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 308/3000\n",
      "742/742 [==============================] - 0s 112us/step - loss: 2.5651e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 309/3000\n",
      "742/742 [==============================] - 0s 100us/step - loss: 2.5271e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 310/3000\n",
      "742/742 [==============================] - 0s 132us/step - loss: 2.4870e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 311/3000\n",
      "742/742 [==============================] - 0s 101us/step - loss: 2.4751e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 312/3000\n",
      "742/742 [==============================] - 0s 124us/step - loss: 2.4212e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 313/3000\n",
      "742/742 [==============================] - 0s 117us/step - loss: 2.3848e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 314/3000\n",
      "742/742 [==============================] - 0s 124us/step - loss: 2.3474e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 315/3000\n",
      "742/742 [==============================] - 0s 121us/step - loss: 2.3139e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 316/3000\n",
      "742/742 [==============================] - 0s 119us/step - loss: 2.2857e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 317/3000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 2.2576e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 318/3000\n",
      "742/742 [==============================] - 0s 123us/step - loss: 2.2157e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 319/3000\n",
      "742/742 [==============================] - 0s 125us/step - loss: 2.1813e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 320/3000\n",
      "742/742 [==============================] - 0s 112us/step - loss: 2.1612e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 321/3000\n",
      "742/742 [==============================] - 0s 119us/step - loss: 2.1188e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 322/3000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 2.1375e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 323/3000\n",
      "742/742 [==============================] - 0s 113us/step - loss: 2.0754e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 324/3000\n",
      "742/742 [==============================] - 0s 116us/step - loss: 2.0224e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 325/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 2.0018e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 326/3000\n",
      "742/742 [==============================] - 0s 106us/step - loss: 1.9698e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 327/3000\n",
      "742/742 [==============================] - 0s 112us/step - loss: 1.9457e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 328/3000\n",
      "742/742 [==============================] - 0s 115us/step - loss: 1.9304e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 329/3000\n",
      "742/742 [==============================] - 0s 117us/step - loss: 1.8864e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 330/3000\n",
      "742/742 [==============================] - 0s 108us/step - loss: 1.8526e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 331/3000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 1.8328e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 332/3000\n",
      "742/742 [==============================] - 0s 109us/step - loss: 1.8215e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 333/3000\n",
      "742/742 [==============================] - 0s 97us/step - loss: 1.7740e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 334/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.7598e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 335/3000\n",
      "742/742 [==============================] - 0s 112us/step - loss: 1.7376e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 336/3000\n",
      "742/742 [==============================] - 0s 109us/step - loss: 1.6982e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 337/3000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.6804e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 338/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.6495e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 339/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 1.6306e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 340/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.6062e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 341/3000\n",
      "742/742 [==============================] - 0s 110us/step - loss: 1.5937e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 342/3000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 1.5621e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 343/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.5365e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 344/3000\n",
      "742/742 [==============================] - 0s 100us/step - loss: 1.5148e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 345/3000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 1.4967e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 346/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.4741e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 347/3000\n",
      "742/742 [==============================] - 0s 100us/step - loss: 1.4552e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 348/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.4314e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 349/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.4154e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350/3000\n",
      "742/742 [==============================] - 0s 109us/step - loss: 1.3965e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 351/3000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 1.3749e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 352/3000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.3551e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 353/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.3333e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 354/3000\n",
      "742/742 [==============================] - 0s 58us/step - loss: 1.3160e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 355/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.3283e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 356/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 1.2708e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 357/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.2567e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 358/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 1.2444e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 359/3000\n",
      "742/742 [==============================] - 0s 59us/step - loss: 1.2249e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 360/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.2146e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 361/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.1895e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 362/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.1718e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 363/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.1590e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 364/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.1478e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 365/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.1217e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 366/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.1071e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 367/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.0965e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 368/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.0845e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 369/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.0603e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 370/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.0542e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 371/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.0358e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 372/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.0191e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 373/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.0026e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 374/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 9.8839e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 375/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 9.7493e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 376/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 9.6278e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 377/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 9.5184e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 378/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 9.3678e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 379/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 9.2525e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 380/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 9.0874e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 381/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 8.9919e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 382/3000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 8.8889e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 383/3000\n",
      "742/742 [==============================] - 0s 102us/step - loss: 8.7521e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 384/3000\n",
      "742/742 [==============================] - 0s 106us/step - loss: 8.5673e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 385/3000\n",
      "742/742 [==============================] - 0s 106us/step - loss: 8.4776e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 386/3000\n",
      "742/742 [==============================] - 0s 98us/step - loss: 8.3710e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 387/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 8.2032e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 388/3000\n",
      "742/742 [==============================] - 0s 112us/step - loss: 8.2697e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 389/3000\n",
      "742/742 [==============================] - 0s 97us/step - loss: 8.0242e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 390/3000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 7.8571e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 391/3000\n",
      "742/742 [==============================] - 0s 123us/step - loss: 7.7412e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 392/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 7.6111e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 393/3000\n",
      "742/742 [==============================] - 0s 97us/step - loss: 7.5216e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 394/3000\n",
      "742/742 [==============================] - 0s 110us/step - loss: 7.4565e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 395/3000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 7.3039e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 396/3000\n",
      "742/742 [==============================] - 0s 108us/step - loss: 7.2633e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 397/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 7.1595e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 398/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 7.0577e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 399/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 6.9030e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 400/3000\n",
      "742/742 [==============================] - 0s 98us/step - loss: 6.8303e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 401/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 6.8320e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 402/3000\n",
      "742/742 [==============================] - 0s 97us/step - loss: 6.6405e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 403/3000\n",
      "742/742 [==============================] - 0s 98us/step - loss: 6.5585e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 404/3000\n",
      "742/742 [==============================] - 0s 100us/step - loss: 6.4602e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 405/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 6.4102e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 406/3000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 6.3023e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 407/3000\n",
      "742/742 [==============================] - 0s 98us/step - loss: 6.2000e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 408/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 78us/step - loss: 6.1574e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 409/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 6.0392e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 410/3000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 5.9719e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 411/3000\n",
      "742/742 [==============================] - 0s 136us/step - loss: 5.8538e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 412/3000\n",
      "742/742 [==============================] - 0s 116us/step - loss: 5.8299e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 413/3000\n",
      "742/742 [==============================] - 0s 141us/step - loss: 5.7044e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 414/3000\n",
      "742/742 [==============================] - 0s 132us/step - loss: 5.6348e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 415/3000\n",
      "742/742 [==============================] - 0s 127us/step - loss: 5.5634e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 416/3000\n",
      "742/742 [==============================] - 0s 115us/step - loss: 5.5065e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 417/3000\n",
      "742/742 [==============================] - 0s 140us/step - loss: 5.4063e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 418/3000\n",
      "742/742 [==============================] - 0s 125us/step - loss: 5.3345e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 419/3000\n",
      "742/742 [==============================] - 0s 147us/step - loss: 5.2552e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 420/3000\n",
      "742/742 [==============================] - 0s 129us/step - loss: 5.2128e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 421/3000\n",
      "742/742 [==============================] - 0s 117us/step - loss: 5.1026e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 422/3000\n",
      "742/742 [==============================] - 0s 143us/step - loss: 5.0441e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 423/3000\n",
      "742/742 [==============================] - 0s 127us/step - loss: 5.0047e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 424/3000\n",
      "742/742 [==============================] - 0s 119us/step - loss: 4.9129e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 425/3000\n",
      "742/742 [==============================] - 0s 123us/step - loss: 4.8535e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 426/3000\n",
      "742/742 [==============================] - 0s 110us/step - loss: 4.8186e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 427/3000\n",
      "742/742 [==============================] - 0s 108us/step - loss: 4.7246e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 428/3000\n",
      "742/742 [==============================] - 0s 125us/step - loss: 4.6552e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 429/3000\n",
      "742/742 [==============================] - 0s 97us/step - loss: 4.6180e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 430/3000\n",
      "742/742 [==============================] - 0s 102us/step - loss: 4.5516e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 431/3000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 4.4738e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 432/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 4.4181e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 433/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 4.3387e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 434/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 4.2770e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 435/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 4.2157e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 436/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 4.1647e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 437/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 4.1198e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 438/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 4.0803e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 439/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 4.0061e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 440/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 3.9567e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 441/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 3.8848e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 442/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 3.8275e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 443/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 3.7839e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 444/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 3.7419e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 445/3000\n",
      "742/742 [==============================] - 0s 109us/step - loss: 3.6852e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 446/3000\n",
      "742/742 [==============================] - 0s 109us/step - loss: 3.6356e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 447/3000\n",
      "742/742 [==============================] - 0s 120us/step - loss: 3.5831e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 448/3000\n",
      "742/742 [==============================] - 0s 97us/step - loss: 3.5303e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 449/3000\n",
      "742/742 [==============================] - 0s 102us/step - loss: 3.5256e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 450/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 3.4664e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 451/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 3.4136e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 452/3000\n",
      "742/742 [==============================] - 0s 123us/step - loss: 3.3696e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 453/3000\n",
      "742/742 [==============================] - 0s 104us/step - loss: 3.3295e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 454/3000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 3.2379e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 455/3000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 3.2466e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 456/3000\n",
      "742/742 [==============================] - 0s 112us/step - loss: 3.1870e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 457/3000\n",
      "742/742 [==============================] - 0s 105us/step - loss: 3.1465e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 458/3000\n",
      "742/742 [==============================] - 0s 102us/step - loss: 3.0822e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 459/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 3.0504e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 460/3000\n",
      "742/742 [==============================] - 0s 98us/step - loss: 3.0042e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 461/3000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 2.9630e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 462/3000\n",
      "742/742 [==============================] - 0s 86us/step - loss: 2.9188e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 463/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 2.8805e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 464/3000\n",
      "742/742 [==============================] - 0s 100us/step - loss: 2.8465e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 465/3000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 2.8111e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 466/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 100us/step - loss: 2.7873e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 467/3000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 2.7273e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 468/3000\n",
      "742/742 [==============================] - 0s 131us/step - loss: 2.6891e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 469/3000\n",
      "742/742 [==============================] - 0s 128us/step - loss: 2.6582e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 470/3000\n",
      "742/742 [==============================] - 0s 110us/step - loss: 2.6660e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 471/3000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 2.5795e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 472/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 2.5833e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 473/3000\n",
      "742/742 [==============================] - 0s 58us/step - loss: 2.5292e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 474/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 2.4856e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 475/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 2.4601e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 476/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 2.4314e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 477/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 2.3850e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 478/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 2.3680e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 479/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 2.3245e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 480/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 2.3023e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 481/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 2.2626e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 482/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 2.2369e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 483/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 2.2138e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 484/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 2.1979e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 485/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 2.1512e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 486/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 2.1419e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 487/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 2.0903e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 488/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 2.0838e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 489/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 2.0486e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 490/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 2.0229e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 491/3000\n",
      "742/742 [==============================] - 0s 61us/step - loss: 2.0083e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 492/3000\n",
      "742/742 [==============================] - 0s 61us/step - loss: 1.9677e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 493/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 1.9373e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 494/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.9062e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 495/3000\n",
      "742/742 [==============================] - 0s 57us/step - loss: 1.8830e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 496/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.8553e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 497/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 1.8368e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 498/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 1.8055e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 499/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.7859e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 500/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 1.7720e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 501/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.7402e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 502/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 1.7155e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 503/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.7294e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 504/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.6765e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 505/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.6462e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 506/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 1.6211e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 507/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.6019e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 508/3000\n",
      "742/742 [==============================] - 0s 61us/step - loss: 1.5828e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 509/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.5490e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 510/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.5339e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 511/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.5192e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 512/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 1.4921e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 513/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.4686e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 514/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 1.4450e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 515/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.4542e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 516/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.4828e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 517/3000\n",
      "742/742 [==============================] - 0s 119us/step - loss: 1.4464e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 518/3000\n",
      "742/742 [==============================] - 0s 105us/step - loss: 1.3921e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 519/3000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.3615e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 520/3000\n",
      "742/742 [==============================] - 0s 100us/step - loss: 1.3315e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 521/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 1.3138e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 522/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 1.3114e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 523/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 1.2918e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 524/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.2624e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 525/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.2504e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 526/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.2357e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 527/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.2191e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 528/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.2044e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 529/3000\n",
      "742/742 [==============================] - 0s 61us/step - loss: 1.2080e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 530/3000\n",
      "742/742 [==============================] - 0s 61us/step - loss: 1.1858e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 531/3000\n",
      "742/742 [==============================] - 0s 61us/step - loss: 1.1616e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 532/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 1.1501e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 533/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.1319e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 534/3000\n",
      "742/742 [==============================] - 0s 57us/step - loss: 1.1186e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 535/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.0956e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 536/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.0957e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 537/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.0770e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 538/3000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 1.0602e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 539/3000\n",
      "742/742 [==============================] - 0s 112us/step - loss: 1.0519e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 540/3000\n",
      "742/742 [==============================] - 0s 132us/step - loss: 1.0434e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 541/3000\n",
      "742/742 [==============================] - 0s 125us/step - loss: 1.0221e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 542/3000\n",
      "742/742 [==============================] - 0s 121us/step - loss: 1.0061e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 543/3000\n",
      "742/742 [==============================] - 0s 113us/step - loss: 1.0031e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 544/3000\n",
      "742/742 [==============================] - 0s 121us/step - loss: 9.8606e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 545/3000\n",
      "742/742 [==============================] - 0s 108us/step - loss: 9.7008e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 546/3000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 9.5369e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 547/3000\n",
      "742/742 [==============================] - 0s 123us/step - loss: 9.4373e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 548/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 9.3489e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 549/3000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 9.2188e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 550/3000\n",
      "742/742 [==============================] - 0s 117us/step - loss: 9.0798e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 551/3000\n",
      "742/742 [==============================] - 0s 113us/step - loss: 9.0316e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 552/3000\n",
      "742/742 [==============================] - 0s 120us/step - loss: 8.8477e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 553/3000\n",
      "742/742 [==============================] - 0s 117us/step - loss: 8.7794e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 554/3000\n",
      "742/742 [==============================] - 0s 121us/step - loss: 8.6693e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 555/3000\n",
      "742/742 [==============================] - 0s 102us/step - loss: 8.5689e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 556/3000\n",
      "742/742 [==============================] - 0s 109us/step - loss: 8.4275e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 557/3000\n",
      "742/742 [==============================] - 0s 110us/step - loss: 8.3624e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 558/3000\n",
      "742/742 [==============================] - 0s 127us/step - loss: 8.2572e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 559/3000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 8.1568e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 560/3000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 8.0435e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 561/3000\n",
      "742/742 [==============================] - 0s 110us/step - loss: 7.9319e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 562/3000\n",
      "742/742 [==============================] - 0s 100us/step - loss: 7.8813e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 563/3000\n",
      "742/742 [==============================] - 0s 102us/step - loss: 7.7648e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 564/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 7.6644e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 565/3000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 7.6137e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 566/3000\n",
      "742/742 [==============================] - 0s 121us/step - loss: 7.4362e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 567/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 7.4394e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 568/3000\n",
      "742/742 [==============================] - 0s 101us/step - loss: 7.4025e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 569/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 7.2000e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 570/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 7.0932e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 571/3000\n",
      "742/742 [==============================] - 0s 104us/step - loss: 7.0675e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 572/3000\n",
      "742/742 [==============================] - 0s 102us/step - loss: 6.9542e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 573/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 6.8948e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 574/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 6.8659e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 575/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 6.6377e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 576/3000\n",
      "742/742 [==============================] - 0s 97us/step - loss: 6.8498e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 577/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 6.5734e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 578/3000\n",
      "742/742 [==============================] - 0s 105us/step - loss: 6.4296e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 579/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 6.3180e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 580/3000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 6.2875e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 581/3000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 6.1525e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 582/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 81us/step - loss: 6.0858e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 583/3000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 6.0401e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 584/3000\n",
      "742/742 [==============================] - 0s 154us/step - loss: 5.9557e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 585/3000\n",
      "742/742 [==============================] - 0s 146us/step - loss: 5.9171e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 586/3000\n",
      "742/742 [==============================] - 0s 132us/step - loss: 5.8400e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 587/3000\n",
      "742/742 [==============================] - 0s 137us/step - loss: 5.7420e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 588/3000\n",
      "742/742 [==============================] - 0s 140us/step - loss: 5.6802e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 589/3000\n",
      "742/742 [==============================] - 0s 141us/step - loss: 5.6055e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 590/3000\n",
      "742/742 [==============================] - 0s 156us/step - loss: 5.5283e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 591/3000\n",
      "742/742 [==============================] - 0s 132us/step - loss: 5.4303e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 592/3000\n",
      "742/742 [==============================] - 0s 120us/step - loss: 5.4825e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 593/3000\n",
      "742/742 [==============================] - 0s 127us/step - loss: 5.3524e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 594/3000\n",
      "742/742 [==============================] - 0s 135us/step - loss: 5.2801e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 595/3000\n",
      "742/742 [==============================] - 0s 112us/step - loss: 5.2142e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 596/3000\n",
      "742/742 [==============================] - 0s 136us/step - loss: 5.2158e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 597/3000\n",
      "742/742 [==============================] - 0s 135us/step - loss: 5.1267e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 598/3000\n",
      "742/742 [==============================] - 0s 113us/step - loss: 5.0592e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 599/3000\n",
      "742/742 [==============================] - 0s 129us/step - loss: 4.9724e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 600/3000\n",
      "742/742 [==============================] - 0s 108us/step - loss: 4.9443e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 601/3000\n",
      "742/742 [==============================] - 0s 124us/step - loss: 4.8945e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 602/3000\n",
      "742/742 [==============================] - 0s 131us/step - loss: 4.8383e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 603/3000\n",
      "742/742 [==============================] - 0s 109us/step - loss: 4.7909e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 604/3000\n",
      "742/742 [==============================] - 0s 129us/step - loss: 4.7307e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 605/3000\n",
      "742/742 [==============================] - 0s 105us/step - loss: 4.6688e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 606/3000\n",
      "742/742 [==============================] - 0s 112us/step - loss: 4.6037e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 607/3000\n",
      "742/742 [==============================] - 0s 113us/step - loss: 4.5772e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 608/3000\n",
      "742/742 [==============================] - 0s 117us/step - loss: 4.5178e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 609/3000\n",
      "742/742 [==============================] - 0s 115us/step - loss: 4.4945e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 610/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 4.4190e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 611/3000\n",
      "742/742 [==============================] - 0s 109us/step - loss: 4.3692e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 612/3000\n",
      "742/742 [==============================] - 0s 85us/step - loss: 4.3210e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 613/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 4.2607e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 614/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 4.2511e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 615/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 4.2021e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 616/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 4.1434e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 617/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 4.0904e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 618/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 4.0727e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 619/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 4.0029e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 620/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 3.9699e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 621/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 3.9402e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 622/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 3.8920e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 623/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 3.8607e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 624/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 3.8085e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 625/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 3.7490e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 626/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 3.7337e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 627/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 3.6791e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 628/3000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 3.6526e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 629/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 3.6133e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 630/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 3.5723e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 631/3000\n",
      "742/742 [==============================] - 0s 106us/step - loss: 3.5377e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 632/3000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 3.5088e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 633/3000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 3.4911e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 634/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 3.4261e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 635/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 3.4012e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 636/3000\n",
      "742/742 [==============================] - 0s 97us/step - loss: 3.3811e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 637/3000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 3.3401e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 638/3000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 3.3152e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 639/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 3.2622e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 640/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 93us/step - loss: 3.2421e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 641/3000\n",
      "742/742 [==============================] - 0s 85us/step - loss: 3.2020e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 642/3000\n",
      "742/742 [==============================] - 0s 152us/step - loss: 3.1939e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 643/3000\n",
      "742/742 [==============================] - 0s 151us/step - loss: 3.1907e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 644/3000\n",
      "742/742 [==============================] - 0s 121us/step - loss: 3.0991e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 645/3000\n",
      "742/742 [==============================] - 0s 123us/step - loss: 3.0919e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 646/3000\n",
      "742/742 [==============================] - 0s 115us/step - loss: 3.0517e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 647/3000\n",
      "742/742 [==============================] - 0s 124us/step - loss: 3.0726e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 648/3000\n",
      "742/742 [==============================] - 0s 98us/step - loss: 3.0116e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 649/3000\n",
      "742/742 [==============================] - 0s 102us/step - loss: 2.9553e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 650/3000\n",
      "742/742 [==============================] - 0s 120us/step - loss: 2.9513e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 651/3000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 2.9272e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 652/3000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 2.9087e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 653/3000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 2.8686e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 654/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 2.8365e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 655/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 2.8172e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 656/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 2.7883e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 657/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 2.7762e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 658/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 2.7521e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 659/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 2.7288e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 660/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 2.7079e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 661/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 2.6822e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 662/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 2.6509e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 663/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 2.6316e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 664/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 2.6204e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 665/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 2.5979e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 666/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 2.5842e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 667/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 2.5465e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 668/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 2.5216e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 669/3000\n",
      "742/742 [==============================] - 0s 100us/step - loss: 2.4975e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 670/3000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 2.5159e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 671/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 2.4959e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 672/3000\n",
      "742/742 [==============================] - 0s 59us/step - loss: 2.4565e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 673/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 2.4517e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 674/3000\n",
      "742/742 [==============================] - 0s 43us/step - loss: 2.4035e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 675/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 2.3858e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 676/3000\n",
      "742/742 [==============================] - 0s 49us/step - loss: 2.3842e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 677/3000\n",
      "742/742 [==============================] - 0s 58us/step - loss: 2.3794e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 678/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 2.3537e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 679/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 2.3231e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 680/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 2.3223e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 681/3000\n",
      "742/742 [==============================] - ETA: 0s - loss: 2.6077e-07 - acc: 1.000 - 0s 65us/step - loss: 2.2974e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 682/3000\n",
      "742/742 [==============================] - 0s 57us/step - loss: 2.3031e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 683/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 2.2757e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 684/3000\n",
      "742/742 [==============================] - 0s 61us/step - loss: 2.2533e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 685/3000\n",
      "742/742 [==============================] - 0s 61us/step - loss: 2.2420e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 686/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 2.2195e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 687/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 2.2083e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 688/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 2.1986e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 689/3000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 2.1866e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 690/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 2.1850e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 691/3000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 2.1496e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 692/3000\n",
      "742/742 [==============================] - 0s 98us/step - loss: 2.1536e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 693/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 2.1400e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 694/3000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 2.1143e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 695/3000\n",
      "742/742 [==============================] - 0s 101us/step - loss: 2.0910e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 696/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 2.0966e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 697/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 2.0765e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 698/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 2.0637e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 699/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 2.0476e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 700/3000\n",
      "742/742 [==============================] - 0s 39us/step - loss: 2.0548e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 701/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 2.0436e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 702/3000\n",
      "742/742 [==============================] - 0s 43us/step - loss: 2.0171e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 703/3000\n",
      "742/742 [==============================] - 0s 42us/step - loss: 1.9994e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 704/3000\n",
      "742/742 [==============================] - 0s 42us/step - loss: 1.9914e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 705/3000\n",
      "742/742 [==============================] - 0s 55us/step - loss: 1.9777e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 706/3000\n",
      "742/742 [==============================] - 0s 53us/step - loss: 1.9617e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 707/3000\n",
      "742/742 [==============================] - 0s 53us/step - loss: 1.9480e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 708/3000\n",
      "742/742 [==============================] - 0s 50us/step - loss: 1.9496e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 709/3000\n",
      "742/742 [==============================] - 0s 42us/step - loss: 1.9376e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 710/3000\n",
      "742/742 [==============================] - 0s 42us/step - loss: 1.9311e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 711/3000\n",
      "742/742 [==============================] - 0s 37us/step - loss: 1.9014e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 712/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 1.8902e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 713/3000\n",
      "742/742 [==============================] - 0s 91us/step - loss: 1.8902e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 714/3000\n",
      "742/742 [==============================] - 0s 105us/step - loss: 1.9127e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 715/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.8837e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 716/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.8637e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 717/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.8564e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 718/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.8484e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 719/3000\n",
      "742/742 [==============================] - 0s 39us/step - loss: 1.8420e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 720/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 1.8444e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 721/3000\n",
      "742/742 [==============================] - 0s 56us/step - loss: 1.8235e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 722/3000\n",
      "742/742 [==============================] - 0s 53us/step - loss: 1.8130e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 723/3000\n",
      "742/742 [==============================] - 0s 53us/step - loss: 1.8187e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 724/3000\n",
      "742/742 [==============================] - 0s 55us/step - loss: 1.8002e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 725/3000\n",
      "742/742 [==============================] - 0s 54us/step - loss: 1.8002e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 726/3000\n",
      "742/742 [==============================] - 0s 51us/step - loss: 1.7833e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 727/3000\n",
      "742/742 [==============================] - 0s 40us/step - loss: 1.7681e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 728/3000\n",
      "742/742 [==============================] - 0s 42us/step - loss: 1.7544e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 729/3000\n",
      "742/742 [==============================] - 0s 42us/step - loss: 1.7512e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 730/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 1.7448e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 731/3000\n",
      "742/742 [==============================] - 0s 42us/step - loss: 1.7424e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 732/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.7383e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 733/3000\n",
      "742/742 [==============================] - 0s 42us/step - loss: 1.7399e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 734/3000\n",
      "742/742 [==============================] - 0s 85us/step - loss: 1.7183e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 735/3000\n",
      "742/742 [==============================] - 0s 61us/step - loss: 1.7215e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 736/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 1.7070e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 737/3000\n",
      "742/742 [==============================] - 0s 61us/step - loss: 1.7046e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 738/3000\n",
      "742/742 [==============================] - 0s 59us/step - loss: 1.7038e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 739/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.7102e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 740/3000\n",
      "742/742 [==============================] - 0s 61us/step - loss: 1.6829e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 741/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.6781e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 742/3000\n",
      "742/742 [==============================] - 0s 60us/step - loss: 1.6701e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 743/3000\n",
      "742/742 [==============================] - 0s 46us/step - loss: 1.6604e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 744/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 1.6556e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 745/3000\n",
      "742/742 [==============================] - 0s 55us/step - loss: 1.6387e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 746/3000\n",
      "742/742 [==============================] - 0s 54us/step - loss: 1.6460e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 747/3000\n",
      "742/742 [==============================] - 0s 54us/step - loss: 1.6387e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 748/3000\n",
      "742/742 [==============================] - 0s 54us/step - loss: 1.6283e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 749/3000\n",
      "742/742 [==============================] - 0s 50us/step - loss: 1.6235e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 750/3000\n",
      "742/742 [==============================] - 0s 42us/step - loss: 1.6146e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 751/3000\n",
      "742/742 [==============================] - 0s 50us/step - loss: 1.6122e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 752/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.6058e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 753/3000\n",
      "742/742 [==============================] - 0s 37us/step - loss: 1.6042e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 754/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.5953e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 755/3000\n",
      "742/742 [==============================] - 0s 55us/step - loss: 1.5897e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 756/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 53us/step - loss: 1.5841e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 757/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.5753e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 758/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.5712e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 759/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 1.5696e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 760/3000\n",
      "742/742 [==============================] - 0s 59us/step - loss: 1.5664e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 761/3000\n",
      "742/742 [==============================] - 0s 61us/step - loss: 1.5560e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 762/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.5488e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 763/3000\n",
      "742/742 [==============================] - 0s 57us/step - loss: 1.5536e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 764/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 1.5383e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 765/3000\n",
      "742/742 [==============================] - 0s 61us/step - loss: 1.5319e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 766/3000\n",
      "742/742 [==============================] - 0s 58us/step - loss: 1.5343e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 767/3000\n",
      "742/742 [==============================] - 0s 37us/step - loss: 1.5247e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 768/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 1.5166e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 769/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 1.5142e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 770/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.5102e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 771/3000\n",
      "742/742 [==============================] - 0s 120us/step - loss: 1.5038e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 772/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.5030e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 773/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.5022e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 774/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 1.4957e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 775/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.4933e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 776/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.4917e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 777/3000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 1.4837e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 778/3000\n",
      "742/742 [==============================] - 0s 97us/step - loss: 1.4789e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 779/3000\n",
      "742/742 [==============================] - 0s 97us/step - loss: 1.4773e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 780/3000\n",
      "742/742 [==============================] - 0s 100us/step - loss: 1.4789e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 781/3000\n",
      "742/742 [==============================] - 0s 85us/step - loss: 1.4652e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 782/3000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 1.4660e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 783/3000\n",
      "742/742 [==============================] - 0s 86us/step - loss: 1.4652e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 784/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.4580e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 785/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 1.4540e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 786/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.4516e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 787/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.4379e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 788/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.4556e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 789/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.4435e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 790/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.4371e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 791/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.4291e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 792/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.4283e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 793/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 1.4259e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 794/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.4234e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 795/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.4210e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 796/3000\n",
      "742/742 [==============================] - 0s 109us/step - loss: 1.4162e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 797/3000\n",
      "742/742 [==============================] - 0s 106us/step - loss: 1.4122e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 798/3000\n",
      "742/742 [==============================] - 0s 112us/step - loss: 1.4138e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 799/3000\n",
      "742/742 [==============================] - 0s 102us/step - loss: 1.4098e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 800/3000\n",
      "742/742 [==============================] - 0s 104us/step - loss: 1.4114e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 801/3000\n",
      "742/742 [==============================] - 0s 115us/step - loss: 1.4098e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 802/3000\n",
      "742/742 [==============================] - 0s 85us/step - loss: 1.4010e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 803/3000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 1.4018e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 804/3000\n",
      "742/742 [==============================] - 0s 106us/step - loss: 1.4010e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 805/3000\n",
      "742/742 [==============================] - 0s 86us/step - loss: 1.3897e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 806/3000\n",
      "742/742 [==============================] - 0s 85us/step - loss: 1.3881e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 807/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 1.3809e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 808/3000\n",
      "742/742 [==============================] - 0s 97us/step - loss: 1.3809e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 809/3000\n",
      "742/742 [==============================] - 0s 97us/step - loss: 1.3793e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 810/3000\n",
      "742/742 [==============================] - 0s 108us/step - loss: 1.3769e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 811/3000\n",
      "742/742 [==============================] - 0s 86us/step - loss: 1.3744e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 812/3000\n",
      "742/742 [==============================] - 0s 97us/step - loss: 1.3696e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 813/3000\n",
      "742/742 [==============================] - 0s 97us/step - loss: 1.3656e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 814/3000\n",
      "742/742 [==============================] - 0s 105us/step - loss: 1.3648e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 815/3000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 1.3680e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 816/3000\n",
      "742/742 [==============================] - 0s 124us/step - loss: 1.3640e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 817/3000\n",
      "742/742 [==============================] - 0s 128us/step - loss: 1.3584e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 818/3000\n",
      "742/742 [==============================] - 0s 131us/step - loss: 1.3560e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 819/3000\n",
      "742/742 [==============================] - 0s 150us/step - loss: 1.3616e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 820/3000\n",
      "742/742 [==============================] - 0s 124us/step - loss: 1.3576e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 821/3000\n",
      "742/742 [==============================] - 0s 128us/step - loss: 1.3503e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 822/3000\n",
      "742/742 [==============================] - 0s 128us/step - loss: 1.3503e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 823/3000\n",
      "742/742 [==============================] - 0s 144us/step - loss: 1.3487e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 824/3000\n",
      "742/742 [==============================] - 0s 135us/step - loss: 1.3415e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 825/3000\n",
      "742/742 [==============================] - 0s 144us/step - loss: 1.3407e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 826/3000\n",
      "742/742 [==============================] - 0s 127us/step - loss: 1.3407e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 827/3000\n",
      "742/742 [==============================] - 0s 125us/step - loss: 1.3391e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 828/3000\n",
      "742/742 [==============================] - 0s 135us/step - loss: 1.3351e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 829/3000\n",
      "742/742 [==============================] - 0s 127us/step - loss: 1.3295e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 830/3000\n",
      "742/742 [==============================] - 0s 124us/step - loss: 1.3295e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 831/3000\n",
      "742/742 [==============================] - 0s 128us/step - loss: 1.3295e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 832/3000\n",
      "742/742 [==============================] - 0s 112us/step - loss: 1.3287e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 833/3000\n",
      "742/742 [==============================] - 0s 136us/step - loss: 1.3262e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 834/3000\n",
      "742/742 [==============================] - 0s 125us/step - loss: 1.3303e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 835/3000\n",
      "742/742 [==============================] - 0s 128us/step - loss: 1.3190e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 836/3000\n",
      "742/742 [==============================] - 0s 137us/step - loss: 1.3206e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 837/3000\n",
      "742/742 [==============================] - 0s 104us/step - loss: 1.3158e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 838/3000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 1.3150e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 839/3000\n",
      "742/742 [==============================] - 0s 98us/step - loss: 1.3158e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 840/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.3094e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 841/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.3086e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 842/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.3094e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 843/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.3070e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 844/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.3029e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 845/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.3038e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 846/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.3021e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 847/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.2989e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 848/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.2965e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 849/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 1.2965e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 850/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.2925e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 851/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.2925e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 852/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.2901e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 853/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.2901e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 854/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 1.2869e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 855/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 1.2845e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 856/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.2845e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 857/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.2861e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 858/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.2813e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 859/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 1.2813e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 860/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.2821e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 861/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.2788e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 862/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 1.2813e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 863/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.2780e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 864/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.2780e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 865/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 1.2772e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 866/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 1.2740e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 867/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.2732e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 868/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.2708e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 869/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.2740e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 870/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.2692e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 871/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.2684e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 872/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 62us/step - loss: 1.2684e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 873/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 1.2692e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 874/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.2644e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 875/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.2644e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 876/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.2636e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 877/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 1.2612e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 878/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 1.2612e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 879/3000\n",
      "742/742 [==============================] - ETA: 0s - loss: 1.1921e-07 - acc: 1.000 - 0s 66us/step - loss: 1.2604e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 880/3000\n",
      "742/742 [==============================] - 0s 58us/step - loss: 1.2580e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 881/3000\n",
      "742/742 [==============================] - 0s 60us/step - loss: 1.2596e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 882/3000\n",
      "742/742 [==============================] - 0s 61us/step - loss: 1.2572e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 883/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.2580e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 884/3000\n",
      "742/742 [==============================] - 0s 59us/step - loss: 1.2564e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 885/3000\n",
      "742/742 [==============================] - 0s 61us/step - loss: 1.2580e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 886/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.2556e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 887/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.2539e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 888/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.2531e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 889/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.2539e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 890/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.2531e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 891/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.2499e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 892/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.2507e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 893/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 1.2531e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 894/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.2483e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 895/3000\n",
      "742/742 [==============================] - 0s 61us/step - loss: 1.2475e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 896/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.2507e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 897/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.2483e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 898/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 1.2451e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 899/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.2467e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 900/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 1.2459e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 901/3000\n",
      "742/742 [==============================] - 0s 59us/step - loss: 1.2435e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 902/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.2435e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 903/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.2427e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 904/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.2427e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 905/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.2451e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 906/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 1.2411e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 907/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.2395e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 908/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 1.2411e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 909/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.2387e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 910/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.2387e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 911/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.2379e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 912/3000\n",
      "742/742 [==============================] - 0s 61us/step - loss: 1.2395e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 913/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.2379e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 914/3000\n",
      "742/742 [==============================] - 0s 59us/step - loss: 1.2379e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 915/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.2355e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 916/3000\n",
      "742/742 [==============================] - 0s 59us/step - loss: 1.2347e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 917/3000\n",
      "742/742 [==============================] - ETA: 0s - loss: 1.1921e-07 - acc: 1.000 - 0s 67us/step - loss: 1.2363e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 918/3000\n",
      "742/742 [==============================] - ETA: 0s - loss: 1.1921e-07 - acc: 1.000 - 0s 62us/step - loss: 1.2347e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 919/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 1.2347e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 920/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.2339e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 921/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 1.2331e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 922/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.2331e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 923/3000\n",
      "742/742 [==============================] - 0s 58us/step - loss: 1.2307e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 924/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 1.2307e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 925/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 1.2298e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 926/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 1.2307e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 927/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 1.2290e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 928/3000\n",
      "742/742 [==============================] - 0s 59us/step - loss: 1.2282e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 929/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.2282e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 930/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.2290e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 931/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.2298e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 932/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 1.2298e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 933/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.2266e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 934/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.2282e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 935/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.2266e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 936/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 1.2266e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 937/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 1.2266e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 938/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.2250e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 939/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.2242e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 940/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 1.2242e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 941/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.2234e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 942/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.2234e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 943/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.2218e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 944/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.2210e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 945/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 1.2202e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 946/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.2210e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 947/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.2242e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 948/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.2210e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 949/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.2194e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 950/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.2186e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 951/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 1.2186e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 952/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 1.2186e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 953/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.2178e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 954/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 1.2186e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 955/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.2170e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 956/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 1.2162e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 957/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.2170e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 958/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.2170e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 959/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.2162e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 960/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 1.2186e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 961/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.2186e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 962/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.2170e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 963/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.2146e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 964/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.2154e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 965/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.2146e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 966/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.2146e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 967/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.2146e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 968/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 1.2146e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 969/3000\n",
      "742/742 [==============================] - 0s 61us/step - loss: 1.2130e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 970/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.2130e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 971/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 1.2130e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 972/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.2130e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 973/3000\n",
      "742/742 [==============================] - 0s 59us/step - loss: 1.2130e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 974/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 1.2122e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 975/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.2122e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 976/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 1.2106e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 977/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.2114e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 978/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 1.2122e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 979/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.2122e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 980/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 1.2114e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 00980: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping  \n",
    "from decimal import ROUND_UP\n",
    "from keras import optimizers\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "rmsp=optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "adagrad=optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
    "adad=optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "adam=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "adamax=optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "nadam=optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "from keras.callbacks import EarlyStopping  \n",
    "from decimal import ROUND_UP\n",
    "max_features = X_train.shape[1]\n",
    "m = Sequential()\n",
    "m.add(Dense(39, input_shape=(dims,)))\n",
    "m.add(Activation('elu'))\n",
    "m.add(Dense(25))\n",
    "m.add(Activation('relu'))\n",
    "m.add(Dense(10))\n",
    "m.add(Activation('softmax'))\n",
    "#m.add(Round())\n",
    "m.compile(loss='categorical_crossentropy', optimizer=adam,metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1, mode='auto')\n",
    "hist1=m.fit(X_train_scaled,\n",
    "          Y_train,\n",
    "          batch_size=32,\n",
    "          epochs=3000, verbose=1,\n",
    "          validation_data=(X_test_scaled, Y_test),\n",
    "          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a321cd1eb8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEKCAYAAAAW8vJGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ns2vE9wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a3203d6208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRJKUFEREJOn/AOCI4PeXyuELAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a321bfeb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(hist1.history['loss'])\n",
    "plt.plot(hist1.history['val_loss'])\n",
    "plt.legend(['Training', 'Validation'], prop={'size': 15})\n",
    "#plt.savefig('loss with adam.fig', format='eps', dpi=1000)\n",
    "#plt.savefig('loss with adam.eps', format='eps', dpi=1000)\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (p.u)')\n",
    "plt.plot(hist1.history['acc'])\n",
    "plt.plot(hist1.history['val_acc'])\n",
    "#plt.savefig('accuracy with adam.fig', format='eps', dpi=1000)\n",
    "#plt.savefig('accuracy with adam.eps', format='eps', dpi=1000)\n",
    "plt.legend(['Training', 'Validation'], loc='lower right', prop={'size': 15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 742 samples, validate on 248 samples\n",
      "Epoch 1/1500\n",
      "742/742 [==============================] - 1s 814us/step - loss: 2.2372 - acc: 0.4367 - val_loss: 2.1824 - val_acc: 0.5242\n",
      "Epoch 2/1500\n",
      "742/742 [==============================] - 0s 84us/step - loss: 2.1345 - acc: 0.4744 - val_loss: 2.0679 - val_acc: 0.5242\n",
      "Epoch 3/1500\n",
      "742/742 [==============================] - 0s 81us/step - loss: 2.0120 - acc: 0.4744 - val_loss: 1.9324 - val_acc: 0.5242\n",
      "Epoch 4/1500\n",
      "742/742 [==============================] - 0s 79us/step - loss: 1.8706 - acc: 0.4744 - val_loss: 1.7810 - val_acc: 0.5242\n",
      "Epoch 5/1500\n",
      "742/742 [==============================] - 0s 79us/step - loss: 1.7189 - acc: 0.4744 - val_loss: 1.6260 - val_acc: 0.5242\n",
      "Epoch 6/1500\n",
      "742/742 [==============================] - 0s 94us/step - loss: 1.5703 - acc: 0.4744 - val_loss: 1.4797 - val_acc: 0.5242\n",
      "Epoch 7/1500\n",
      "742/742 [==============================] - 0s 96us/step - loss: 1.4369 - acc: 0.4744 - val_loss: 1.3535 - val_acc: 0.5242\n",
      "Epoch 8/1500\n",
      "742/742 [==============================] - 0s 84us/step - loss: 1.3266 - acc: 0.4744 - val_loss: 1.2537 - val_acc: 0.5242\n",
      "Epoch 9/1500\n",
      "742/742 [==============================] - 0s 93us/step - loss: 1.2429 - acc: 0.4744 - val_loss: 1.1757 - val_acc: 0.5242\n",
      "Epoch 10/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.1782 - acc: 0.4744 - val_loss: 1.1188 - val_acc: 0.5242\n",
      "Epoch 11/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.1305 - acc: 0.4744 - val_loss: 1.0749 - val_acc: 0.5242\n",
      "Epoch 12/1500\n",
      "742/742 [==============================] - 0s 81us/step - loss: 1.0924 - acc: 0.4744 - val_loss: 1.0396 - val_acc: 0.5242\n",
      "Epoch 13/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.0603 - acc: 0.4744 - val_loss: 1.0086 - val_acc: 0.5242\n",
      "Epoch 14/1500\n",
      "742/742 [==============================] - 0s 85us/step - loss: 1.0304 - acc: 0.4744 - val_loss: 0.9791 - val_acc: 0.5242\n",
      "Epoch 15/1500\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.0007 - acc: 0.4987 - val_loss: 0.9498 - val_acc: 0.5524\n",
      "Epoch 16/1500\n",
      "742/742 [==============================] - 0s 113us/step - loss: 0.9699 - acc: 0.5296 - val_loss: 0.9193 - val_acc: 0.5847\n",
      "Epoch 17/1500\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.9352 - acc: 0.6806 - val_loss: 0.8851 - val_acc: 0.8508\n",
      "Epoch 18/1500\n",
      "742/742 [==============================] - 0s 104us/step - loss: 0.8949 - acc: 0.8437 - val_loss: 0.8447 - val_acc: 0.8548\n",
      "Epoch 19/1500\n",
      "742/742 [==============================] - 0s 82us/step - loss: 0.8504 - acc: 0.8571 - val_loss: 0.8028 - val_acc: 0.8750\n",
      "Epoch 20/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.8038 - acc: 0.8585 - val_loss: 0.7590 - val_acc: 0.8831\n",
      "Epoch 21/1500\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.7516 - acc: 0.8585 - val_loss: 0.7093 - val_acc: 0.8831\n",
      "Epoch 22/1500\n",
      "742/742 [==============================] - 0s 115us/step - loss: 0.6999 - acc: 0.8598 - val_loss: 0.6610 - val_acc: 0.8831\n",
      "Epoch 23/1500\n",
      "742/742 [==============================] - 0s 125us/step - loss: 0.6453 - acc: 0.8598 - val_loss: 0.6131 - val_acc: 0.8831\n",
      "Epoch 24/1500\n",
      "742/742 [==============================] - 0s 108us/step - loss: 0.5925 - acc: 0.8652 - val_loss: 0.5646 - val_acc: 0.8952\n",
      "Epoch 25/1500\n",
      "742/742 [==============================] - 0s 86us/step - loss: 0.5410 - acc: 0.8787 - val_loss: 0.5197 - val_acc: 0.8952\n",
      "Epoch 26/1500\n",
      "742/742 [==============================] - 0s 101us/step - loss: 0.4954 - acc: 0.8814 - val_loss: 0.4787 - val_acc: 0.8992\n",
      "Epoch 27/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.4542 - acc: 0.8922 - val_loss: 0.4423 - val_acc: 0.8992\n",
      "Epoch 28/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.4174 - acc: 0.8935 - val_loss: 0.4101 - val_acc: 0.9032\n",
      "Epoch 29/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 0.3860 - acc: 0.9043 - val_loss: 0.3816 - val_acc: 0.9073\n",
      "Epoch 30/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.3579 - acc: 0.9137 - val_loss: 0.3581 - val_acc: 0.9234\n",
      "Epoch 31/1500\n",
      "742/742 [==============================] - 0s 79us/step - loss: 0.3342 - acc: 0.9218 - val_loss: 0.3381 - val_acc: 0.9234\n",
      "Epoch 32/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.3130 - acc: 0.9299 - val_loss: 0.3183 - val_acc: 0.9234\n",
      "Epoch 33/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.2943 - acc: 0.9245 - val_loss: 0.3012 - val_acc: 0.9234\n",
      "Epoch 34/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.2776 - acc: 0.9380 - val_loss: 0.2883 - val_acc: 0.9355\n",
      "Epoch 35/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.2630 - acc: 0.9407 - val_loss: 0.2743 - val_acc: 0.9355\n",
      "Epoch 36/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 0.2497 - acc: 0.9434 - val_loss: 0.2640 - val_acc: 0.9355\n",
      "Epoch 37/1500\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.2376 - acc: 0.9461 - val_loss: 0.2530 - val_acc: 0.9355\n",
      "Epoch 38/1500\n",
      "742/742 [==============================] - 0s 113us/step - loss: 0.2264 - acc: 0.9474 - val_loss: 0.2446 - val_acc: 0.9435\n",
      "Epoch 39/1500\n",
      "742/742 [==============================] - 0s 85us/step - loss: 0.2166 - acc: 0.9515 - val_loss: 0.2340 - val_acc: 0.9355\n",
      "Epoch 40/1500\n",
      "742/742 [==============================] - 0s 120us/step - loss: 0.2073 - acc: 0.9501 - val_loss: 0.2265 - val_acc: 0.9476\n",
      "Epoch 41/1500\n",
      "742/742 [==============================] - 0s 108us/step - loss: 0.1986 - acc: 0.9528 - val_loss: 0.2195 - val_acc: 0.9556\n",
      "Epoch 42/1500\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.1916 - acc: 0.9555 - val_loss: 0.2126 - val_acc: 0.9597\n",
      "Epoch 43/1500\n",
      "742/742 [==============================] - 0s 105us/step - loss: 0.1848 - acc: 0.9515 - val_loss: 0.2070 - val_acc: 0.9597\n",
      "Epoch 44/1500\n",
      "742/742 [==============================] - 0s 106us/step - loss: 0.1769 - acc: 0.9569 - val_loss: 0.2025 - val_acc: 0.9597\n",
      "Epoch 45/1500\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.1711 - acc: 0.9569 - val_loss: 0.1964 - val_acc: 0.9597\n",
      "Epoch 46/1500\n",
      "742/742 [==============================] - 0s 98us/step - loss: 0.1652 - acc: 0.9636 - val_loss: 0.1919 - val_acc: 0.9597\n",
      "Epoch 47/1500\n",
      "742/742 [==============================] - 0s 96us/step - loss: 0.1601 - acc: 0.9650 - val_loss: 0.1867 - val_acc: 0.9597\n",
      "Epoch 48/1500\n",
      "742/742 [==============================] - 0s 109us/step - loss: 0.1550 - acc: 0.9650 - val_loss: 0.1833 - val_acc: 0.9597\n",
      "Epoch 49/1500\n",
      "742/742 [==============================] - 0s 79us/step - loss: 0.1498 - acc: 0.9677 - val_loss: 0.1793 - val_acc: 0.9597\n",
      "Epoch 50/1500\n",
      "742/742 [==============================] - 0s 101us/step - loss: 0.1456 - acc: 0.9677 - val_loss: 0.1759 - val_acc: 0.9597\n",
      "Epoch 51/1500\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.1423 - acc: 0.9677 - val_loss: 0.1724 - val_acc: 0.9597\n",
      "Epoch 52/1500\n",
      "742/742 [==============================] - 0s 102us/step - loss: 0.1377 - acc: 0.9663 - val_loss: 0.1702 - val_acc: 0.9597\n",
      "Epoch 53/1500\n",
      "742/742 [==============================] - 0s 84us/step - loss: 0.1337 - acc: 0.9663 - val_loss: 0.1669 - val_acc: 0.9597\n",
      "Epoch 54/1500\n",
      "742/742 [==============================] - 0s 117us/step - loss: 0.1301 - acc: 0.9663 - val_loss: 0.1648 - val_acc: 0.9637\n",
      "Epoch 55/1500\n",
      "742/742 [==============================] - 0s 104us/step - loss: 0.1275 - acc: 0.9704 - val_loss: 0.1617 - val_acc: 0.9637\n",
      "Epoch 56/1500\n",
      "742/742 [==============================] - 0s 84us/step - loss: 0.1238 - acc: 0.9663 - val_loss: 0.1592 - val_acc: 0.9637\n",
      "Epoch 57/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.1208 - acc: 0.9663 - val_loss: 0.1569 - val_acc: 0.9637\n",
      "Epoch 58/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.1179 - acc: 0.9677 - val_loss: 0.1551 - val_acc: 0.9637\n",
      "Epoch 59/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.1156 - acc: 0.9663 - val_loss: 0.1532 - val_acc: 0.9637\n",
      "Epoch 60/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.1123 - acc: 0.9717 - val_loss: 0.1512 - val_acc: 0.9637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.1100 - acc: 0.9704 - val_loss: 0.1491 - val_acc: 0.9637\n",
      "Epoch 62/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.1074 - acc: 0.9704 - val_loss: 0.1469 - val_acc: 0.9637\n",
      "Epoch 63/1500\n",
      "742/742 [==============================] - 0s 115us/step - loss: 0.1053 - acc: 0.9717 - val_loss: 0.1460 - val_acc: 0.9637\n",
      "Epoch 64/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 0.1039 - acc: 0.9757 - val_loss: 0.1454 - val_acc: 0.9677\n",
      "Epoch 65/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.1009 - acc: 0.9717 - val_loss: 0.1423 - val_acc: 0.9637\n",
      "Epoch 66/1500\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.0991 - acc: 0.9730 - val_loss: 0.1413 - val_acc: 0.9677\n",
      "Epoch 67/1500\n",
      "742/742 [==============================] - 0s 81us/step - loss: 0.0970 - acc: 0.9717 - val_loss: 0.1402 - val_acc: 0.9677\n",
      "Epoch 68/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0949 - acc: 0.9744 - val_loss: 0.1388 - val_acc: 0.9677\n",
      "Epoch 69/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0933 - acc: 0.9757 - val_loss: 0.1379 - val_acc: 0.9718\n",
      "Epoch 70/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0920 - acc: 0.9825 - val_loss: 0.1365 - val_acc: 0.9758\n",
      "Epoch 71/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0897 - acc: 0.9744 - val_loss: 0.1351 - val_acc: 0.9718\n",
      "Epoch 72/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.0880 - acc: 0.9757 - val_loss: 0.1344 - val_acc: 0.9758\n",
      "Epoch 73/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0867 - acc: 0.9811 - val_loss: 0.1331 - val_acc: 0.9758\n",
      "Epoch 74/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0857 - acc: 0.9825 - val_loss: 0.1327 - val_acc: 0.9758\n",
      "Epoch 75/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0844 - acc: 0.9784 - val_loss: 0.1318 - val_acc: 0.9758\n",
      "Epoch 76/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0817 - acc: 0.9825 - val_loss: 0.1306 - val_acc: 0.9758\n",
      "Epoch 77/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0805 - acc: 0.9825 - val_loss: 0.1304 - val_acc: 0.9758\n",
      "Epoch 78/1500\n",
      "742/742 [==============================] - 0s 79us/step - loss: 0.0790 - acc: 0.9825 - val_loss: 0.1304 - val_acc: 0.9839\n",
      "Epoch 79/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0778 - acc: 0.9825 - val_loss: 0.1296 - val_acc: 0.9839\n",
      "Epoch 80/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 0.0765 - acc: 0.9825 - val_loss: 0.1282 - val_acc: 0.9758\n",
      "Epoch 81/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0751 - acc: 0.9838 - val_loss: 0.1281 - val_acc: 0.9839\n",
      "Epoch 82/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0740 - acc: 0.9825 - val_loss: 0.1271 - val_acc: 0.9798\n",
      "Epoch 83/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 0.0728 - acc: 0.9838 - val_loss: 0.1279 - val_acc: 0.9839\n",
      "Epoch 84/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0712 - acc: 0.9838 - val_loss: 0.1253 - val_acc: 0.9839\n",
      "Epoch 85/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0703 - acc: 0.9825 - val_loss: 0.1251 - val_acc: 0.9839\n",
      "Epoch 86/1500\n",
      "742/742 [==============================] - 0s 80us/step - loss: 0.0692 - acc: 0.9852 - val_loss: 0.1246 - val_acc: 0.9839\n",
      "Epoch 87/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0680 - acc: 0.9838 - val_loss: 0.1245 - val_acc: 0.9839\n",
      "Epoch 88/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 0.0670 - acc: 0.9838 - val_loss: 0.1242 - val_acc: 0.9839\n",
      "Epoch 89/1500\n",
      "742/742 [==============================] - 0s 106us/step - loss: 0.0660 - acc: 0.9865 - val_loss: 0.1257 - val_acc: 0.9879\n",
      "Epoch 90/1500\n",
      "742/742 [==============================] - 0s 97us/step - loss: 0.0651 - acc: 0.9865 - val_loss: 0.1233 - val_acc: 0.9839\n",
      "Epoch 91/1500\n",
      "742/742 [==============================] - 0s 102us/step - loss: 0.0647 - acc: 0.9838 - val_loss: 0.1236 - val_acc: 0.9879\n",
      "Epoch 92/1500\n",
      "742/742 [==============================] - 0s 106us/step - loss: 0.0633 - acc: 0.9865 - val_loss: 0.1227 - val_acc: 0.9839\n",
      "Epoch 93/1500\n",
      "742/742 [==============================] - 0s 98us/step - loss: 0.0633 - acc: 0.9838 - val_loss: 0.1220 - val_acc: 0.9839\n",
      "Epoch 94/1500\n",
      "742/742 [==============================] - 0s 109us/step - loss: 0.0615 - acc: 0.9865 - val_loss: 0.1217 - val_acc: 0.9879\n",
      "Epoch 95/1500\n",
      "742/742 [==============================] - 0s 106us/step - loss: 0.0602 - acc: 0.9865 - val_loss: 0.1202 - val_acc: 0.9839\n",
      "Epoch 96/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.0599 - acc: 0.9865 - val_loss: 0.1201 - val_acc: 0.9879\n",
      "Epoch 97/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0592 - acc: 0.9865 - val_loss: 0.1191 - val_acc: 0.9879\n",
      "Epoch 98/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0577 - acc: 0.9865 - val_loss: 0.1178 - val_acc: 0.9879\n",
      "Epoch 99/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0570 - acc: 0.9865 - val_loss: 0.1171 - val_acc: 0.9879\n",
      "Epoch 100/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 0.0561 - acc: 0.9892 - val_loss: 0.1173 - val_acc: 0.9879\n",
      "Epoch 101/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0553 - acc: 0.9879 - val_loss: 0.1159 - val_acc: 0.9879\n",
      "Epoch 102/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0544 - acc: 0.9892 - val_loss: 0.1155 - val_acc: 0.9879\n",
      "Epoch 103/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0538 - acc: 0.9892 - val_loss: 0.1144 - val_acc: 0.9879\n",
      "Epoch 104/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 0.0534 - acc: 0.9879 - val_loss: 0.1138 - val_acc: 0.9879\n",
      "Epoch 105/1500\n",
      "742/742 [==============================] - 0s 86us/step - loss: 0.0527 - acc: 0.9892 - val_loss: 0.1134 - val_acc: 0.9879\n",
      "Epoch 106/1500\n",
      "742/742 [==============================] - 0s 101us/step - loss: 0.0517 - acc: 0.9892 - val_loss: 0.1130 - val_acc: 0.9879\n",
      "Epoch 107/1500\n",
      "742/742 [==============================] - 0s 102us/step - loss: 0.0511 - acc: 0.9892 - val_loss: 0.1122 - val_acc: 0.9879\n",
      "Epoch 108/1500\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.0508 - acc: 0.9892 - val_loss: 0.1127 - val_acc: 0.9879\n",
      "Epoch 109/1500\n",
      "742/742 [==============================] - 0s 110us/step - loss: 0.0495 - acc: 0.9892 - val_loss: 0.1105 - val_acc: 0.9879\n",
      "Epoch 110/1500\n",
      "742/742 [==============================] - 0s 85us/step - loss: 0.0491 - acc: 0.9892 - val_loss: 0.1099 - val_acc: 0.9879\n",
      "Epoch 111/1500\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.0492 - acc: 0.9906 - val_loss: 0.1091 - val_acc: 0.9879\n",
      "Epoch 112/1500\n",
      "742/742 [==============================] - 0s 98us/step - loss: 0.0484 - acc: 0.9892 - val_loss: 0.1102 - val_acc: 0.9879\n",
      "Epoch 113/1500\n",
      "742/742 [==============================] - 0s 108us/step - loss: 0.0474 - acc: 0.9892 - val_loss: 0.1081 - val_acc: 0.9879\n",
      "Epoch 114/1500\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.0466 - acc: 0.9892 - val_loss: 0.1083 - val_acc: 0.9879\n",
      "Epoch 115/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0462 - acc: 0.9892 - val_loss: 0.1078 - val_acc: 0.9879\n",
      "Epoch 116/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 0.0456 - acc: 0.9892 - val_loss: 0.1071 - val_acc: 0.9879\n",
      "Epoch 117/1500\n",
      "742/742 [==============================] - 0s 66us/step - loss: 0.0450 - acc: 0.9892 - val_loss: 0.1069 - val_acc: 0.9879\n",
      "Epoch 118/1500\n",
      "742/742 [==============================] - 0s 34us/step - loss: 0.0446 - acc: 0.9906 - val_loss: 0.1060 - val_acc: 0.9879\n",
      "Epoch 119/1500\n",
      "742/742 [==============================] - 0s 58us/step - loss: 0.0441 - acc: 0.9892 - val_loss: 0.1057 - val_acc: 0.9879\n",
      "Epoch 120/1500\n",
      "742/742 [==============================] - 0s 59us/step - loss: 0.0438 - acc: 0.9892 - val_loss: 0.1057 - val_acc: 0.9879\n",
      "Epoch 121/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 61us/step - loss: 0.0433 - acc: 0.9919 - val_loss: 0.1042 - val_acc: 0.9919\n",
      "Epoch 122/1500\n",
      "742/742 [==============================] - 0s 59us/step - loss: 0.0428 - acc: 0.9919 - val_loss: 0.1044 - val_acc: 0.9879\n",
      "Epoch 123/1500\n",
      "742/742 [==============================] - 0s 58us/step - loss: 0.0418 - acc: 0.9906 - val_loss: 0.1037 - val_acc: 0.9919\n",
      "Epoch 124/1500\n",
      "742/742 [==============================] - 0s 60us/step - loss: 0.0416 - acc: 0.9906 - val_loss: 0.1035 - val_acc: 0.9919\n",
      "Epoch 125/1500\n",
      "742/742 [==============================] - 0s 55us/step - loss: 0.0409 - acc: 0.9906 - val_loss: 0.1033 - val_acc: 0.9879\n",
      "Epoch 126/1500\n",
      "742/742 [==============================] - 0s 37us/step - loss: 0.0405 - acc: 0.9906 - val_loss: 0.1027 - val_acc: 0.9919\n",
      "Epoch 127/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0401 - acc: 0.9919 - val_loss: 0.1027 - val_acc: 0.9879\n",
      "Epoch 128/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 0.0397 - acc: 0.9906 - val_loss: 0.1022 - val_acc: 0.9919\n",
      "Epoch 129/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0393 - acc: 0.9919 - val_loss: 0.1018 - val_acc: 0.9919\n",
      "Epoch 130/1500\n",
      "742/742 [==============================] - 0s 60us/step - loss: 0.0389 - acc: 0.9919 - val_loss: 0.1018 - val_acc: 0.9919\n",
      "Epoch 131/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 0.0384 - acc: 0.9919 - val_loss: 0.1011 - val_acc: 0.9919\n",
      "Epoch 132/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0379 - acc: 0.9919 - val_loss: 0.1012 - val_acc: 0.9919\n",
      "Epoch 133/1500\n",
      "742/742 [==============================] - 0s 84us/step - loss: 0.0375 - acc: 0.9919 - val_loss: 0.1009 - val_acc: 0.9919\n",
      "Epoch 134/1500\n",
      "742/742 [==============================] - 0s 66us/step - loss: 0.0374 - acc: 0.9919 - val_loss: 0.1005 - val_acc: 0.9919\n",
      "Epoch 135/1500\n",
      "742/742 [==============================] - 0s 65us/step - loss: 0.0369 - acc: 0.9919 - val_loss: 0.1008 - val_acc: 0.9879\n",
      "Epoch 136/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0363 - acc: 0.9919 - val_loss: 0.0997 - val_acc: 0.9919\n",
      "Epoch 137/1500\n",
      "742/742 [==============================] - 0s 38us/step - loss: 0.0360 - acc: 0.9919 - val_loss: 0.0996 - val_acc: 0.9919\n",
      "Epoch 138/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0356 - acc: 0.9933 - val_loss: 0.0996 - val_acc: 0.9919\n",
      "Epoch 139/1500\n",
      "742/742 [==============================] - 0s 47us/step - loss: 0.0354 - acc: 0.9919 - val_loss: 0.0995 - val_acc: 0.9919\n",
      "Epoch 140/1500\n",
      "742/742 [==============================] - 0s 54us/step - loss: 0.0351 - acc: 0.9933 - val_loss: 0.0987 - val_acc: 0.9919\n",
      "Epoch 141/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 0.0350 - acc: 0.9919 - val_loss: 0.0990 - val_acc: 0.9919\n",
      "Epoch 142/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0345 - acc: 0.9933 - val_loss: 0.0982 - val_acc: 0.9919\n",
      "Epoch 143/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0348 - acc: 0.9906 - val_loss: 0.1006 - val_acc: 0.9879\n",
      "Epoch 144/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 0.0336 - acc: 0.9933 - val_loss: 0.0980 - val_acc: 0.9919\n",
      "Epoch 145/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0330 - acc: 0.9933 - val_loss: 0.0972 - val_acc: 0.9919\n",
      "Epoch 146/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 0.0327 - acc: 0.9933 - val_loss: 0.0972 - val_acc: 0.9919\n",
      "Epoch 147/1500\n",
      "742/742 [==============================] - 0s 37us/step - loss: 0.0322 - acc: 0.9933 - val_loss: 0.0973 - val_acc: 0.9919\n",
      "Epoch 148/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0327 - acc: 0.9919 - val_loss: 0.0976 - val_acc: 0.9919\n",
      "Epoch 149/1500\n",
      "742/742 [==============================] - 0s 46us/step - loss: 0.0317 - acc: 0.9933 - val_loss: 0.0969 - val_acc: 0.9919\n",
      "Epoch 150/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0314 - acc: 0.9933 - val_loss: 0.0960 - val_acc: 0.9919\n",
      "Epoch 151/1500\n",
      "742/742 [==============================] - 0s 59us/step - loss: 0.0310 - acc: 0.9933 - val_loss: 0.0962 - val_acc: 0.9919\n",
      "Epoch 152/1500\n",
      "742/742 [==============================] - 0s 58us/step - loss: 0.0305 - acc: 0.9933 - val_loss: 0.0967 - val_acc: 0.9919\n",
      "Epoch 153/1500\n",
      "742/742 [==============================] - 0s 58us/step - loss: 0.0316 - acc: 0.9906 - val_loss: 0.0983 - val_acc: 0.9919\n",
      "Epoch 154/1500\n",
      "742/742 [==============================] - 0s 59us/step - loss: 0.0295 - acc: 0.9946 - val_loss: 0.0961 - val_acc: 0.9919\n",
      "Epoch 155/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0294 - acc: 0.9933 - val_loss: 0.0956 - val_acc: 0.9919\n",
      "Epoch 156/1500\n",
      "742/742 [==============================] - 0s 48us/step - loss: 0.0289 - acc: 0.9933 - val_loss: 0.0959 - val_acc: 0.9919\n",
      "Epoch 157/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 0.0285 - acc: 0.9933 - val_loss: 0.0958 - val_acc: 0.9919\n",
      "Epoch 158/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 0.0281 - acc: 0.9933 - val_loss: 0.0954 - val_acc: 0.9919\n",
      "Epoch 159/1500\n",
      "742/742 [==============================] - 0s 64us/step - loss: 0.0276 - acc: 0.9933 - val_loss: 0.0954 - val_acc: 0.9919\n",
      "Epoch 160/1500\n",
      "742/742 [==============================] - 0s 60us/step - loss: 0.0280 - acc: 0.9933 - val_loss: 0.0947 - val_acc: 0.9919\n",
      "Epoch 161/1500\n",
      "742/742 [==============================] - 0s 54us/step - loss: 0.0270 - acc: 0.9933 - val_loss: 0.0952 - val_acc: 0.9919\n",
      "Epoch 162/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 0.0264 - acc: 0.9946 - val_loss: 0.0956 - val_acc: 0.9919\n",
      "Epoch 163/1500\n",
      "742/742 [==============================] - 0s 113us/step - loss: 0.0259 - acc: 0.9946 - val_loss: 0.0951 - val_acc: 0.9919\n",
      "Epoch 164/1500\n",
      "742/742 [==============================] - 0s 109us/step - loss: 0.0255 - acc: 0.9946 - val_loss: 0.0949 - val_acc: 0.9919\n",
      "Epoch 165/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0249 - acc: 0.9946 - val_loss: 0.0956 - val_acc: 0.9919\n",
      "Epoch 166/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0246 - acc: 0.9946 - val_loss: 0.0946 - val_acc: 0.9919\n",
      "Epoch 167/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0240 - acc: 0.9946 - val_loss: 0.0949 - val_acc: 0.9919\n",
      "Epoch 168/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0232 - acc: 0.9946 - val_loss: 0.0943 - val_acc: 0.9919\n",
      "Epoch 169/1500\n",
      "742/742 [==============================] - 0s 81us/step - loss: 0.0229 - acc: 0.9946 - val_loss: 0.0940 - val_acc: 0.9919\n",
      "Epoch 170/1500\n",
      "742/742 [==============================] - 0s 108us/step - loss: 0.0231 - acc: 0.9946 - val_loss: 0.0950 - val_acc: 0.9919\n",
      "Epoch 171/1500\n",
      "742/742 [==============================] - 0s 106us/step - loss: 0.0220 - acc: 0.9946 - val_loss: 0.0937 - val_acc: 0.9919\n",
      "Epoch 172/1500\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.0212 - acc: 0.9946 - val_loss: 0.0930 - val_acc: 0.9919\n",
      "Epoch 173/1500\n",
      "742/742 [==============================] - 0s 100us/step - loss: 0.0215 - acc: 0.9946 - val_loss: 0.0930 - val_acc: 0.9919\n",
      "Epoch 174/1500\n",
      "742/742 [==============================] - 0s 81us/step - loss: 0.0203 - acc: 0.9946 - val_loss: 0.0925 - val_acc: 0.9919\n",
      "Epoch 175/1500\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.0199 - acc: 0.9946 - val_loss: 0.0925 - val_acc: 0.9919\n",
      "Epoch 176/1500\n",
      "742/742 [==============================] - 0s 85us/step - loss: 0.0200 - acc: 0.9973 - val_loss: 0.0930 - val_acc: 0.9919\n",
      "Epoch 177/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.0188 - acc: 0.9960 - val_loss: 0.0915 - val_acc: 0.9919\n",
      "Epoch 178/1500\n",
      "742/742 [==============================] - 0s 100us/step - loss: 0.0188 - acc: 0.9960 - val_loss: 0.0911 - val_acc: 0.9919\n",
      "Epoch 179/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0181 - acc: 0.9960 - val_loss: 0.0909 - val_acc: 0.9919\n",
      "Epoch 180/1500\n",
      "742/742 [==============================] - 0s 97us/step - loss: 0.0177 - acc: 0.9960 - val_loss: 0.0906 - val_acc: 0.9919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.0173 - acc: 0.9960 - val_loss: 0.0900 - val_acc: 0.9919\n",
      "Epoch 182/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 0.0169 - acc: 0.9960 - val_loss: 0.0897 - val_acc: 0.9919\n",
      "Epoch 183/1500\n",
      "742/742 [==============================] - 0s 81us/step - loss: 0.0164 - acc: 0.9973 - val_loss: 0.0893 - val_acc: 0.9919\n",
      "Epoch 184/1500\n",
      "742/742 [==============================] - 0s 115us/step - loss: 0.0162 - acc: 0.9973 - val_loss: 0.0889 - val_acc: 0.9919\n",
      "Epoch 185/1500\n",
      "742/742 [==============================] - 0s 98us/step - loss: 0.0158 - acc: 0.9973 - val_loss: 0.0884 - val_acc: 0.9919\n",
      "Epoch 186/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0154 - acc: 0.9973 - val_loss: 0.0880 - val_acc: 0.9919\n",
      "Epoch 187/1500\n",
      "742/742 [==============================] - 0s 82us/step - loss: 0.0150 - acc: 0.9973 - val_loss: 0.0877 - val_acc: 0.9919\n",
      "Epoch 188/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.0146 - acc: 0.9973 - val_loss: 0.0872 - val_acc: 0.9919\n",
      "Epoch 189/1500\n",
      "742/742 [==============================] - 0s 65us/step - loss: 0.0143 - acc: 0.9973 - val_loss: 0.0868 - val_acc: 0.9919\n",
      "Epoch 190/1500\n",
      "742/742 [==============================] - 0s 57us/step - loss: 0.0139 - acc: 0.9973 - val_loss: 0.0864 - val_acc: 0.9919\n",
      "Epoch 191/1500\n",
      "742/742 [==============================] - 0s 43us/step - loss: 0.0139 - acc: 0.9973 - val_loss: 0.0860 - val_acc: 0.9919\n",
      "Epoch 192/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0134 - acc: 0.9973 - val_loss: 0.0857 - val_acc: 0.9919\n",
      "Epoch 193/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0130 - acc: 0.9973 - val_loss: 0.0853 - val_acc: 0.9919\n",
      "Epoch 194/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0129 - acc: 0.9973 - val_loss: 0.0850 - val_acc: 0.9919\n",
      "Epoch 195/1500\n",
      "742/742 [==============================] - 0s 79us/step - loss: 0.0124 - acc: 0.9973 - val_loss: 0.0848 - val_acc: 0.9919\n",
      "Epoch 196/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0120 - acc: 0.9973 - val_loss: 0.0843 - val_acc: 0.9919\n",
      "Epoch 197/1500\n",
      "742/742 [==============================] - 0s 85us/step - loss: 0.0116 - acc: 0.9973 - val_loss: 0.0839 - val_acc: 0.9919\n",
      "Epoch 198/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0114 - acc: 0.9973 - val_loss: 0.0835 - val_acc: 0.9919\n",
      "Epoch 199/1500\n",
      "742/742 [==============================] - 0s 48us/step - loss: 0.0111 - acc: 0.9973 - val_loss: 0.0831 - val_acc: 0.9919\n",
      "Epoch 200/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0109 - acc: 0.9973 - val_loss: 0.0828 - val_acc: 0.9919\n",
      "Epoch 201/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 0.0106 - acc: 0.9973 - val_loss: 0.0824 - val_acc: 0.9919\n",
      "Epoch 202/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0105 - acc: 0.9973 - val_loss: 0.0820 - val_acc: 0.9919\n",
      "Epoch 203/1500\n",
      "742/742 [==============================] - 0s 65us/step - loss: 0.0099 - acc: 0.9973 - val_loss: 0.0817 - val_acc: 0.9919\n",
      "Epoch 204/1500\n",
      "742/742 [==============================] - 0s 66us/step - loss: 0.0096 - acc: 0.9973 - val_loss: 0.0814 - val_acc: 0.9919\n",
      "Epoch 205/1500\n",
      "742/742 [==============================] - 0s 65us/step - loss: 0.0094 - acc: 0.9973 - val_loss: 0.0811 - val_acc: 0.9919\n",
      "Epoch 206/1500\n",
      "742/742 [==============================] - 0s 65us/step - loss: 0.0092 - acc: 0.9973 - val_loss: 0.0807 - val_acc: 0.9919\n",
      "Epoch 207/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 0.0089 - acc: 0.9973 - val_loss: 0.0804 - val_acc: 0.9919\n",
      "Epoch 208/1500\n",
      "742/742 [==============================] - 0s 40us/step - loss: 0.0088 - acc: 0.9973 - val_loss: 0.0800 - val_acc: 0.9919\n",
      "Epoch 209/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0082 - acc: 0.9973 - val_loss: 0.0798 - val_acc: 0.9919\n",
      "Epoch 210/1500\n",
      "742/742 [==============================] - 0s 40us/step - loss: 0.0082 - acc: 0.9973 - val_loss: 0.0794 - val_acc: 0.9919\n",
      "Epoch 211/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0079 - acc: 0.9973 - val_loss: 0.0792 - val_acc: 0.9919\n",
      "Epoch 212/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 0.0077 - acc: 0.9973 - val_loss: 0.0789 - val_acc: 0.9919\n",
      "Epoch 213/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0075 - acc: 0.9973 - val_loss: 0.0785 - val_acc: 0.9919\n",
      "Epoch 214/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 0.0077 - acc: 0.9987 - val_loss: 0.0781 - val_acc: 0.9919\n",
      "Epoch 215/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0069 - acc: 0.9987 - val_loss: 0.0775 - val_acc: 0.9919\n",
      "Epoch 216/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 0.0067 - acc: 0.9973 - val_loss: 0.0774 - val_acc: 0.9919\n",
      "Epoch 217/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0065 - acc: 0.9973 - val_loss: 0.0771 - val_acc: 0.9919\n",
      "Epoch 218/1500\n",
      "742/742 [==============================] - 0s 56us/step - loss: 0.0063 - acc: 0.9973 - val_loss: 0.0768 - val_acc: 0.9919\n",
      "Epoch 219/1500\n",
      "742/742 [==============================] - 0s 64us/step - loss: 0.0062 - acc: 0.9987 - val_loss: 0.0766 - val_acc: 0.9919\n",
      "Epoch 220/1500\n",
      "742/742 [==============================] - 0s 33us/step - loss: 0.0060 - acc: 0.9987 - val_loss: 0.0763 - val_acc: 0.9919\n",
      "Epoch 221/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 0.0058 - acc: 0.9987 - val_loss: 0.0762 - val_acc: 0.9919\n",
      "Epoch 222/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0057 - acc: 0.9987 - val_loss: 0.0759 - val_acc: 0.9919\n",
      "Epoch 223/1500\n",
      "742/742 [==============================] - 0s 39us/step - loss: 0.0056 - acc: 0.9987 - val_loss: 0.0756 - val_acc: 0.9919\n",
      "Epoch 224/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0054 - acc: 0.9987 - val_loss: 0.0756 - val_acc: 0.9919\n",
      "Epoch 225/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 0.0053 - acc: 0.9987 - val_loss: 0.0751 - val_acc: 0.9919\n",
      "Epoch 226/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0051 - acc: 0.9987 - val_loss: 0.0749 - val_acc: 0.9919\n",
      "Epoch 227/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 0.0050 - acc: 0.9987 - val_loss: 0.0747 - val_acc: 0.9919\n",
      "Epoch 228/1500\n",
      "742/742 [==============================] - 0s 54us/step - loss: 0.0049 - acc: 0.9987 - val_loss: 0.0746 - val_acc: 0.9919\n",
      "Epoch 229/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 0.0048 - acc: 0.9987 - val_loss: 0.0743 - val_acc: 0.9919\n",
      "Epoch 230/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 0.0046 - acc: 0.9987 - val_loss: 0.0742 - val_acc: 0.9919\n",
      "Epoch 231/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0045 - acc: 0.9987 - val_loss: 0.0740 - val_acc: 0.9919\n",
      "Epoch 232/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 0.0045 - acc: 0.9987 - val_loss: 0.0739 - val_acc: 0.9919\n",
      "Epoch 233/1500\n",
      "742/742 [==============================] - 0s 53us/step - loss: 0.0043 - acc: 0.9987 - val_loss: 0.0734 - val_acc: 0.9919\n",
      "Epoch 234/1500\n",
      "742/742 [==============================] - 0s 81us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0733 - val_acc: 0.9919\n",
      "Epoch 235/1500\n",
      "742/742 [==============================] - 0s 49us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0732 - val_acc: 0.9919\n",
      "Epoch 236/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 0.0040 - acc: 0.9987 - val_loss: 0.0733 - val_acc: 0.9919\n",
      "Epoch 237/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0728 - val_acc: 0.9919\n",
      "Epoch 238/1500\n",
      "742/742 [==============================] - 0s 51us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0726 - val_acc: 0.9919\n",
      "Epoch 239/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0726 - val_acc: 0.9919\n",
      "Epoch 240/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0722 - val_acc: 0.9919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0721 - val_acc: 0.9919\n",
      "Epoch 242/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0721 - val_acc: 0.9919\n",
      "Epoch 243/1500\n",
      "742/742 [==============================] - 0s 47us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0718 - val_acc: 0.9919\n",
      "Epoch 244/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0719 - val_acc: 0.9919\n",
      "Epoch 245/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0717 - val_acc: 0.9919\n",
      "Epoch 246/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0714 - val_acc: 0.9919\n",
      "Epoch 247/1500\n",
      "742/742 [==============================] - 0s 56us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0713 - val_acc: 0.9919\n",
      "Epoch 248/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0711 - val_acc: 0.9919\n",
      "Epoch 249/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0706 - val_acc: 0.9919\n",
      "Epoch 250/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0707 - val_acc: 0.9919\n",
      "Epoch 251/1500\n",
      "742/742 [==============================] - 0s 91us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0706 - val_acc: 0.9919\n",
      "Epoch 252/1500\n",
      "742/742 [==============================] - 0s 48us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0705 - val_acc: 0.9919\n",
      "Epoch 253/1500\n",
      "742/742 [==============================] - 0s 46us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0706 - val_acc: 0.9919\n",
      "Epoch 254/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0703 - val_acc: 0.9919\n",
      "Epoch 255/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0701 - val_acc: 0.9919\n",
      "Epoch 256/1500\n",
      "742/742 [==============================] - 0s 49us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0700 - val_acc: 0.9919\n",
      "Epoch 257/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0699 - val_acc: 0.9919\n",
      "Epoch 258/1500\n",
      "742/742 [==============================] - 0s 52us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0698 - val_acc: 0.9919\n",
      "Epoch 259/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0697 - val_acc: 0.9919\n",
      "Epoch 260/1500\n",
      "742/742 [==============================] - 0s 41us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0697 - val_acc: 0.9919\n",
      "Epoch 261/1500\n",
      "742/742 [==============================] - 0s 64us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0696 - val_acc: 0.9919\n",
      "Epoch 262/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0695 - val_acc: 0.9919\n",
      "Epoch 263/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0695 - val_acc: 0.9919\n",
      "Epoch 264/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0688 - val_acc: 0.9960\n",
      "Epoch 265/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0689 - val_acc: 0.9960\n",
      "Epoch 266/1500\n",
      "742/742 [==============================] - 0s 59us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0689 - val_acc: 0.9960\n",
      "Epoch 267/1500\n",
      "742/742 [==============================] - 0s 58us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0690 - val_acc: 0.9960\n",
      "Epoch 268/1500\n",
      "742/742 [==============================] - 0s 98us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0689 - val_acc: 0.9960\n",
      "Epoch 269/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0687 - val_acc: 0.9960\n",
      "Epoch 270/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0685 - val_acc: 0.9960\n",
      "Epoch 271/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0685 - val_acc: 0.9960\n",
      "Epoch 272/1500\n",
      "742/742 [==============================] - 0s 65us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0685 - val_acc: 0.9960\n",
      "Epoch 273/1500\n",
      "742/742 [==============================] - 0s 65us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0685 - val_acc: 0.9960\n",
      "Epoch 274/1500\n",
      "742/742 [==============================] - 0s 66us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0683 - val_acc: 0.9960\n",
      "Epoch 275/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0684 - val_acc: 0.9960\n",
      "Epoch 276/1500\n",
      "742/742 [==============================] - 0s 61us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0682 - val_acc: 0.9960\n",
      "Epoch 277/1500\n",
      "742/742 [==============================] - 0s 46us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0683 - val_acc: 0.9960\n",
      "Epoch 278/1500\n",
      "742/742 [==============================] - 0s 106us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0681 - val_acc: 0.9960\n",
      "Epoch 279/1500\n",
      "742/742 [==============================] - 0s 104us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0681 - val_acc: 0.9960\n",
      "Epoch 280/1500\n",
      "742/742 [==============================] - 0s 66us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0679 - val_acc: 0.9960\n",
      "Epoch 281/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0679 - val_acc: 0.9960\n",
      "Epoch 282/1500\n",
      "742/742 [==============================] - 0s 66us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0678 - val_acc: 0.9960\n",
      "Epoch 283/1500\n",
      "742/742 [==============================] - 0s 85us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0678 - val_acc: 0.9960\n",
      "Epoch 284/1500\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0678 - val_acc: 0.9960\n",
      "Epoch 285/1500\n",
      "742/742 [==============================] - 0s 102us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0676 - val_acc: 0.9960\n",
      "Epoch 286/1500\n",
      "742/742 [==============================] - 0s 98us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0676 - val_acc: 0.9960\n",
      "Epoch 287/1500\n",
      "742/742 [==============================] - 0s 97us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0676 - val_acc: 0.9960\n",
      "Epoch 288/1500\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0675 - val_acc: 0.9960\n",
      "Epoch 289/1500\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0675 - val_acc: 0.9960\n",
      "Epoch 290/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0674 - val_acc: 0.9960\n",
      "Epoch 291/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0674 - val_acc: 0.9960\n",
      "Epoch 292/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0674 - val_acc: 0.9960\n",
      "Epoch 293/1500\n",
      "742/742 [==============================] - 0s 79us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0672 - val_acc: 0.9960\n",
      "Epoch 294/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0672 - val_acc: 0.9960\n",
      "Epoch 295/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0673 - val_acc: 0.9960\n",
      "Epoch 296/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0672 - val_acc: 0.9960\n",
      "Epoch 297/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0671 - val_acc: 0.9960\n",
      "Epoch 298/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0671 - val_acc: 0.9960\n",
      "Epoch 299/1500\n",
      "742/742 [==============================] - 0s 81us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0670 - val_acc: 0.9960\n",
      "Epoch 300/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0670 - val_acc: 0.9960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 9.8825e-04 - acc: 1.0000 - val_loss: 0.0670 - val_acc: 0.9960\n",
      "Epoch 302/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 9.7297e-04 - acc: 1.0000 - val_loss: 0.0669 - val_acc: 0.9960\n",
      "Epoch 303/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 9.4993e-04 - acc: 1.0000 - val_loss: 0.0669 - val_acc: 0.9960\n",
      "Epoch 304/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 9.3756e-04 - acc: 1.0000 - val_loss: 0.0668 - val_acc: 0.9960\n",
      "Epoch 305/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 9.1725e-04 - acc: 1.0000 - val_loss: 0.0668 - val_acc: 0.9960\n",
      "Epoch 306/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 9.0370e-04 - acc: 1.0000 - val_loss: 0.0668 - val_acc: 0.9960\n",
      "Epoch 307/1500\n",
      "742/742 [==============================] - 0s 79us/step - loss: 8.8813e-04 - acc: 1.0000 - val_loss: 0.0667 - val_acc: 0.9960\n",
      "Epoch 308/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 8.7592e-04 - acc: 1.0000 - val_loss: 0.0667 - val_acc: 0.9960\n",
      "Epoch 309/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 8.6005e-04 - acc: 1.0000 - val_loss: 0.0667 - val_acc: 0.9960\n",
      "Epoch 310/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 8.4548e-04 - acc: 1.0000 - val_loss: 0.0667 - val_acc: 0.9960\n",
      "Epoch 311/1500\n",
      "742/742 [==============================] - 0s 79us/step - loss: 8.2996e-04 - acc: 1.0000 - val_loss: 0.0666 - val_acc: 0.9960\n",
      "Epoch 312/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 8.3031e-04 - acc: 1.0000 - val_loss: 0.0666 - val_acc: 0.9960\n",
      "Epoch 313/1500\n",
      "742/742 [==============================] - 0s 65us/step - loss: 8.0092e-04 - acc: 1.0000 - val_loss: 0.0665 - val_acc: 0.9960\n",
      "Epoch 314/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 7.8502e-04 - acc: 1.0000 - val_loss: 0.0665 - val_acc: 0.9960\n",
      "Epoch 315/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 7.7571e-04 - acc: 1.0000 - val_loss: 0.0665 - val_acc: 0.9960\n",
      "Epoch 316/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 7.6370e-04 - acc: 1.0000 - val_loss: 0.0664 - val_acc: 0.9960\n",
      "Epoch 317/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 7.4609e-04 - acc: 1.0000 - val_loss: 0.0664 - val_acc: 0.9960\n",
      "Epoch 318/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 7.3224e-04 - acc: 1.0000 - val_loss: 0.0664 - val_acc: 0.9960\n",
      "Epoch 319/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 7.2371e-04 - acc: 1.0000 - val_loss: 0.0664 - val_acc: 0.9960\n",
      "Epoch 320/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 7.1269e-04 - acc: 1.0000 - val_loss: 0.0664 - val_acc: 0.9960\n",
      "Epoch 321/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 6.9783e-04 - acc: 1.0000 - val_loss: 0.0663 - val_acc: 0.9960\n",
      "Epoch 322/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 6.8724e-04 - acc: 1.0000 - val_loss: 0.0663 - val_acc: 0.9960\n",
      "Epoch 323/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 6.7349e-04 - acc: 1.0000 - val_loss: 0.0663 - val_acc: 0.9960\n",
      "Epoch 324/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 6.6479e-04 - acc: 1.0000 - val_loss: 0.0662 - val_acc: 0.9960\n",
      "Epoch 325/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 6.5657e-04 - acc: 1.0000 - val_loss: 0.0663 - val_acc: 0.9960\n",
      "Epoch 326/1500\n",
      "742/742 [==============================] - 0s 65us/step - loss: 6.4508e-04 - acc: 1.0000 - val_loss: 0.0662 - val_acc: 0.9960\n",
      "Epoch 327/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 6.3255e-04 - acc: 1.0000 - val_loss: 0.0662 - val_acc: 0.9960\n",
      "Epoch 328/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 6.1822e-04 - acc: 1.0000 - val_loss: 0.0662 - val_acc: 0.9960\n",
      "Epoch 329/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 6.0891e-04 - acc: 1.0000 - val_loss: 0.0661 - val_acc: 0.9960\n",
      "Epoch 330/1500\n",
      "742/742 [==============================] - 0s 62us/step - loss: 5.9991e-04 - acc: 1.0000 - val_loss: 0.0661 - val_acc: 0.9960\n",
      "Epoch 331/1500\n",
      "742/742 [==============================] - 0s 65us/step - loss: 5.9045e-04 - acc: 1.0000 - val_loss: 0.0661 - val_acc: 0.9960\n",
      "Epoch 332/1500\n",
      "742/742 [==============================] - 0s 65us/step - loss: 5.7867e-04 - acc: 1.0000 - val_loss: 0.0661 - val_acc: 0.9960\n",
      "Epoch 333/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 5.7212e-04 - acc: 1.0000 - val_loss: 0.0660 - val_acc: 0.9960\n",
      "Epoch 334/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 5.6431e-04 - acc: 1.0000 - val_loss: 0.0661 - val_acc: 0.9960\n",
      "Epoch 335/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 5.5886e-04 - acc: 1.0000 - val_loss: 0.0659 - val_acc: 0.9960\n",
      "Epoch 336/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 5.5846e-04 - acc: 1.0000 - val_loss: 0.0659 - val_acc: 0.9960\n",
      "Epoch 337/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 5.3635e-04 - acc: 1.0000 - val_loss: 0.0659 - val_acc: 0.9960\n",
      "Epoch 338/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 5.2061e-04 - acc: 1.0000 - val_loss: 0.0659 - val_acc: 0.9960\n",
      "Epoch 339/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 5.1107e-04 - acc: 1.0000 - val_loss: 0.0659 - val_acc: 0.9960\n",
      "Epoch 340/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 5.0164e-04 - acc: 1.0000 - val_loss: 0.0659 - val_acc: 0.9960\n",
      "Epoch 341/1500\n",
      "742/742 [==============================] - 0s 92us/step - loss: 4.9625e-04 - acc: 1.0000 - val_loss: 0.0659 - val_acc: 0.9960\n",
      "Epoch 342/1500\n",
      "742/742 [==============================] - 0s 82us/step - loss: 4.8874e-04 - acc: 1.0000 - val_loss: 0.0659 - val_acc: 0.9960\n",
      "Epoch 343/1500\n",
      "742/742 [==============================] - 0s 98us/step - loss: 4.8102e-04 - acc: 1.0000 - val_loss: 0.0659 - val_acc: 0.9960\n",
      "Epoch 344/1500\n",
      "742/742 [==============================] - 0s 119us/step - loss: 4.7039e-04 - acc: 1.0000 - val_loss: 0.0658 - val_acc: 0.9960\n",
      "Epoch 345/1500\n",
      "742/742 [==============================] - 0s 96us/step - loss: 4.6331e-04 - acc: 1.0000 - val_loss: 0.0658 - val_acc: 0.9960\n",
      "Epoch 346/1500\n",
      "742/742 [==============================] - 0s 85us/step - loss: 4.5635e-04 - acc: 1.0000 - val_loss: 0.0658 - val_acc: 0.9960\n",
      "Epoch 347/1500\n",
      "742/742 [==============================] - 0s 123us/step - loss: 4.5375e-04 - acc: 1.0000 - val_loss: 0.0658 - val_acc: 0.9960\n",
      "Epoch 348/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 4.4809e-04 - acc: 1.0000 - val_loss: 0.0658 - val_acc: 0.9960\n",
      "Epoch 349/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 4.3606e-04 - acc: 1.0000 - val_loss: 0.0658 - val_acc: 0.9960\n",
      "Epoch 350/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 4.3110e-04 - acc: 1.0000 - val_loss: 0.0658 - val_acc: 0.9960\n",
      "Epoch 351/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 4.2310e-04 - acc: 1.0000 - val_loss: 0.0657 - val_acc: 0.9960\n",
      "Epoch 352/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 4.1700e-04 - acc: 1.0000 - val_loss: 0.0657 - val_acc: 0.9960\n",
      "Epoch 353/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 4.1316e-04 - acc: 1.0000 - val_loss: 0.0657 - val_acc: 0.9960\n",
      "Epoch 354/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 4.0439e-04 - acc: 1.0000 - val_loss: 0.0657 - val_acc: 0.9960\n",
      "Epoch 355/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 3.9717e-04 - acc: 1.0000 - val_loss: 0.0657 - val_acc: 0.9960\n",
      "Epoch 356/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 3.9229e-04 - acc: 1.0000 - val_loss: 0.0657 - val_acc: 0.9960\n",
      "Epoch 357/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 3.8600e-04 - acc: 1.0000 - val_loss: 0.0657 - val_acc: 0.9960\n",
      "Epoch 358/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 3.7986e-04 - acc: 1.0000 - val_loss: 0.0657 - val_acc: 0.9960\n",
      "Epoch 359/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 102us/step - loss: 3.7480e-04 - acc: 1.0000 - val_loss: 0.0657 - val_acc: 0.9960\n",
      "Epoch 360/1500\n",
      "742/742 [==============================] - 0s 105us/step - loss: 3.7151e-04 - acc: 1.0000 - val_loss: 0.0656 - val_acc: 0.9960\n",
      "Epoch 361/1500\n",
      "742/742 [==============================] - 0s 88us/step - loss: 3.6518e-04 - acc: 1.0000 - val_loss: 0.0656 - val_acc: 0.9960\n",
      "Epoch 362/1500\n",
      "742/742 [==============================] - 0s 104us/step - loss: 3.6827e-04 - acc: 1.0000 - val_loss: 0.0656 - val_acc: 0.9960\n",
      "Epoch 363/1500\n",
      "742/742 [==============================] - 0s 91us/step - loss: 3.6137e-04 - acc: 1.0000 - val_loss: 0.0656 - val_acc: 0.9960\n",
      "Epoch 364/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 3.4471e-04 - acc: 1.0000 - val_loss: 0.0656 - val_acc: 0.9960\n",
      "Epoch 365/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 3.3740e-04 - acc: 1.0000 - val_loss: 0.0656 - val_acc: 0.9960\n",
      "Epoch 366/1500\n",
      "742/742 [==============================] - 0s 81us/step - loss: 3.3250e-04 - acc: 1.0000 - val_loss: 0.0656 - val_acc: 0.9960\n",
      "Epoch 367/1500\n",
      "742/742 [==============================] - 0s 79us/step - loss: 3.2691e-04 - acc: 1.0000 - val_loss: 0.0655 - val_acc: 0.9960\n",
      "Epoch 368/1500\n",
      "742/742 [==============================] - 0s 84us/step - loss: 3.2279e-04 - acc: 1.0000 - val_loss: 0.0655 - val_acc: 0.9960\n",
      "Epoch 369/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 3.1881e-04 - acc: 1.0000 - val_loss: 0.0655 - val_acc: 0.9960\n",
      "Epoch 370/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 3.1328e-04 - acc: 1.0000 - val_loss: 0.0655 - val_acc: 0.9960\n",
      "Epoch 371/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 3.0921e-04 - acc: 1.0000 - val_loss: 0.0655 - val_acc: 0.9960\n",
      "Epoch 372/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 3.0462e-04 - acc: 1.0000 - val_loss: 0.0655 - val_acc: 0.9960\n",
      "Epoch 373/1500\n",
      "742/742 [==============================] - 0s 82us/step - loss: 3.0036e-04 - acc: 1.0000 - val_loss: 0.0655 - val_acc: 0.9960\n",
      "Epoch 374/1500\n",
      "742/742 [==============================] - 0s 89us/step - loss: 2.9636e-04 - acc: 1.0000 - val_loss: 0.0655 - val_acc: 0.9960\n",
      "Epoch 375/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 2.9291e-04 - acc: 1.0000 - val_loss: 0.0655 - val_acc: 0.9960\n",
      "Epoch 376/1500\n",
      "742/742 [==============================] - 0s 83us/step - loss: 2.8689e-04 - acc: 1.0000 - val_loss: 0.0655 - val_acc: 0.9960\n",
      "Epoch 377/1500\n",
      "742/742 [==============================] - 0s 81us/step - loss: 2.8240e-04 - acc: 1.0000 - val_loss: 0.0655 - val_acc: 0.9960\n",
      "Epoch 378/1500\n",
      "742/742 [==============================] - 0s 82us/step - loss: 2.8096e-04 - acc: 1.0000 - val_loss: 0.0655 - val_acc: 0.9960\n",
      "Epoch 379/1500\n",
      "742/742 [==============================] - 0s 84us/step - loss: 2.7831e-04 - acc: 1.0000 - val_loss: 0.0654 - val_acc: 0.9960\n",
      "Epoch 380/1500\n",
      "742/742 [==============================] - 0s 81us/step - loss: 2.7685e-04 - acc: 1.0000 - val_loss: 0.0654 - val_acc: 0.9960\n",
      "Epoch 381/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 2.6604e-04 - acc: 1.0000 - val_loss: 0.0654 - val_acc: 0.9960\n",
      "Epoch 382/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 2.6045e-04 - acc: 1.0000 - val_loss: 0.0654 - val_acc: 0.9960\n",
      "Epoch 383/1500\n",
      "742/742 [==============================] - 0s 66us/step - loss: 2.5638e-04 - acc: 1.0000 - val_loss: 0.0654 - val_acc: 0.9960\n",
      "Epoch 384/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 2.5318e-04 - acc: 1.0000 - val_loss: 0.0654 - val_acc: 0.9960\n",
      "Epoch 385/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 2.4957e-04 - acc: 1.0000 - val_loss: 0.0654 - val_acc: 0.9960\n",
      "Epoch 386/1500\n",
      "742/742 [==============================] - 0s 84us/step - loss: 2.4749e-04 - acc: 1.0000 - val_loss: 0.0654 - val_acc: 0.9960\n",
      "Epoch 387/1500\n",
      "742/742 [==============================] - 0s 93us/step - loss: 2.4463e-04 - acc: 1.0000 - val_loss: 0.0654 - val_acc: 0.9960\n",
      "Epoch 388/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 2.3911e-04 - acc: 1.0000 - val_loss: 0.0654 - val_acc: 0.9960\n",
      "Epoch 389/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 2.3517e-04 - acc: 1.0000 - val_loss: 0.0654 - val_acc: 0.9960\n",
      "Epoch 390/1500\n",
      "742/742 [==============================] - 0s 81us/step - loss: 2.3269e-04 - acc: 1.0000 - val_loss: 0.0654 - val_acc: 0.9960\n",
      "Epoch 391/1500\n",
      "742/742 [==============================] - 0s 84us/step - loss: 2.3086e-04 - acc: 1.0000 - val_loss: 0.0654 - val_acc: 0.9960\n",
      "Epoch 392/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 2.2528e-04 - acc: 1.0000 - val_loss: 0.0654 - val_acc: 0.9960\n",
      "Epoch 393/1500\n",
      "742/742 [==============================] - 0s 98us/step - loss: 2.2249e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 394/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 2.1896e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 395/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 2.1642e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 396/1500\n",
      "742/742 [==============================] - 0s 94us/step - loss: 2.1320e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 397/1500\n",
      "742/742 [==============================] - 0s 94us/step - loss: 2.1089e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 398/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 2.0644e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 399/1500\n",
      "742/742 [==============================] - ETA: 0s - loss: 1.1169e-04 - acc: 1.000 - 0s 77us/step - loss: 2.0385e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 400/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 2.0165e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 401/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.9844e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 402/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.9649e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 403/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.9341e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 404/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.9115e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 405/1500\n",
      "742/742 [==============================] - 0s 79us/step - loss: 1.8828e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 406/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.8737e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 407/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.8398e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 408/1500\n",
      "742/742 [==============================] - 0s 81us/step - loss: 1.7993e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 409/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.7748e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 410/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.7626e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 411/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.7352e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 412/1500\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.7040e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 413/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.6840e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 414/1500\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.6598e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 415/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.6361e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 416/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.6117e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 417/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.5984e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 418/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.5732e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 419/1500\n",
      "742/742 [==============================] - 0s 82us/step - loss: 1.5509e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 420/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.5304e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 421/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.5216e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 422/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.4968e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 423/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.5052e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 424/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.4532e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 425/1500\n",
      "742/742 [==============================] - 0s 79us/step - loss: 1.4237e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 426/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.3986e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 427/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.3891e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 428/1500\n",
      "742/742 [==============================] - 0s 108us/step - loss: 1.3778e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 429/1500\n",
      "742/742 [==============================] - 0s 132us/step - loss: 1.3525e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 430/1500\n",
      "742/742 [==============================] - 0s 125us/step - loss: 1.3315e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 431/1500\n",
      "742/742 [==============================] - 0s 144us/step - loss: 1.3076e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 432/1500\n",
      "742/742 [==============================] - 0s 137us/step - loss: 1.2926e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 433/1500\n",
      "742/742 [==============================] - 0s 120us/step - loss: 1.2816e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 434/1500\n",
      "742/742 [==============================] - 0s 121us/step - loss: 1.2585e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 435/1500\n",
      "742/742 [==============================] - 0s 123us/step - loss: 1.2403e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 436/1500\n",
      "742/742 [==============================] - 0s 101us/step - loss: 1.2299e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 437/1500\n",
      "742/742 [==============================] - 0s 104us/step - loss: 1.2065e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 438/1500\n",
      "742/742 [==============================] - 0s 82us/step - loss: 1.1923e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 439/1500\n",
      "742/742 [==============================] - 0s 80us/step - loss: 1.1825e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 440/1500\n",
      "742/742 [==============================] - 0s 116us/step - loss: 1.1609e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 441/1500\n",
      "742/742 [==============================] - 0s 104us/step - loss: 1.1474e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 442/1500\n",
      "742/742 [==============================] - 0s 112us/step - loss: 1.1343e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 443/1500\n",
      "742/742 [==============================] - 0s 108us/step - loss: 1.1137e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 444/1500\n",
      "742/742 [==============================] - 0s 147us/step - loss: 1.1148e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 445/1500\n",
      "742/742 [==============================] - 0s 135us/step - loss: 1.0891e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 446/1500\n",
      "742/742 [==============================] - 0s 128us/step - loss: 1.0710e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 447/1500\n",
      "742/742 [==============================] - 0s 108us/step - loss: 1.0541e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 448/1500\n",
      "742/742 [==============================] - 0s 141us/step - loss: 1.0425e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 449/1500\n",
      "742/742 [==============================] - 0s 102us/step - loss: 1.0243e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 450/1500\n",
      "742/742 [==============================] - 0s 105us/step - loss: 1.0180e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 451/1500\n",
      "742/742 [==============================] - 0s 120us/step - loss: 1.0045e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 452/1500\n",
      "742/742 [==============================] - 0s 121us/step - loss: 9.8926e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 453/1500\n",
      "742/742 [==============================] - 0s 105us/step - loss: 9.8258e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 454/1500\n",
      "742/742 [==============================] - 0s 135us/step - loss: 9.6438e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 455/1500\n",
      "742/742 [==============================] - 0s 101us/step - loss: 9.5227e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 456/1500\n",
      "742/742 [==============================] - 0s 101us/step - loss: 9.3963e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 457/1500\n",
      "742/742 [==============================] - 0s 129us/step - loss: 9.2594e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 458/1500\n",
      "742/742 [==============================] - 0s 104us/step - loss: 9.1556e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 459/1500\n",
      "742/742 [==============================] - ETA: 0s - loss: 9.0987e-05 - acc: 1.000 - 0s 102us/step - loss: 9.0496e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 460/1500\n",
      "742/742 [==============================] - 0s 101us/step - loss: 8.9089e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 461/1500\n",
      "742/742 [==============================] - 0s 90us/step - loss: 8.7713e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 462/1500\n",
      "742/742 [==============================] - 0s 124us/step - loss: 8.6741e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 463/1500\n",
      "742/742 [==============================] - 0s 79us/step - loss: 8.5614e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 464/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 8.4833e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 465/1500\n",
      "742/742 [==============================] - 0s 79us/step - loss: 8.3579e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 466/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 8.2666e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 467/1500\n",
      "742/742 [==============================] - 0s 82us/step - loss: 8.1497e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 468/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 8.0644e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 469/1500\n",
      "742/742 [==============================] - 0s 79us/step - loss: 7.9453e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 470/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 7.8540e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 471/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 7.7355e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 472/1500\n",
      "742/742 [==============================] - 0s 79us/step - loss: 7.6423e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 473/1500\n",
      "742/742 [==============================] - 0s 101us/step - loss: 7.5425e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 474/1500\n",
      "742/742 [==============================] - 0s 113us/step - loss: 7.4250e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 475/1500\n",
      "742/742 [==============================] - 0s 81us/step - loss: 7.3416e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 476/1500\n",
      "742/742 [==============================] - 0s 101us/step - loss: 7.2398e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 477/1500\n",
      "742/742 [==============================] - 0s 124us/step - loss: 7.1757e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 478/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 7.0845e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 479/1500\n",
      "742/742 [==============================] - 0s 65us/step - loss: 7.1583e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 480/1500\n",
      "742/742 [==============================] - 0s 76us/step - loss: 6.9693e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 481/1500\n",
      "742/742 [==============================] - 0s 82us/step - loss: 6.7893e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 482/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 6.6850e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 483/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 6.5894e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 484/1500\n",
      "742/742 [==============================] - 0s 79us/step - loss: 6.5079e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 485/1500\n",
      "742/742 [==============================] - 0s 65us/step - loss: 6.4227e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 486/1500\n",
      "742/742 [==============================] - 0s 65us/step - loss: 6.3649e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 487/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 6.2751e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 488/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 6.1919e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 489/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 6.1105e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 490/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 6.0375e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 491/1500\n",
      "742/742 [==============================] - 0s 66us/step - loss: 5.9600e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 492/1500\n",
      "742/742 [==============================] - 0s 82us/step - loss: 5.8999e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 493/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 5.8085e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 494/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 5.7479e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 495/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 5.6601e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 496/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 5.6172e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 497/1500\n",
      "742/742 [==============================] - 0s 82us/step - loss: 5.5149e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 498/1500\n",
      "742/742 [==============================] - 0s 131us/step - loss: 5.4891e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 499/1500\n",
      "742/742 [==============================] - 0s 102us/step - loss: 5.3901e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 500/1500\n",
      "742/742 [==============================] - 0s 92us/step - loss: 5.3244e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 501/1500\n",
      "742/742 [==============================] - 0s 82us/step - loss: 5.2786e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 502/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 5.1999e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 503/1500\n",
      "742/742 [==============================] - 0s 82us/step - loss: 5.1420e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 504/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 5.0701e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 505/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 5.0166e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 506/1500\n",
      "742/742 [==============================] - 0s 65us/step - loss: 4.9572e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 507/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 4.8655e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 508/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 4.8109e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 509/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 4.7385e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 510/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 4.6985e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 511/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 4.6386e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 512/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 4.5701e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 513/1500\n",
      "742/742 [==============================] - 0s 65us/step - loss: 4.5095e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 514/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 4.5040e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 515/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 4.3926e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 516/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 4.3470e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 517/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 4.2959e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 518/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 4.2378e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 519/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 4.2026e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 520/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 4.1345e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 521/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 4.0937e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 522/1500\n",
      "742/742 [==============================] - 0s 66us/step - loss: 4.0563e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 523/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 3.9974e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 524/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 3.9233e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 525/1500\n",
      "742/742 [==============================] - 0s 88us/step - loss: 3.8704e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 526/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 3.8304e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 527/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 3.7977e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 528/1500\n",
      "742/742 [==============================] - 0s 88us/step - loss: 3.7469e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 529/1500\n",
      "742/742 [==============================] - 0s 90us/step - loss: 3.7053e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 530/1500\n",
      "742/742 [==============================] - 0s 89us/step - loss: 3.6504e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 531/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 3.6074e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 532/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 66us/step - loss: 3.5253e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 533/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 3.4846e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 534/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 3.4564e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 535/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 3.3960e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 536/1500\n",
      "742/742 [==============================] - 0s 100us/step - loss: 3.3560e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 537/1500\n",
      "742/742 [==============================] - 0s 100us/step - loss: 3.3084e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 538/1500\n",
      "742/742 [==============================] - 0s 97us/step - loss: 3.2718e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 539/1500\n",
      "742/742 [==============================] - 0s 96us/step - loss: 3.2221e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 540/1500\n",
      "742/742 [==============================] - 0s 85us/step - loss: 3.1953e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 541/1500\n",
      "742/742 [==============================] - 0s 100us/step - loss: 3.1658e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 542/1500\n",
      "742/742 [==============================] - 0s 81us/step - loss: 3.1079e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 543/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 3.0888e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 544/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 3.0842e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 545/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 2.9951e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 546/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 2.9398e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 547/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 2.8961e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 548/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 2.8675e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 549/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 2.8391e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 550/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 2.8241e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 551/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 2.7624e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 552/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 2.7302e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 553/1500\n",
      "742/742 [==============================] - 0s 66us/step - loss: 2.7001e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 554/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 2.6610e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 555/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 2.6326e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 556/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 2.5966e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 557/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 2.5532e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 558/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 2.5274e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 559/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 2.4972e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 560/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 2.4630e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 561/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 2.4421e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 562/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 2.4035e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 563/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 2.3728e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 564/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 2.3613e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 565/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 2.3170e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 566/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 2.3014e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 567/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 2.2496e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 568/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 2.2410e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 569/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 2.2170e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 570/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 2.1814e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 571/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 2.1499e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 572/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 2.1261e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 573/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 2.1044e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 574/1500\n",
      "742/742 [==============================] - 0s 66us/step - loss: 2.0744e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 575/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 2.0478e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 576/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 2.0204e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 577/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 2.0000e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 578/1500\n",
      "742/742 [==============================] - 0s 65us/step - loss: 1.9723e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 579/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.9466e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 580/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.9209e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 581/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.8911e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 582/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.8872e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 583/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.8508e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 584/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.8342e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 585/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.8086e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 586/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.7803e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 587/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.7790e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 588/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.7471e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 589/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.7255e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 590/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.6936e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 591/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.6844e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 592/1500\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.6577e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 593/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.6868e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 594/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.6608e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 595/1500\n",
      "742/742 [==============================] - 0s 62us/step - loss: 1.6100e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 596/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.5700e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 597/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.5490e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 598/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.5234e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 599/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.5112e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 600/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.4929e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 601/1500\n",
      "742/742 [==============================] - 0s 85us/step - loss: 1.4704e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 602/1500\n",
      "742/742 [==============================] - 0s 84us/step - loss: 1.4514e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 603/1500\n",
      "742/742 [==============================] - 0s 97us/step - loss: 1.4557e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 604/1500\n",
      "742/742 [==============================] - 0s 82us/step - loss: 1.4232e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 605/1500\n",
      "742/742 [==============================] - 0s 84us/step - loss: 1.3969e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 606/1500\n",
      "742/742 [==============================] - 0s 104us/step - loss: 1.3799e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 607/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.3650e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 608/1500\n",
      "742/742 [==============================] - ETA: 0s - loss: 5.6774e-06 - acc: 1.000 - 0s 78us/step - loss: 1.3617e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 609/1500\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.3322e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 610/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.3107e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 611/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.2999e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 612/1500\n",
      "742/742 [==============================] - 0s 93us/step - loss: 1.2866e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 613/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.2685e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 614/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.2564e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 615/1500\n",
      "742/742 [==============================] - 0s 84us/step - loss: 1.2385e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 616/1500\n",
      "742/742 [==============================] - 0s 85us/step - loss: 1.2240e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 617/1500\n",
      "742/742 [==============================] - 0s 93us/step - loss: 1.2020e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 618/1500\n",
      "742/742 [==============================] - 0s 120us/step - loss: 1.1894e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 619/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.1737e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 620/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.1624e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 621/1500\n",
      "742/742 [==============================] - 0s 38us/step - loss: 1.1447e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 622/1500\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.1335e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 623/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.1176e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 624/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.1121e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 625/1500\n",
      "742/742 [==============================] - 0s 65us/step - loss: 1.0885e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 626/1500\n",
      "742/742 [==============================] - 0s 65us/step - loss: 1.0744e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 627/1500\n",
      "742/742 [==============================] - 0s 62us/step - loss: 1.0665e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 628/1500\n",
      "742/742 [==============================] - 0s 62us/step - loss: 1.0533e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 629/1500\n",
      "742/742 [==============================] - 0s 113us/step - loss: 1.0405e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 630/1500\n",
      "742/742 [==============================] - 0s 140us/step - loss: 1.0233e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 631/1500\n",
      "742/742 [==============================] - 0s 143us/step - loss: 1.0111e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 632/1500\n",
      "742/742 [==============================] - 0s 129us/step - loss: 9.9737e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 633/1500\n",
      "742/742 [==============================] - 0s 113us/step - loss: 9.8513e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 634/1500\n",
      "742/742 [==============================] - 0s 101us/step - loss: 9.7215e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 635/1500\n",
      "742/742 [==============================] - 0s 85us/step - loss: 9.6794e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 636/1500\n",
      "742/742 [==============================] - 0s 60us/step - loss: 9.5129e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 637/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 9.3957e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 638/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 9.3372e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 639/1500\n",
      "742/742 [==============================] - 0s 51us/step - loss: 9.1661e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 640/1500\n",
      "742/742 [==============================] - 0s 58us/step - loss: 9.0548e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 641/1500\n",
      "742/742 [==============================] - 0s 54us/step - loss: 8.9451e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 642/1500\n",
      "742/742 [==============================] - 0s 55us/step - loss: 8.9088e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 643/1500\n",
      "742/742 [==============================] - 0s 57us/step - loss: 8.7535e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 644/1500\n",
      "742/742 [==============================] - 0s 65us/step - loss: 8.6226e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 645/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 8.4822e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 646/1500\n",
      "742/742 [==============================] - 0s 54us/step - loss: 8.3824e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 647/1500\n",
      "742/742 [==============================] - 0s 48us/step - loss: 8.2734e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 648/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 8.2235e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 649/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 8.0971e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 650/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 7.9768e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 651/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 7.8787e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 652/1500\n",
      "742/742 [==============================] - 0s 58us/step - loss: 7.7910e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 653/1500\n",
      "742/742 [==============================] - 0s 59us/step - loss: 7.6826e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 654/1500\n",
      "742/742 [==============================] - 0s 58us/step - loss: 7.7017e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 655/1500\n",
      "742/742 [==============================] - 0s 57us/step - loss: 7.5387e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 656/1500\n",
      "742/742 [==============================] - 0s 39us/step - loss: 7.4088e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 657/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 7.3666e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 658/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 7.1981e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 659/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 7.1897e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 660/1500\n",
      "742/742 [==============================] - 0s 46us/step - loss: 7.0204e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 661/1500\n",
      "742/742 [==============================] - 0s 91us/step - loss: 7.0008e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 662/1500\n",
      "742/742 [==============================] - 0s 98us/step - loss: 6.8588e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 663/1500\n",
      "742/742 [==============================] - 0s 82us/step - loss: 6.8384e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 664/1500\n",
      "742/742 [==============================] - 0s 94us/step - loss: 6.7306e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 665/1500\n",
      "742/742 [==============================] - 0s 84us/step - loss: 6.6740e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 666/1500\n",
      "742/742 [==============================] - 0s 84us/step - loss: 6.5550e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 667/1500\n",
      "742/742 [==============================] - 0s 108us/step - loss: 6.4511e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 668/1500\n",
      "742/742 [==============================] - 0s 98us/step - loss: 6.3786e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 669/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 6.3405e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 670/1500\n",
      "742/742 [==============================] - 0s 81us/step - loss: 6.2151e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 671/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 6.1304e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 672/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 6.0465e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 673/1500\n",
      "742/742 [==============================] - 0s 55us/step - loss: 6.0811e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 674/1500\n",
      "742/742 [==============================] - 0s 44us/step - loss: 5.9111e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 675/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 5.8440e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 676/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 5.7603e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 677/1500\n",
      "742/742 [==============================] - 0s 55us/step - loss: 5.7021e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 678/1500\n",
      "742/742 [==============================] - 0s 49us/step - loss: 5.6141e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 679/1500\n",
      "742/742 [==============================] - 0s 58us/step - loss: 5.5632e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 680/1500\n",
      "742/742 [==============================] - 0s 48us/step - loss: 5.4888e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 681/1500\n",
      "742/742 [==============================] - 0s 44us/step - loss: 5.3949e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 682/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 5.3471e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 683/1500\n",
      "742/742 [==============================] - 0s 101us/step - loss: 5.2974e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 684/1500\n",
      "742/742 [==============================] - 0s 104us/step - loss: 5.2585e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 685/1500\n",
      "742/742 [==============================] - 0s 96us/step - loss: 5.1386e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 686/1500\n",
      "742/742 [==============================] - 0s 104us/step - loss: 5.1299e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 687/1500\n",
      "742/742 [==============================] - 0s 90us/step - loss: 5.0254e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 688/1500\n",
      "742/742 [==============================] - 0s 105us/step - loss: 5.0039e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 689/1500\n",
      "742/742 [==============================] - 0s 96us/step - loss: 4.9257e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 690/1500\n",
      "742/742 [==============================] - 0s 93us/step - loss: 4.9983e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 691/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 4.7921e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 692/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 4.7265e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 693/1500\n",
      "742/742 [==============================] - 0s 38us/step - loss: 4.6460e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 694/1500\n",
      "742/742 [==============================] - 0s 84us/step - loss: 4.5665e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 695/1500\n",
      "742/742 [==============================] - 0s 59us/step - loss: 4.5145e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 696/1500\n",
      "742/742 [==============================] - 0s 55us/step - loss: 4.4775e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 697/1500\n",
      "742/742 [==============================] - 0s 54us/step - loss: 4.4097e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 698/1500\n",
      "742/742 [==============================] - 0s 62us/step - loss: 4.3874e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 699/1500\n",
      "742/742 [==============================] - 0s 57us/step - loss: 4.3014e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 700/1500\n",
      "742/742 [==============================] - 0s 54us/step - loss: 4.2888e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 701/1500\n",
      "742/742 [==============================] - 0s 48us/step - loss: 4.2285e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 702/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 4.1419e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 703/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 4.1113e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 704/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 4.0727e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 705/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 4.0207e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 706/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 73us/step - loss: 3.9499e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 707/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 3.9244e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 708/1500\n",
      "742/742 [==============================] - 0s 66us/step - loss: 3.8561e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 709/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 3.8026e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 710/1500\n",
      "742/742 [==============================] - 0s 66us/step - loss: 3.7864e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 711/1500\n",
      "742/742 [==============================] - 0s 61us/step - loss: 3.7048e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 712/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 3.6802e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 713/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 3.6226e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 714/1500\n",
      "742/742 [==============================] - 0s 58us/step - loss: 3.5640e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 715/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 3.5421e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 716/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 3.4904e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 717/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 3.5313e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 718/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 3.5283e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 719/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 3.3831e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 720/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 3.3051e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 721/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 3.2993e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 722/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 3.2134e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 723/1500\n",
      "742/742 [==============================] - 0s 57us/step - loss: 3.1632e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 724/1500\n",
      "742/742 [==============================] - 0s 44us/step - loss: 3.1216e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 725/1500\n",
      "742/742 [==============================] - 0s 45us/step - loss: 3.1413e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 726/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 3.0598e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 727/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 3.0205e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 728/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 2.9966e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 729/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 2.9433e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 730/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 2.9111e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 731/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 2.8910e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 732/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 2.8776e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 733/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 2.8229e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 734/1500\n",
      "742/742 [==============================] - 0s 62us/step - loss: 2.7779e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 735/1500\n",
      "742/742 [==============================] - 0s 62us/step - loss: 2.7469e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 736/1500\n",
      "742/742 [==============================] - 0s 41us/step - loss: 2.7341e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 737/1500\n",
      "742/742 [==============================] - 0s 58us/step - loss: 2.6813e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 738/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 2.6427e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 739/1500\n",
      "742/742 [==============================] - 0s 62us/step - loss: 2.6166e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 740/1500\n",
      "742/742 [==============================] - 0s 48us/step - loss: 2.6128e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 741/1500\n",
      "742/742 [==============================] - 0s 45us/step - loss: 2.5338e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 742/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 2.5216e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 743/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 2.5173e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 744/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 2.4627e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 745/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 2.4340e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 746/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 2.3901e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 747/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 2.3628e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 748/1500\n",
      "742/742 [==============================] - 0s 59us/step - loss: 2.3465e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 749/1500\n",
      "742/742 [==============================] - 0s 34us/step - loss: 2.3011e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 750/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 2.2846e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 751/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 2.2652e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 752/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 2.2553e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 753/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 2.2071e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 754/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 2.1695e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 755/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 2.1679e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 756/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 2.1147e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 757/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 2.1012e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 758/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 2.0808e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 759/1500\n",
      "742/742 [==============================] - 0s 57us/step - loss: 2.0448e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 760/1500\n",
      "742/742 [==============================] - 0s 50us/step - loss: 2.0290e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 761/1500\n",
      "742/742 [==============================] - 0s 52us/step - loss: 2.0272e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 762/1500\n",
      "742/742 [==============================] - 0s 47us/step - loss: 1.9823e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 763/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 1.9588e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 764/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 1.9237e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 765/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 1.9076e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 766/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 1.8789e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 767/1500\n",
      "742/742 [==============================] - 0s 51us/step - loss: 1.8604e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 768/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.8431e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 769/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 1.8086e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 770/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 1.7826e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 771/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 1.7730e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 772/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 1.7546e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 773/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 1.7297e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 774/1500\n",
      "742/742 [==============================] - 0s 72us/step - loss: 1.7231e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 775/1500\n",
      "742/742 [==============================] - 0s 29us/step - loss: 1.6884e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 776/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 1.6633e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 777/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 1.6458e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 778/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 1.6326e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 779/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 1.6114e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 780/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 1.6009e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 781/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 1.5658e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 782/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 1.5591e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 783/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 1.5267e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 784/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.5089e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 785/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.5036e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 786/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.5019e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 787/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.4661e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 788/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 1.4473e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 789/1500\n",
      "742/742 [==============================] - 0s 59us/step - loss: 1.4395e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 790/1500\n",
      "742/742 [==============================] - 0s 62us/step - loss: 1.4126e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 791/1500\n",
      "742/742 [==============================] - 0s 59us/step - loss: 1.4076e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 792/1500\n",
      "742/742 [==============================] - 0s 61us/step - loss: 1.3788e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 793/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 1.3636e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 794/1500\n",
      "742/742 [==============================] - 0s 45us/step - loss: 1.3302e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 795/1500\n",
      "742/742 [==============================] - 0s 65us/step - loss: 1.3213e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 796/1500\n",
      "742/742 [==============================] - 0s 96us/step - loss: 1.2983e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 797/1500\n",
      "742/742 [==============================] - 0s 96us/step - loss: 1.2880e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 798/1500\n",
      "742/742 [==============================] - 0s 65us/step - loss: 1.2733e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 799/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.2579e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 800/1500\n",
      "742/742 [==============================] - 0s 85us/step - loss: 1.2404e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 801/1500\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.2296e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 802/1500\n",
      "742/742 [==============================] - 0s 93us/step - loss: 1.2157e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 803/1500\n",
      "742/742 [==============================] - 0s 84us/step - loss: 1.1958e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 804/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.2022e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 805/1500\n",
      "742/742 [==============================] - 0s 84us/step - loss: 1.1872e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 806/1500\n",
      "742/742 [==============================] - 0s 79us/step - loss: 1.1538e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 807/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.1424e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 808/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.1201e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 809/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.1119e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 810/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.0960e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 811/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.0820e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 812/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.0663e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 813/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.0619e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 814/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.0537e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 815/1500\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.0290e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 816/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.0213e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 817/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.0074e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 818/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.0061e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 819/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.0078e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 820/1500\n",
      "742/742 [==============================] - 0s 66us/step - loss: 9.8189e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 821/1500\n",
      "742/742 [==============================] - 0s 66us/step - loss: 9.6831e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 822/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 69us/step - loss: 9.5136e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 823/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 9.3634e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 824/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 9.2622e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 825/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 9.1754e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 826/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 9.0485e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 827/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 9.0276e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 828/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 8.7488e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 829/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 8.7834e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 830/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 8.7537e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 831/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 8.5335e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 832/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 8.5103e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 833/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 8.3592e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 834/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 8.2677e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 835/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 8.1447e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 836/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 8.1118e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 837/1500\n",
      "742/742 [==============================] - 0s 76us/step - loss: 7.9873e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 838/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 7.9086e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 839/1500\n",
      "742/742 [==============================] - 0s 81us/step - loss: 7.8355e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 840/1500\n",
      "742/742 [==============================] - 0s 65us/step - loss: 7.7238e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 841/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 7.6250e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 842/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 7.5423e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 843/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 7.4700e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 844/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 7.3760e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 845/1500\n",
      "742/742 [==============================] - 0s 66us/step - loss: 7.3302e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 846/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 7.2499e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 847/1500\n",
      "742/742 [==============================] - 0s 62us/step - loss: 7.1655e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 848/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 7.1077e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 849/1500\n",
      "742/742 [==============================] - 0s 65us/step - loss: 7.0105e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 850/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 6.8940e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 851/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 6.8851e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 852/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 6.7655e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 853/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 6.7221e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 854/1500\n",
      "742/742 [==============================] - 0s 66us/step - loss: 6.8442e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 855/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 6.8570e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 856/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 6.5493e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 857/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 6.4738e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 858/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 6.3309e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 859/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 6.2513e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 860/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 6.1846e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 861/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 6.1581e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 862/1500\n",
      "742/742 [==============================] - 0s 102us/step - loss: 6.0730e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 863/1500\n",
      "742/742 [==============================] - 0s 120us/step - loss: 6.0890e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 864/1500\n",
      "742/742 [==============================] - 0s 90us/step - loss: 5.9131e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 865/1500\n",
      "742/742 [==============================] - 0s 79us/step - loss: 5.7838e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 866/1500\n",
      "742/742 [==============================] - 0s 86us/step - loss: 5.7645e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 867/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 5.6786e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 868/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 5.6296e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 869/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 5.5926e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 870/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 5.5404e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 871/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 5.5115e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 872/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 5.3677e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 873/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 5.3412e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 874/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 5.2809e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 875/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 5.2311e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 876/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 5.1902e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 877/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 5.1612e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 878/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 5.0697e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 879/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 5.1355e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 880/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 5.0134e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 881/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 4.9500e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 882/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 4.8769e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 883/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 4.8375e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 884/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 4.7724e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 885/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 4.7266e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 886/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 4.9074e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 887/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 4.7732e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 888/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 4.5917e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 889/1500\n",
      "742/742 [==============================] - 0s 62us/step - loss: 4.5828e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 890/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 4.5274e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 891/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 4.4294e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 892/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 4.4021e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 893/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 4.3322e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 894/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 4.3330e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 895/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 4.2647e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 896/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 4.2125e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 897/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 4.1916e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 898/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 4.1579e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 899/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 4.1073e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 900/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 4.0784e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 901/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 4.0470e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 902/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 3.9956e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 903/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 3.9418e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 904/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 3.9346e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 905/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 3.9000e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 906/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 3.8567e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 907/1500\n",
      "742/742 [==============================] - 0s 66us/step - loss: 3.8036e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 908/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 3.7739e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 909/1500\n",
      "742/742 [==============================] - 0s 81us/step - loss: 3.7683e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 910/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 3.7072e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 911/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 3.6735e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 912/1500\n",
      "742/742 [==============================] - 0s 66us/step - loss: 3.6454e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 913/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 3.6012e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 914/1500\n",
      "742/742 [==============================] - 0s 82us/step - loss: 3.5811e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 915/1500\n",
      "742/742 [==============================] - 0s 93us/step - loss: 3.5361e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 916/1500\n",
      "742/742 [==============================] - 0s 109us/step - loss: 3.5193e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 917/1500\n",
      "742/742 [==============================] - 0s 81us/step - loss: 3.4807e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 918/1500\n",
      "742/742 [==============================] - 0s 88us/step - loss: 3.4542e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 919/1500\n",
      "742/742 [==============================] - 0s 84us/step - loss: 3.4189e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 920/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 3.3875e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 921/1500\n",
      "742/742 [==============================] - 0s 84us/step - loss: 3.3690e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 922/1500\n",
      "742/742 [==============================] - 0s 81us/step - loss: 3.3755e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 923/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 3.3184e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 924/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 3.2638e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 925/1500\n",
      "742/742 [==============================] - 0s 119us/step - loss: 3.3064e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 926/1500\n",
      "742/742 [==============================] - 0s 97us/step - loss: 3.2196e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 927/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 3.2245e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 928/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 3.1650e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 929/1500\n",
      "742/742 [==============================] - 0s 94us/step - loss: 3.1457e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 930/1500\n",
      "742/742 [==============================] - 0s 82us/step - loss: 3.1168e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 931/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 3.0959e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 932/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 3.0718e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 933/1500\n",
      "742/742 [==============================] - 0s 61us/step - loss: 3.0325e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 934/1500\n",
      "742/742 [==============================] - 0s 59us/step - loss: 3.0092e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 935/1500\n",
      "742/742 [==============================] - 0s 62us/step - loss: 2.9778e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 936/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 2.9835e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 937/1500\n",
      "742/742 [==============================] - 0s 109us/step - loss: 2.9730e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 938/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 90us/step - loss: 2.9594e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 939/1500\n",
      "742/742 [==============================] - 0s 86us/step - loss: 2.9031e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 940/1500\n",
      "742/742 [==============================] - 0s 94us/step - loss: 2.9031e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 941/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 2.8373e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 942/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 2.8260e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 943/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 2.8260e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 944/1500\n",
      "742/742 [==============================] - 0s 89us/step - loss: 2.8003e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 945/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 2.7907e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 946/1500\n",
      "742/742 [==============================] - 0s 36us/step - loss: 2.7569e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 947/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 2.7296e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 948/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 2.7055e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 949/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 2.6862e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 950/1500\n",
      "742/742 [==============================] - 0s 79us/step - loss: 2.6758e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 951/1500\n",
      "742/742 [==============================] - 0s 102us/step - loss: 2.6557e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 952/1500\n",
      "742/742 [==============================] - 0s 105us/step - loss: 2.6533e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 953/1500\n",
      "742/742 [==============================] - 0s 81us/step - loss: 2.5971e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 954/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 2.6035e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 955/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 2.5786e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 956/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 2.5368e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 957/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 2.5248e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 958/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 2.5304e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 959/1500\n",
      "742/742 [==============================] - 0s 64us/step - loss: 2.5200e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 960/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 2.4910e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 961/1500\n",
      "742/742 [==============================] - 0s 88us/step - loss: 2.4613e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 962/1500\n",
      "742/742 [==============================] - 0s 102us/step - loss: 2.4509e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 963/1500\n",
      "742/742 [==============================] - 0s 102us/step - loss: 2.4163e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 964/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 2.4364e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 965/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 2.4091e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 966/1500\n",
      "742/742 [==============================] - 0s 89us/step - loss: 2.3754e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 967/1500\n",
      "742/742 [==============================] - 0s 57us/step - loss: 2.3866e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 968/1500\n",
      "742/742 [==============================] - 0s 55us/step - loss: 2.3577e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 969/1500\n",
      "742/742 [==============================] - 0s 55us/step - loss: 2.3352e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 970/1500\n",
      "742/742 [==============================] - 0s 57us/step - loss: 2.3368e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 971/1500\n",
      "742/742 [==============================] - 0s 55us/step - loss: 2.2974e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 972/1500\n",
      "742/742 [==============================] - 0s 55us/step - loss: 2.3006e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 973/1500\n",
      "742/742 [==============================] - 0s 51us/step - loss: 2.2717e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 974/1500\n",
      "742/742 [==============================] - 0s 57us/step - loss: 2.2693e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 975/1500\n",
      "742/742 [==============================] - 0s 48us/step - loss: 2.2541e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 976/1500\n",
      "742/742 [==============================] - 0s 40us/step - loss: 2.2332e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 977/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 2.2267e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 978/1500\n",
      "742/742 [==============================] - 0s 66us/step - loss: 2.2034e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 979/1500\n",
      "742/742 [==============================] - 0s 31us/step - loss: 2.2002e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 980/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 2.1954e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 981/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 2.1729e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 982/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 2.1673e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 983/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 2.1472e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 984/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 2.1328e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 985/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 2.1352e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 986/1500\n",
      "742/742 [==============================] - 0s 55us/step - loss: 2.1087e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 987/1500\n",
      "742/742 [==============================] - 0s 59us/step - loss: 2.0902e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 988/1500\n",
      "742/742 [==============================] - 0s 55us/step - loss: 2.0974e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 989/1500\n",
      "742/742 [==============================] - 0s 39us/step - loss: 2.0838e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 990/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 2.0685e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 991/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 2.0492e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 992/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 2.0701e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 993/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 2.0460e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 994/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 2.0340e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 995/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 2.0315e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 996/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 1.9922e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 997/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 1.9850e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 998/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 1.9809e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 999/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.9689e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1000/1500\n",
      "742/742 [==============================] - 0s 61us/step - loss: 1.9705e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1001/1500\n",
      "742/742 [==============================] - 0s 57us/step - loss: 1.9528e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1002/1500\n",
      "742/742 [==============================] - 0s 54us/step - loss: 1.9424e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1003/1500\n",
      "742/742 [==============================] - 0s 50us/step - loss: 1.9102e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1004/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 1.9504e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1005/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 1.8926e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1006/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 1.9512e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1007/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 1.9263e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1008/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 1.8797e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1009/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.8516e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1010/1500\n",
      "742/742 [==============================] - 0s 109us/step - loss: 1.8404e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1011/1500\n",
      "742/742 [==============================] - 0s 93us/step - loss: 1.8460e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1012/1500\n",
      "742/742 [==============================] - 0s 96us/step - loss: 1.8371e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1013/1500\n",
      "742/742 [==============================] - 0s 84us/step - loss: 1.8307e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1014/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.8259e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1015/1500\n",
      "742/742 [==============================] - 0s 108us/step - loss: 1.8114e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1016/1500\n",
      "742/742 [==============================] - 0s 96us/step - loss: 1.8155e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1017/1500\n",
      "742/742 [==============================] - 0s 85us/step - loss: 1.8187e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1018/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.8042e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1019/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.7897e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1020/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.8187e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1021/1500\n",
      "742/742 [==============================] - 0s 35us/step - loss: 1.7801e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1022/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.7648e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1023/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 1.7697e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1024/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 1.7456e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1025/1500\n",
      "742/742 [==============================] - 0s 42us/step - loss: 1.7287e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1026/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.7255e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1027/1500\n",
      "742/742 [==============================] - 0s 65us/step - loss: 1.7319e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1028/1500\n",
      "742/742 [==============================] - 0s 59us/step - loss: 1.7183e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1029/1500\n",
      "742/742 [==============================] - 0s 62us/step - loss: 1.7166e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1030/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.7086e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1031/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 1.6958e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1032/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.6958e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1033/1500\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.6885e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1034/1500\n",
      "742/742 [==============================] - 0s 65us/step - loss: 1.6901e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1035/1500\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.6901e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1036/1500\n",
      "742/742 [==============================] - 0s 65us/step - loss: 1.6717e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1037/1500\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.6733e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1038/1500\n",
      "742/742 [==============================] - 0s 62us/step - loss: 1.6660e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1039/1500\n",
      "742/742 [==============================] - 0s 110us/step - loss: 1.6652e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1040/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.6660e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1041/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.6476e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1042/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.6572e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1043/1500\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.6435e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1044/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.6419e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1045/1500\n",
      "742/742 [==============================] - 0s 81us/step - loss: 1.6251e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1046/1500\n",
      "742/742 [==============================] - 0s 98us/step - loss: 1.6235e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1047/1500\n",
      "742/742 [==============================] - 0s 85us/step - loss: 1.6106e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1048/1500\n",
      "742/742 [==============================] - 0s 82us/step - loss: 1.5994e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1049/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.6138e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1050/1500\n",
      "742/742 [==============================] - 0s 79us/step - loss: 1.6122e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1051/1500\n",
      "742/742 [==============================] - 0s 79us/step - loss: 1.6050e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1052/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.5986e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1053/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.5825e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1054/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.5889e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1055/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.5986e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1056/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 1.5713e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1057/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.5696e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1058/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.5664e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1059/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.5632e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1060/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.5600e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1061/1500\n",
      "742/742 [==============================] - 0s 82us/step - loss: 1.5576e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1062/1500\n",
      "742/742 [==============================] - 0s 104us/step - loss: 1.5552e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1063/1500\n",
      "742/742 [==============================] - 0s 106us/step - loss: 1.5520e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1064/1500\n",
      "742/742 [==============================] - 0s 112us/step - loss: 1.5680e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1065/1500\n",
      "742/742 [==============================] - 0s 94us/step - loss: 1.5455e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1066/1500\n",
      "742/742 [==============================] - 0s 97us/step - loss: 1.5351e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1067/1500\n",
      "742/742 [==============================] - 0s 102us/step - loss: 1.5383e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1068/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.5287e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1069/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.5247e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1070/1500\n",
      "742/742 [==============================] - 0s 79us/step - loss: 1.5198e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1071/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.5247e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1072/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.5102e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1073/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.5182e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1074/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.5094e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1075/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.5030e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1076/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.5054e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1077/1500\n",
      "742/742 [==============================] - 0s 116us/step - loss: 1.5038e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1078/1500\n",
      "742/742 [==============================] - 0s 124us/step - loss: 1.4973e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1079/1500\n",
      "742/742 [==============================] - 0s 82us/step - loss: 1.4973e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1080/1500\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.4885e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1081/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.4933e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1082/1500\n",
      "742/742 [==============================] - 0s 88us/step - loss: 1.4813e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1083/1500\n",
      "742/742 [==============================] - 0s 79us/step - loss: 1.4789e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1084/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.4741e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1085/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.4684e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1086/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.4684e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1087/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.4716e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1088/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.4588e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1089/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.4596e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1090/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.4580e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1091/1500\n",
      "742/742 [==============================] - 0s 81us/step - loss: 1.4700e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1092/1500\n",
      "742/742 [==============================] - 0s 86us/step - loss: 1.4628e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1093/1500\n",
      "742/742 [==============================] - 0s 101us/step - loss: 1.4443e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1094/1500\n",
      "742/742 [==============================] - 0s 108us/step - loss: 1.4483e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1095/1500\n",
      "742/742 [==============================] - 0s 98us/step - loss: 1.4427e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1096/1500\n",
      "742/742 [==============================] - 0s 109us/step - loss: 1.4491e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1097/1500\n",
      "742/742 [==============================] - 0s 101us/step - loss: 1.4411e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1098/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.4355e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1099/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.4371e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1100/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.4315e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1101/1500\n",
      "742/742 [==============================] - 0s 109us/step - loss: 1.4291e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1102/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.4194e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1103/1500\n",
      "742/742 [==============================] - 0s 96us/step - loss: 1.4210e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1104/1500\n",
      "742/742 [==============================] - 0s 123us/step - loss: 1.4178e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1105/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.4154e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1106/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.4138e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1107/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.4162e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1108/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.4146e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1109/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.4074e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1110/1500\n",
      "742/742 [==============================] - 0s 105us/step - loss: 1.4154e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1111/1500\n",
      "742/742 [==============================] - 0s 100us/step - loss: 1.3881e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1112/1500\n",
      "742/742 [==============================] - 0s 109us/step - loss: 1.3993e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1113/1500\n",
      "742/742 [==============================] - 0s 104us/step - loss: 1.4042e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1114/1500\n",
      "742/742 [==============================] - 0s 86us/step - loss: 1.3929e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1115/1500\n",
      "742/742 [==============================] - 0s 111us/step - loss: 1.3921e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1116/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.3921e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1117/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.3873e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1118/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.3857e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1119/1500\n",
      "742/742 [==============================] - 0s 82us/step - loss: 1.3865e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1120/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.3865e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1121/1500\n",
      "742/742 [==============================] - 0s 79us/step - loss: 1.3833e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1122/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.3777e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1123/1500\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.3769e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1124/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.3785e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1125/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.3752e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1126/1500\n",
      "742/742 [==============================] - 0s 81us/step - loss: 1.3688e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1127/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.3696e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1128/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.3688e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1129/1500\n",
      "742/742 [==============================] - 0s 81us/step - loss: 1.3640e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1130/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.3648e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1131/1500\n",
      "742/742 [==============================] - 0s 84us/step - loss: 1.3664e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1132/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.3600e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1133/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.3624e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1134/1500\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.3552e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1135/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.3576e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1136/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.3528e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1137/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.3519e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1138/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.3568e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1139/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.3519e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1140/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.3503e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1141/1500\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.3503e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1142/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.3463e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1143/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.3447e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1144/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.3407e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1145/1500\n",
      "742/742 [==============================] - 0s 65us/step - loss: 1.3439e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1146/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.3423e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1147/1500\n",
      "742/742 [==============================] - 0s 79us/step - loss: 1.3399e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1148/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.3383e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1149/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.3407e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1150/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.3359e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1151/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.3327e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1152/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.3295e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1153/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.3303e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1154/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.3279e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1155/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.3262e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1156/1500\n",
      "742/742 [==============================] - 0s 82us/step - loss: 1.3287e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1157/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.3198e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1158/1500\n",
      "742/742 [==============================] - 0s 88us/step - loss: 1.3238e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1159/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.3222e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1160/1500\n",
      "742/742 [==============================] - 0s 82us/step - loss: 1.3198e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1161/1500\n",
      "742/742 [==============================] - 0s 82us/step - loss: 1.3238e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1162/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.3174e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1163/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.3158e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1164/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.3182e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1165/1500\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.3166e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1166/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.3086e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1167/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.3102e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1168/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.3102e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1169/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.3142e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1170/1500\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.3070e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1171/1500\n",
      "742/742 [==============================] - 0s 81us/step - loss: 1.3021e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1172/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.3046e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1173/1500\n",
      "742/742 [==============================] - 0s 81us/step - loss: 1.3021e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1174/1500\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.3021e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1175/1500\n",
      "742/742 [==============================] - 0s 92us/step - loss: 1.3021e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1176/1500\n",
      "742/742 [==============================] - 0s 81us/step - loss: 1.2981e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1177/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.3021e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1178/1500\n",
      "742/742 [==============================] - 0s 79us/step - loss: 1.2981e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1179/1500\n",
      "742/742 [==============================] - 0s 79us/step - loss: 1.2965e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1180/1500\n",
      "742/742 [==============================] - 0s 84us/step - loss: 1.2957e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1181/1500\n",
      "742/742 [==============================] - 0s 96us/step - loss: 1.2941e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1182/1500\n",
      "742/742 [==============================] - 0s 84us/step - loss: 1.2965e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1183/1500\n",
      "742/742 [==============================] - ETA: 0s - loss: 1.3039e-07 - acc: 1.000 - 0s 79us/step - loss: 1.2925e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1184/1500\n",
      "742/742 [==============================] - 0s 82us/step - loss: 1.2933e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1185/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.2909e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1186/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.2901e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1187/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.2893e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1188/1500\n",
      "742/742 [==============================] - 0s 82us/step - loss: 1.2917e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1189/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.2869e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1190/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.2869e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1191/1500\n",
      "742/742 [==============================] - 0s 79us/step - loss: 1.2829e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1192/1500\n",
      "742/742 [==============================] - 0s 82us/step - loss: 1.2861e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1193/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.2837e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1194/1500\n",
      "742/742 [==============================] - 0s 81us/step - loss: 1.2829e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1195/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.2821e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1196/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.2837e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1197/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.2813e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1198/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.2780e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1199/1500\n",
      "742/742 [==============================] - 0s 79us/step - loss: 1.2797e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1200/1500\n",
      "742/742 [==============================] - 0s 81us/step - loss: 1.2780e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1201/1500\n",
      "742/742 [==============================] - 0s 93us/step - loss: 1.2756e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1202/1500\n",
      "742/742 [==============================] - 0s 117us/step - loss: 1.2756e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1203/1500\n",
      "742/742 [==============================] - 0s 115us/step - loss: 1.2748e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1204/1500\n",
      "742/742 [==============================] - 0s 98us/step - loss: 1.2829e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1205/1500\n",
      "742/742 [==============================] - 0s 115us/step - loss: 1.2772e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1206/1500\n",
      "742/742 [==============================] - 0s 98us/step - loss: 1.2748e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1207/1500\n",
      "742/742 [==============================] - 0s 85us/step - loss: 1.2724e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1208/1500\n",
      "742/742 [==============================] - 0s 82us/step - loss: 1.2716e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1209/1500\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.2724e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1210/1500\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.2692e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1211/1500\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.2716e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1212/1500\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.2692e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1213/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.2676e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1214/1500\n",
      "742/742 [==============================] - 0s 84us/step - loss: 1.2716e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1215/1500\n",
      "742/742 [==============================] - 0s 105us/step - loss: 1.2644e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1216/1500\n",
      "742/742 [==============================] - 0s 97us/step - loss: 1.2676e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1217/1500\n",
      "742/742 [==============================] - 0s 101us/step - loss: 1.2660e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1218/1500\n",
      "742/742 [==============================] - 0s 98us/step - loss: 1.2644e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1219/1500\n",
      "742/742 [==============================] - 0s 84us/step - loss: 1.2620e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1220/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.2644e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1221/1500\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.2628e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1222/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.2604e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1223/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.2636e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1224/1500\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.2652e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1225/1500\n",
      "742/742 [==============================] - 0s 124us/step - loss: 1.2628e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1226/1500\n",
      "742/742 [==============================] - 0s 81us/step - loss: 1.2620e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1227/1500\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.2596e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1228/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 1.2580e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1229/1500\n",
      "742/742 [==============================] - 0s 79us/step - loss: 1.2596e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1230/1500\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.2564e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1231/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.2572e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1232/1500\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.2564e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1233/1500\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.2539e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1234/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 1.2539e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1235/1500\n",
      "742/742 [==============================] - 0s 63us/step - loss: 1.2539e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1236/1500\n",
      "742/742 [==============================] - 0s 65us/step - loss: 1.2548e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1237/1500\n",
      "742/742 [==============================] - 0s 98us/step - loss: 1.2564e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1238/1500\n",
      "742/742 [==============================] - 0s 97us/step - loss: 1.2523e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1239/1500\n",
      "742/742 [==============================] - 0s 98us/step - loss: 1.2564e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1240/1500\n",
      "742/742 [==============================] - 0s 96us/step - loss: 1.2523e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1241/1500\n",
      "742/742 [==============================] - 0s 84us/step - loss: 1.2507e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1242/1500\n",
      "742/742 [==============================] - 0s 96us/step - loss: 1.2491e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1243/1500\n",
      "742/742 [==============================] - 0s 101us/step - loss: 1.2499e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1244/1500\n",
      "742/742 [==============================] - 0s 102us/step - loss: 1.2483e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 1245/1500\n",
      "742/742 [==============================] - 0s 102us/step - loss: 1.2451e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 01245: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping  \n",
    "from decimal import ROUND_UP\n",
    "from keras import optimizers\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "rmsp=optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "adagrad=optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
    "adad=optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "adam=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "adamax=optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "nadam=optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "from keras.callbacks import EarlyStopping  \n",
    "from decimal import ROUND_UP\n",
    "max_features = X_train.shape[1]\n",
    "m = Sequential()\n",
    "m.add(Dense(29, input_shape=(dims,)))\n",
    "m.add(Activation('softmax'))\n",
    "m.add(Dense(20))\n",
    "m.add(Activation('relu'))\n",
    "m.add(Dense(10))\n",
    "m.add(Activation('softmax'))\n",
    "#m.add(Round())\n",
    "m.compile(loss='categorical_crossentropy', optimizer=adam,metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1, mode='auto')\n",
    "hist=m.fit(X_train_scaled,\n",
    "          Y_train,\n",
    "          batch_size=32,\n",
    "          epochs=1500, verbose=1,\n",
    "          validation_data=(X_test_scaled, Y_test),\n",
    "          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 742 samples, validate on 248 samples\n",
      "Epoch 1/3000\n",
      "742/742 [==============================] - 1s 690us/step - loss: 1.8306 - acc: 0.4232 - val_loss: 1.2290 - val_acc: 0.5242\n",
      "Epoch 2/3000\n",
      "742/742 [==============================] - 0s 76us/step - loss: 1.0550 - acc: 0.6914 - val_loss: 0.7463 - val_acc: 0.8831\n",
      "Epoch 3/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.6532 - acc: 0.8585 - val_loss: 0.5112 - val_acc: 0.8831\n",
      "Epoch 4/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.4581 - acc: 0.8585 - val_loss: 0.3738 - val_acc: 0.8831\n",
      "Epoch 5/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.3583 - acc: 0.8625 - val_loss: 0.3044 - val_acc: 0.9032\n",
      "Epoch 6/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.2850 - acc: 0.8854 - val_loss: 0.2451 - val_acc: 0.9315\n",
      "Epoch 7/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.2300 - acc: 0.9407 - val_loss: 0.1947 - val_acc: 0.9435\n",
      "Epoch 8/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.1866 - acc: 0.9501 - val_loss: 0.1662 - val_acc: 0.9718\n",
      "Epoch 9/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.1523 - acc: 0.9650 - val_loss: 0.1335 - val_acc: 0.9718\n",
      "Epoch 10/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.1267 - acc: 0.9704 - val_loss: 0.1141 - val_acc: 0.9798\n",
      "Epoch 11/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.1048 - acc: 0.9825 - val_loss: 0.0970 - val_acc: 0.9798\n",
      "Epoch 12/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 0.0910 - acc: 0.9825 - val_loss: 0.0846 - val_acc: 0.9798\n",
      "Epoch 13/3000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.0777 - acc: 0.9892 - val_loss: 0.0731 - val_acc: 0.9879\n",
      "Epoch 14/3000\n",
      "742/742 [==============================] - 0s 86us/step - loss: 0.0670 - acc: 0.9906 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 15/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0606 - acc: 0.9906 - val_loss: 0.0585 - val_acc: 0.9960\n",
      "Epoch 16/3000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 0.0517 - acc: 0.9933 - val_loss: 0.0518 - val_acc: 0.9960\n",
      "Epoch 17/3000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.0457 - acc: 0.9933 - val_loss: 0.0494 - val_acc: 0.9960\n",
      "Epoch 18/3000\n",
      "742/742 [==============================] - 0s 116us/step - loss: 0.0422 - acc: 0.9933 - val_loss: 0.0424 - val_acc: 0.9960\n",
      "Epoch 19/3000\n",
      "742/742 [==============================] - 0s 101us/step - loss: 0.0382 - acc: 0.9933 - val_loss: 0.0390 - val_acc: 0.9960\n",
      "Epoch 20/3000\n",
      "742/742 [==============================] - 0s 100us/step - loss: 0.0346 - acc: 0.9946 - val_loss: 0.0357 - val_acc: 0.9960\n",
      "Epoch 21/3000\n",
      "742/742 [==============================] - 0s 109us/step - loss: 0.0321 - acc: 0.9933 - val_loss: 0.0327 - val_acc: 0.9960\n",
      "Epoch 22/3000\n",
      "742/742 [==============================] - 0s 98us/step - loss: 0.0282 - acc: 0.9946 - val_loss: 0.0309 - val_acc: 0.9960\n",
      "Epoch 23/3000\n",
      "742/742 [==============================] - 0s 115us/step - loss: 0.0259 - acc: 0.9933 - val_loss: 0.0320 - val_acc: 0.9960\n",
      "Epoch 24/3000\n",
      "742/742 [==============================] - 0s 106us/step - loss: 0.0247 - acc: 0.9960 - val_loss: 0.0263 - val_acc: 0.9960\n",
      "Epoch 25/3000\n",
      "742/742 [==============================] - 0s 101us/step - loss: 0.0219 - acc: 0.9960 - val_loss: 0.0254 - val_acc: 0.9960\n",
      "Epoch 26/3000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 0.0210 - acc: 0.9960 - val_loss: 0.0237 - val_acc: 0.9960\n",
      "Epoch 27/3000\n",
      "742/742 [==============================] - 0s 105us/step - loss: 0.0187 - acc: 0.9973 - val_loss: 0.0211 - val_acc: 0.9960\n",
      "Epoch 28/3000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.0176 - acc: 0.9973 - val_loss: 0.0200 - val_acc: 0.9960\n",
      "Epoch 29/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.0160 - acc: 0.9973 - val_loss: 0.0201 - val_acc: 0.9960\n",
      "Epoch 30/3000\n",
      "742/742 [==============================] - 0s 101us/step - loss: 0.0150 - acc: 0.9973 - val_loss: 0.0181 - val_acc: 0.9960\n",
      "Epoch 31/3000\n",
      "742/742 [==============================] - 0s 102us/step - loss: 0.0145 - acc: 0.9973 - val_loss: 0.0175 - val_acc: 0.9960\n",
      "Epoch 32/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0132 - acc: 0.9973 - val_loss: 0.0157 - val_acc: 0.9960\n",
      "Epoch 33/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.0125 - acc: 0.9973 - val_loss: 0.0153 - val_acc: 0.9960\n",
      "Epoch 34/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 0.0114 - acc: 0.9987 - val_loss: 0.0143 - val_acc: 0.9960\n",
      "Epoch 35/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0109 - acc: 0.9987 - val_loss: 0.0136 - val_acc: 0.9960\n",
      "Epoch 36/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0102 - acc: 0.9987 - val_loss: 0.0132 - val_acc: 0.9960\n",
      "Epoch 37/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 0.9960\n",
      "Epoch 38/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0094 - acc: 0.9987 - val_loss: 0.0129 - val_acc: 1.0000\n",
      "Epoch 39/3000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 0.9960\n",
      "Epoch 40/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.0109 - val_acc: 1.0000\n",
      "Epoch 41/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 42/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 1.0000\n",
      "Epoch 43/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 1.0000\n",
      "Epoch 44/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 1.0000\n",
      "Epoch 45/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 1.0000\n",
      "Epoch 46/3000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 1.0000\n",
      "Epoch 47/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 1.0000\n",
      "Epoch 48/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 1.0000\n",
      "Epoch 49/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 1.0000\n",
      "Epoch 50/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
      "Epoch 51/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "Epoch 52/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 1.0000\n",
      "Epoch 53/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "Epoch 54/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "Epoch 55/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 1.0000\n",
      "Epoch 56/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 1.0000\n",
      "Epoch 57/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 1.0000\n",
      "Epoch 58/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 1.0000\n",
      "Epoch 59/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 1.0000\n",
      "Epoch 60/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "Epoch 62/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 63/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 64/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 65/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 66/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 67/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 68/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 1.0000\n",
      "Epoch 69/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 70/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 71/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 72/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 1.0000\n",
      "Epoch 73/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 74/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 75/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 76/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 77/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "Epoch 78/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 79/3000\n",
      "742/742 [==============================] - 0s 61us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 80/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 81/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 82/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 83/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 84/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 85/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 86/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 87/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 88/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 89/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 90/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 91/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 92/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 93/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 94/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 95/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 96/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 97/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 98/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 99/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 100/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 101/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 102/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 103/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 104/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 105/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 106/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 107/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 108/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 109/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 110/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 111/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 112/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 113/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 114/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 115/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 116/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 117/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 118/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 119/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 120/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 121/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 71us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 122/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 123/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 124/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 125/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 126/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 127/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 128/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 129/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 130/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 131/3000\n",
      "742/742 [==============================] - 0s 61us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 132/3000\n",
      "742/742 [==============================] - 0s 59us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 133/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 134/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 135/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 136/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 137/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 138/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 139/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 140/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 141/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 142/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 143/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 144/3000\n",
      "742/742 [==============================] - 0s 85us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 145/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 146/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 9.9520e-04 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 147/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 9.8441e-04 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 148/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 9.9263e-04 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 149/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 9.7640e-04 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 150/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 9.5423e-04 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 151/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 9.5057e-04 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 152/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 9.3972e-04 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 153/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 9.3112e-04 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 154/3000\n",
      "742/742 [==============================] - 0s 105us/step - loss: 9.2728e-04 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 155/3000\n",
      "742/742 [==============================] - 0s 85us/step - loss: 9.1866e-04 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 156/3000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 9.0961e-04 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 157/3000\n",
      "742/742 [==============================] - 0s 98us/step - loss: 9.0069e-04 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 158/3000\n",
      "742/742 [==============================] - 0s 104us/step - loss: 8.9209e-04 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 159/3000\n",
      "742/742 [==============================] - 0s 110us/step - loss: 8.8375e-04 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 160/3000\n",
      "742/742 [==============================] - 0s 115us/step - loss: 8.7801e-04 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 161/3000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 8.7105e-04 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 162/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 8.6409e-04 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 163/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 8.5759e-04 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 164/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 8.4908e-04 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 165/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 8.4086e-04 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 166/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 8.3492e-04 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 167/3000\n",
      "742/742 [==============================] - 0s 101us/step - loss: 8.3250e-04 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 168/3000\n",
      "742/742 [==============================] - 0s 109us/step - loss: 8.2780e-04 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 169/3000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 8.1612e-04 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 170/3000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 8.1113e-04 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 171/3000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 8.0330e-04 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 172/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 7.9547e-04 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 173/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 7.9207e-04 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 174/3000\n",
      "742/742 [==============================] - 0s 98us/step - loss: 7.8602e-04 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 175/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 7.8316e-04 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 176/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 7.7454e-04 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 177/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 7.6623e-04 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 178/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 7.6349e-04 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 179/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 7.5650e-04 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 7.4978e-04 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 181/3000\n",
      "742/742 [==============================] - 0s 108us/step - loss: 7.4501e-04 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 182/3000\n",
      "742/742 [==============================] - 0s 116us/step - loss: 7.3919e-04 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 183/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 7.3613e-04 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 184/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 7.3026e-04 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 0.9960\n",
      "Epoch 185/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 7.2820e-04 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 0.9960\n",
      "Epoch 186/3000\n",
      "742/742 [==============================] - 0s 64us/step - loss: 7.2413e-04 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 0.9960\n",
      "Epoch 187/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 7.2071e-04 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 0.9960\n",
      "Epoch 188/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 7.1856e-04 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 0.9960\n",
      "Epoch 189/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 7.0701e-04 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 0.9960\n",
      "Epoch 190/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 6.9964e-04 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 191/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 6.9527e-04 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 192/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 6.8726e-04 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 193/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 6.8360e-04 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 194/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 6.7814e-04 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 195/3000\n",
      "742/742 [==============================] - 0s 104us/step - loss: 6.7165e-04 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 196/3000\n",
      "742/742 [==============================] - 0s 86us/step - loss: 6.6785e-04 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 197/3000\n",
      "742/742 [==============================] - 0s 85us/step - loss: 6.6461e-04 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 198/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 6.5843e-04 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 199/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 6.5489e-04 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 200/3000\n",
      "742/742 [==============================] - 0s 97us/step - loss: 6.5135e-04 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 201/3000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 6.4566e-04 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 202/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 6.4253e-04 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 203/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 6.3753e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 204/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 6.3302e-04 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 205/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 6.2971e-04 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 206/3000\n",
      "742/742 [==============================] - 0s 49us/step - loss: 6.2576e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 207/3000\n",
      "742/742 [==============================] - 0s 42us/step - loss: 6.2209e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 208/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 6.1778e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 209/3000\n",
      "742/742 [==============================] - 0s 42us/step - loss: 6.1744e-04 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 210/3000\n",
      "742/742 [==============================] - 0s 59us/step - loss: 6.1284e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 211/3000\n",
      "742/742 [==============================] - 0s 98us/step - loss: 6.0709e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 212/3000\n",
      "742/742 [==============================] - 0s 112us/step - loss: 6.0538e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 213/3000\n",
      "742/742 [==============================] - 0s 86us/step - loss: 6.0007e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 214/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 5.9502e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 215/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 5.9099e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 216/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 5.8900e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 217/3000\n",
      "742/742 [==============================] - 0s 51us/step - loss: 5.8528e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 218/3000\n",
      "742/742 [==============================] - 0s 42us/step - loss: 5.8154e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 219/3000\n",
      "742/742 [==============================] - 0s 50us/step - loss: 5.7744e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 220/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 5.7429e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 221/3000\n",
      "742/742 [==============================] - ETA: 0s - loss: 3.7264e-04 - acc: 1.000 - 0s 61us/step - loss: 5.7099e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 222/3000\n",
      "742/742 [==============================] - 0s 76us/step - loss: 5.6906e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 223/3000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 5.6479e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 224/3000\n",
      "742/742 [==============================] - 0s 98us/step - loss: 5.6241e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 225/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 5.5800e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 226/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 5.5665e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 227/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 5.5352e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 228/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 5.4984e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 229/3000\n",
      "742/742 [==============================] - 0s 57us/step - loss: 5.4567e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 230/3000\n",
      "742/742 [==============================] - 0s 62us/step - loss: 5.4203e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 231/3000\n",
      "742/742 [==============================] - 0s 50us/step - loss: 5.3908e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 232/3000\n",
      "742/742 [==============================] - 0s 35us/step - loss: 5.3678e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 233/3000\n",
      "742/742 [==============================] - 0s 42us/step - loss: 5.3406e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 234/3000\n",
      "742/742 [==============================] - 0s 42us/step - loss: 5.3106e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 235/3000\n",
      "742/742 [==============================] - 0s 51us/step - loss: 5.2760e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 236/3000\n",
      "742/742 [==============================] - 0s 38us/step - loss: 5.2562e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 237/3000\n",
      "742/742 [==============================] - 0s 58us/step - loss: 5.2183e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/3000\n",
      "742/742 [==============================] - 0s 72us/step - loss: 5.1960e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 239/3000\n",
      "742/742 [==============================] - 0s 50us/step - loss: 5.1653e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 240/3000\n",
      "742/742 [==============================] - 0s 42us/step - loss: 5.1610e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 241/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 5.1079e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 242/3000\n",
      "742/742 [==============================] - 0s 42us/step - loss: 5.0873e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 243/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 5.0611e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 244/3000\n",
      "742/742 [==============================] - 0s 42us/step - loss: 5.0310e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 245/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 5.0288e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 246/3000\n",
      "742/742 [==============================] - 0s 42us/step - loss: 4.9860e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 247/3000\n",
      "742/742 [==============================] - 0s 42us/step - loss: 4.9703e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 248/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 4.9294e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 249/3000\n",
      "742/742 [==============================] - 0s 42us/step - loss: 4.9146e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 250/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 4.8762e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 251/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 4.8570e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 252/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 4.8290e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 253/3000\n",
      "742/742 [==============================] - 0s 42us/step - loss: 4.8035e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 254/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 4.7869e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 255/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 4.7681e-04 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 256/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 4.7356e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 257/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 4.7097e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 258/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 4.6851e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 259/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 4.6684e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 260/3000\n",
      "742/742 [==============================] - 0s 55us/step - loss: 4.6367e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 261/3000\n",
      "742/742 [==============================] - 0s 42us/step - loss: 4.6227e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 262/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 4.5995e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 263/3000\n",
      "742/742 [==============================] - 0s 42us/step - loss: 4.5699e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 264/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 4.5602e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 265/3000\n",
      "742/742 [==============================] - 0s 42us/step - loss: 4.5343e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 266/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 4.5030e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 267/3000\n",
      "742/742 [==============================] - 0s 42us/step - loss: 4.4929e-04 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 268/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 4.4706e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 269/3000\n",
      "742/742 [==============================] - 0s 42us/step - loss: 4.4436e-04 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 270/3000\n",
      "742/742 [==============================] - 0s 76us/step - loss: 4.4259e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 271/3000\n",
      "742/742 [==============================] - 0s 28us/step - loss: 4.4030e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 272/3000\n",
      "742/742 [==============================] - 0s 42us/step - loss: 4.3904e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 273/3000\n",
      "742/742 [==============================] - 0s 42us/step - loss: 4.3605e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 274/3000\n",
      "742/742 [==============================] - ETA: 0s - loss: 1.9994e-04 - acc: 1.000 - 0s 29us/step - loss: 4.3413e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 275/3000\n",
      "742/742 [==============================] - 0s 42us/step - loss: 4.3183e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 00275: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping  \n",
    "from decimal import ROUND_UP\n",
    "from keras import optimizers\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "rmsp=optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "adagrad=optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
    "adad=optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "adam=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "adamax=optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "nadam=optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "from keras.callbacks import EarlyStopping  \n",
    "from decimal import ROUND_UP\n",
    "max_features = X_train.shape[1]\n",
    "m = Sequential()\n",
    "m.add(Dense(39, input_shape=(dims,)))\n",
    "m.add(Activation('elu'))\n",
    "m.add(Dense(25))\n",
    "m.add(Activation('relu'))\n",
    "m.add(Dense(10))\n",
    "m.add(Activation('softmax'))\n",
    "#m.add(Round())\n",
    "m.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1, mode='auto')\n",
    "hist2=m.fit(X_train_scaled,\n",
    "          Y_train,\n",
    "          batch_size=32,\n",
    "          epochs=3000, verbose=1,\n",
    "          validation_data=(X_test_scaled, Y_test),\n",
    "          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 742 samples, validate on 248 samples\n",
      "Epoch 1/3000\n",
      "742/742 [==============================] - 1s 763us/step - loss: 1.8370 - acc: 0.4744 - val_loss: 1.4657 - val_acc: 0.5282\n",
      "Epoch 2/3000\n",
      "742/742 [==============================] - 0s 98us/step - loss: 1.3816 - acc: 0.4744 - val_loss: 1.1557 - val_acc: 0.5282\n",
      "Epoch 3/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.1427 - acc: 0.4879 - val_loss: 0.9883 - val_acc: 0.5444\n",
      "Epoch 4/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.9850 - acc: 0.5458 - val_loss: 0.8740 - val_acc: 0.5605\n",
      "Epoch 5/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.8783 - acc: 0.6631 - val_loss: 0.7975 - val_acc: 0.7097\n",
      "Epoch 6/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.7888 - acc: 0.8086 - val_loss: 0.7112 - val_acc: 0.8185\n",
      "Epoch 7/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.6988 - acc: 0.8544 - val_loss: 0.6332 - val_acc: 0.8629\n",
      "Epoch 8/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 0.6188 - acc: 0.8693 - val_loss: 0.5579 - val_acc: 0.8790\n",
      "Epoch 9/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 0.5368 - acc: 0.8720 - val_loss: 0.4853 - val_acc: 0.8871\n",
      "Epoch 10/3000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 0.4593 - acc: 0.8760 - val_loss: 0.4530 - val_acc: 0.9234\n",
      "Epoch 11/3000\n",
      "742/742 [==============================] - 0s 97us/step - loss: 0.3955 - acc: 0.8949 - val_loss: 0.3742 - val_acc: 0.9194\n",
      "Epoch 12/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.3385 - acc: 0.9016 - val_loss: 0.3214 - val_acc: 0.9234\n",
      "Epoch 13/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.2870 - acc: 0.9205 - val_loss: 0.2826 - val_acc: 0.8952\n",
      "Epoch 14/3000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 0.2448 - acc: 0.9137 - val_loss: 0.2380 - val_acc: 0.9234\n",
      "Epoch 15/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.2117 - acc: 0.9299 - val_loss: 0.2484 - val_acc: 0.9919\n",
      "Epoch 16/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.1834 - acc: 0.9501 - val_loss: 0.1889 - val_acc: 0.9194\n",
      "Epoch 17/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 0.1557 - acc: 0.9474 - val_loss: 0.1902 - val_acc: 0.9960\n",
      "Epoch 18/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.1335 - acc: 0.9784 - val_loss: 0.1467 - val_acc: 0.9677\n",
      "Epoch 19/3000\n",
      "742/742 [==============================] - 0s 85us/step - loss: 0.1118 - acc: 0.9838 - val_loss: 0.1369 - val_acc: 0.9879\n",
      "Epoch 20/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 0.0929 - acc: 0.9865 - val_loss: 0.1401 - val_acc: 0.9960\n",
      "Epoch 21/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 0.0776 - acc: 0.9933 - val_loss: 0.1181 - val_acc: 0.9839\n",
      "Epoch 22/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 0.0641 - acc: 0.9919 - val_loss: 0.1275 - val_acc: 0.9960\n",
      "Epoch 23/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.0543 - acc: 0.9946 - val_loss: 0.1094 - val_acc: 0.9879\n",
      "Epoch 24/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0442 - acc: 0.9960 - val_loss: 0.1070 - val_acc: 0.9919\n",
      "Epoch 25/3000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.0367 - acc: 0.9960 - val_loss: 0.1012 - val_acc: 0.9919\n",
      "Epoch 26/3000\n",
      "742/742 [==============================] - 0s 108us/step - loss: 0.0306 - acc: 0.9960 - val_loss: 0.0939 - val_acc: 0.9919\n",
      "Epoch 27/3000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.0250 - acc: 0.9987 - val_loss: 0.0881 - val_acc: 0.9919\n",
      "Epoch 28/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0207 - acc: 0.9973 - val_loss: 0.0855 - val_acc: 0.9960\n",
      "Epoch 29/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0169 - acc: 0.9987 - val_loss: 0.0814 - val_acc: 0.9919\n",
      "Epoch 30/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0144 - acc: 0.9987 - val_loss: 0.0784 - val_acc: 0.9960\n",
      "Epoch 31/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.0762 - val_acc: 0.9919\n",
      "Epoch 32/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.0769 - val_acc: 0.9960\n",
      "Epoch 33/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.0730 - val_acc: 0.9960\n",
      "Epoch 34/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0742 - val_acc: 0.9960\n",
      "Epoch 35/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0703 - val_acc: 0.9960\n",
      "Epoch 36/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0703 - val_acc: 0.9960\n",
      "Epoch 37/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0691 - val_acc: 0.9960\n",
      "Epoch 38/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0684 - val_acc: 0.9960\n",
      "Epoch 39/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0678 - val_acc: 0.9960\n",
      "Epoch 40/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0678 - val_acc: 0.9960\n",
      "Epoch 41/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0669 - val_acc: 0.9960\n",
      "Epoch 42/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0667 - val_acc: 0.9960\n",
      "Epoch 43/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0663 - val_acc: 0.9960\n",
      "Epoch 44/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0663 - val_acc: 0.9960\n",
      "Epoch 45/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0672 - val_acc: 0.9960\n",
      "Epoch 46/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 9.3988e-04 - acc: 1.0000 - val_loss: 0.0658 - val_acc: 0.9960\n",
      "Epoch 47/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 7.0098e-04 - acc: 1.0000 - val_loss: 0.0657 - val_acc: 0.9960\n",
      "Epoch 48/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 6.1048e-04 - acc: 1.0000 - val_loss: 0.0656 - val_acc: 0.9960\n",
      "Epoch 49/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 5.1024e-04 - acc: 1.0000 - val_loss: 0.0655 - val_acc: 0.9960\n",
      "Epoch 50/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 4.0746e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 51/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 3.6913e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 52/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 2.9979e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 53/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 2.5272e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9960\n",
      "Epoch 54/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.9832e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 55/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.8581e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9960\n",
      "Epoch 56/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.3593e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 57/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.1523e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 58/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.0620e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 59/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 7.6170e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 60/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 7.3303e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 61/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 8.7257e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 62/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 5.1777e-05 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9960\n",
      "Epoch 63/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 4.3762e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 64/3000\n",
      "742/742 [==============================] - 0s 60us/step - loss: 4.1097e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 65/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 3.3241e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 66/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 2.5573e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 67/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 2.2609e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 68/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 2.1262e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 69/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.6016e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 70/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.4066e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 71/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.1658e-05 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 72/3000\n",
      "742/742 [==============================] - 0s 100us/step - loss: 9.0642e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 73/3000\n",
      "742/742 [==============================] - 0s 112us/step - loss: 9.0072e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 74/3000\n",
      "742/742 [==============================] - 0s 110us/step - loss: 6.6160e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 75/3000\n",
      "742/742 [==============================] - 0s 120us/step - loss: 9.9470e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 76/3000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 4.5995e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 77/3000\n",
      "742/742 [==============================] - 0s 116us/step - loss: 5.7130e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 78/3000\n",
      "742/742 [==============================] - 0s 86us/step - loss: 4.3851e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 79/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 3.3519e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 80/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 4.4656e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 81/3000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 2.5615e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 82/3000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 2.6080e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 83/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 2.4864e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 84/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 1.6902e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 85/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.6322e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 86/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.7230e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 87/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.1276e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 88/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.1520e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 89/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 9.0181e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 90/3000\n",
      "742/742 [==============================] - 0s 115us/step - loss: 7.6975e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 91/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 1.3794e-06 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 92/3000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 5.9807e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 93/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 5.9494e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 94/3000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 5.4513e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 95/3000\n",
      "742/742 [==============================] - 0s 98us/step - loss: 5.7647e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 96/3000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 4.7693e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 97/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 4.0446e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 98/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 5.2612e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 99/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 3.4052e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 100/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 3.5611e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 101/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 2.9047e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 102/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 3.0493e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 103/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 2.7931e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 104/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 3.0896e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 105/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 2.2436e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 106/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 2.4653e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 107/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 2.2733e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 108/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 2.0589e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 109/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 2.2500e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 110/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.9456e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 111/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.9906e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 112/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.7889e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 113/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.6757e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 114/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.7287e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 115/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.7584e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 116/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.5785e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 117/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.8002e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 118/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 71us/step - loss: 1.5439e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 119/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.5672e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 120/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.5431e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 121/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.5737e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 122/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 1.5094e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 123/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.4644e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 124/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 1.4395e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 125/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.4596e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 126/3000\n",
      "742/742 [==============================] - 0s 76us/step - loss: 1.4250e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 127/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.4090e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 128/3000\n",
      "742/742 [==============================] - 0s 83us/step - loss: 1.3592e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 129/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.3600e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 130/3000\n",
      "742/742 [==============================] - 0s 98us/step - loss: 1.3479e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 131/3000\n",
      "742/742 [==============================] - 0s 112us/step - loss: 1.3544e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 132/3000\n",
      "742/742 [==============================] - 0s 109us/step - loss: 1.3351e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 133/3000\n",
      "742/742 [==============================] - 0s 86us/step - loss: 1.3383e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 134/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 1.3166e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 135/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 1.3182e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 136/3000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 1.2909e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 137/3000\n",
      "742/742 [==============================] - 0s 85us/step - loss: 1.2901e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 138/3000\n",
      "742/742 [==============================] - 0s 108us/step - loss: 1.2740e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 139/3000\n",
      "742/742 [==============================] - 0s 97us/step - loss: 1.2764e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 140/3000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.2788e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 141/3000\n",
      "742/742 [==============================] - 0s 100us/step - loss: 1.2596e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 142/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.2676e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 143/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.2684e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 144/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.2628e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 145/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 1.2612e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 146/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.2491e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 147/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 1.2580e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 148/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 1.2459e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 149/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 1.2491e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 150/3000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 1.2491e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 151/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 1.2403e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 152/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.2379e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 153/3000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 1.2339e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 154/3000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 1.2298e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 155/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 1.2258e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 156/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.2315e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 157/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.2323e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 158/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 1.2258e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 159/3000\n",
      "742/742 [==============================] - 0s 121us/step - loss: 1.2274e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 160/3000\n",
      "742/742 [==============================] - 0s 115us/step - loss: 1.2210e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 161/3000\n",
      "742/742 [==============================] - 0s 102us/step - loss: 1.2266e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 162/3000\n",
      "742/742 [==============================] - 0s 101us/step - loss: 1.2218e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 163/3000\n",
      "742/742 [==============================] - 0s 127us/step - loss: 1.2218e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 164/3000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 1.2210e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 165/3000\n",
      "742/742 [==============================] - 0s 116us/step - loss: 1.2210e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 166/3000\n",
      "742/742 [==============================] - 0s 101us/step - loss: 1.2186e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 167/3000\n",
      "742/742 [==============================] - 0s 105us/step - loss: 1.2202e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 168/3000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 1.2122e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 169/3000\n",
      "742/742 [==============================] - 0s 100us/step - loss: 1.2186e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 170/3000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 1.2178e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 171/3000\n",
      "742/742 [==============================] - 0s 101us/step - loss: 1.2138e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 172/3000\n",
      "742/742 [==============================] - 0s 112us/step - loss: 1.2106e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 173/3000\n",
      "742/742 [==============================] - 0s 97us/step - loss: 1.2146e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 174/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.2122e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 175/3000\n",
      "742/742 [==============================] - 0s 97us/step - loss: 1.2122e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 176/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 74us/step - loss: 1.2122e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 177/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.2122e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 178/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.2130e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 179/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.2082e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 180/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.2090e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 181/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.2090e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 182/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.2082e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 183/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.2066e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 184/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 1.2074e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 185/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.2049e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 186/3000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 1.2074e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 187/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.2066e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 188/3000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 1.2098e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 189/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.2057e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 190/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 1.2025e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 191/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.2025e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 192/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.2049e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 193/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.2041e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 194/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 1.2041e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 195/3000\n",
      "742/742 [==============================] - 0s 98us/step - loss: 1.2033e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 196/3000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 1.2033e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 197/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 1.2025e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 198/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 1.2025e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 199/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 1.2017e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 200/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 1.2009e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 201/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 1.2025e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 202/3000\n",
      "742/742 [==============================] - 0s 124us/step - loss: 1.2017e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 203/3000\n",
      "742/742 [==============================] - 0s 112us/step - loss: 1.2001e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 204/3000\n",
      "742/742 [==============================] - 0s 124us/step - loss: 1.2017e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 205/3000\n",
      "742/742 [==============================] - 0s 108us/step - loss: 1.2025e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 206/3000\n",
      "742/742 [==============================] - 0s 102us/step - loss: 1.2017e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 207/3000\n",
      "742/742 [==============================] - 0s 104us/step - loss: 1.2009e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 208/3000\n",
      "742/742 [==============================] - 0s 123us/step - loss: 1.2009e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 209/3000\n",
      "742/742 [==============================] - 0s 102us/step - loss: 1.2001e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 210/3000\n",
      "742/742 [==============================] - 0s 112us/step - loss: 1.2001e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 211/3000\n",
      "742/742 [==============================] - 0s 105us/step - loss: 1.2009e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 212/3000\n",
      "742/742 [==============================] - 0s 109us/step - loss: 1.2009e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 213/3000\n",
      "742/742 [==============================] - 0s 98us/step - loss: 1.2001e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 214/3000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 1.2009e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 215/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 1.2001e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 216/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.2001e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 217/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 1.1993e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 218/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 1.2001e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 219/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 1.1985e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 220/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.1985e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 221/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 1.2001e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 222/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.1985e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 223/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 1.1993e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 224/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.1985e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 225/3000\n",
      "742/742 [==============================] - 0s 86us/step - loss: 1.1993e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 226/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 1.2001e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 227/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.1985e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 228/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.1977e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 229/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 1.1985e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 230/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 1.1993e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 231/3000\n",
      "742/742 [==============================] - 0s 86us/step - loss: 1.1985e-07 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9960\n",
      "Epoch 00231: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping  \n",
    "from decimal import ROUND_UP\n",
    "from keras import optimizers\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "rmsp=optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "adagrad=optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
    "adad=optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "adam=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "adamax=optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "nadam=optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "from keras.callbacks import EarlyStopping  \n",
    "from decimal import ROUND_UP\n",
    "max_features = X_train.shape[1]\n",
    "m = Sequential()\n",
    "m.add(Dense(39, input_shape=(dims,)))\n",
    "m.add(Activation('elu'))\n",
    "m.add(Dense(25))\n",
    "m.add(Activation('relu'))\n",
    "m.add(Dense(10))\n",
    "m.add(Activation('softmax'))\n",
    "#m.add(Round())\n",
    "m.compile(loss='categorical_crossentropy', optimizer=rmsp,metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1, mode='auto')\n",
    "hist3=m.fit(X_train_scaled,\n",
    "          Y_train,\n",
    "          batch_size=32,\n",
    "          epochs=3000, verbose=1,\n",
    "          validation_data=(X_test_scaled, Y_test),\n",
    "          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 742 samples, validate on 248 samples\n",
      "Epoch 1/3000\n",
      "742/742 [==============================] - 1s 996us/step - loss: 1.8216 - acc: 0.6644 - val_loss: 1.3782 - val_acc: 0.8790\n",
      "Epoch 2/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 1.2808 - acc: 0.8329 - val_loss: 1.0501 - val_acc: 0.8790\n",
      "Epoch 3/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.9998 - acc: 0.8598 - val_loss: 0.8219 - val_acc: 0.8790\n",
      "Epoch 4/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 0.7876 - acc: 0.8612 - val_loss: 0.6496 - val_acc: 0.8831\n",
      "Epoch 5/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.6106 - acc: 0.8625 - val_loss: 0.5268 - val_acc: 0.8831\n",
      "Epoch 6/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 0.5034 - acc: 0.8639 - val_loss: 0.4530 - val_acc: 0.8831\n",
      "Epoch 7/3000\n",
      "742/742 [==============================] - 0s 80us/step - loss: 0.4338 - acc: 0.8652 - val_loss: 0.4091 - val_acc: 0.8831\n",
      "Epoch 8/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.3885 - acc: 0.8679 - val_loss: 0.3702 - val_acc: 0.8831\n",
      "Epoch 9/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 0.3537 - acc: 0.8693 - val_loss: 0.3374 - val_acc: 0.8831\n",
      "Epoch 10/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.3276 - acc: 0.8693 - val_loss: 0.3163 - val_acc: 0.8831\n",
      "Epoch 11/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 0.3042 - acc: 0.8747 - val_loss: 0.2985 - val_acc: 0.8952\n",
      "Epoch 12/3000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 0.2845 - acc: 0.8895 - val_loss: 0.2884 - val_acc: 0.9234\n",
      "Epoch 13/3000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.2671 - acc: 0.9111 - val_loss: 0.2672 - val_acc: 0.9234\n",
      "Epoch 14/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 0.2507 - acc: 0.9151 - val_loss: 0.2509 - val_acc: 0.9194\n",
      "Epoch 15/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 0.2376 - acc: 0.9178 - val_loss: 0.2394 - val_acc: 0.9234\n",
      "Epoch 16/3000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.2249 - acc: 0.9205 - val_loss: 0.2274 - val_acc: 0.9234\n",
      "Epoch 17/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 0.2120 - acc: 0.9380 - val_loss: 0.2164 - val_acc: 0.9234\n",
      "Epoch 18/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 0.2007 - acc: 0.9313 - val_loss: 0.2044 - val_acc: 0.9274\n",
      "Epoch 19/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.1890 - acc: 0.9501 - val_loss: 0.1987 - val_acc: 0.9516\n",
      "Epoch 20/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 0.1786 - acc: 0.9515 - val_loss: 0.1884 - val_acc: 0.9556\n",
      "Epoch 21/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 0.1696 - acc: 0.9555 - val_loss: 0.1822 - val_acc: 0.9597\n",
      "Epoch 22/3000\n",
      "742/742 [==============================] - 0s 85us/step - loss: 0.1610 - acc: 0.9569 - val_loss: 0.1737 - val_acc: 0.9637\n",
      "Epoch 23/3000\n",
      "742/742 [==============================] - 0s 98us/step - loss: 0.1528 - acc: 0.9569 - val_loss: 0.1650 - val_acc: 0.9637\n",
      "Epoch 24/3000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.1448 - acc: 0.9636 - val_loss: 0.1569 - val_acc: 0.9597\n",
      "Epoch 25/3000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.1376 - acc: 0.9636 - val_loss: 0.1509 - val_acc: 0.9597\n",
      "Epoch 26/3000\n",
      "742/742 [==============================] - 0s 105us/step - loss: 0.1312 - acc: 0.9677 - val_loss: 0.1450 - val_acc: 0.9637\n",
      "Epoch 27/3000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 0.1249 - acc: 0.9690 - val_loss: 0.1396 - val_acc: 0.9637\n",
      "Epoch 28/3000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.1193 - acc: 0.9690 - val_loss: 0.1356 - val_acc: 0.9597\n",
      "Epoch 29/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 0.1140 - acc: 0.9690 - val_loss: 0.1304 - val_acc: 0.9677\n",
      "Epoch 30/3000\n",
      "742/742 [==============================] - 0s 100us/step - loss: 0.1095 - acc: 0.9677 - val_loss: 0.1268 - val_acc: 0.9718\n",
      "Epoch 31/3000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.1040 - acc: 0.9744 - val_loss: 0.1219 - val_acc: 0.9718\n",
      "Epoch 32/3000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.0993 - acc: 0.9744 - val_loss: 0.1191 - val_acc: 0.9758\n",
      "Epoch 33/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0944 - acc: 0.9784 - val_loss: 0.1136 - val_acc: 0.9718\n",
      "Epoch 34/3000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.0904 - acc: 0.9798 - val_loss: 0.1141 - val_acc: 0.9879\n",
      "Epoch 35/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0844 - acc: 0.9865 - val_loss: 0.1081 - val_acc: 0.9718\n",
      "Epoch 36/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.0831 - acc: 0.9811 - val_loss: 0.1043 - val_acc: 0.9718\n",
      "Epoch 37/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0792 - acc: 0.9852 - val_loss: 0.1017 - val_acc: 0.9798\n",
      "Epoch 38/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 0.0758 - acc: 0.9865 - val_loss: 0.0993 - val_acc: 0.9798\n",
      "Epoch 39/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0735 - acc: 0.9852 - val_loss: 0.0977 - val_acc: 0.9919\n",
      "Epoch 40/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0698 - acc: 0.9879 - val_loss: 0.0950 - val_acc: 0.9798\n",
      "Epoch 41/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0679 - acc: 0.9892 - val_loss: 0.0930 - val_acc: 0.9839\n",
      "Epoch 42/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.0659 - acc: 0.9879 - val_loss: 0.0912 - val_acc: 0.9879\n",
      "Epoch 43/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 0.0640 - acc: 0.9892 - val_loss: 0.0898 - val_acc: 0.9919\n",
      "Epoch 44/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0613 - acc: 0.9906 - val_loss: 0.0880 - val_acc: 0.9919\n",
      "Epoch 45/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0595 - acc: 0.9892 - val_loss: 0.0876 - val_acc: 0.9919\n",
      "Epoch 46/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.0577 - acc: 0.9906 - val_loss: 0.0852 - val_acc: 0.9919\n",
      "Epoch 47/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 0.0561 - acc: 0.9906 - val_loss: 0.0846 - val_acc: 0.9919\n",
      "Epoch 48/3000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 0.0537 - acc: 0.9919 - val_loss: 0.0828 - val_acc: 0.9919\n",
      "Epoch 49/3000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.0524 - acc: 0.9906 - val_loss: 0.0872 - val_acc: 0.9919\n",
      "Epoch 50/3000\n",
      "742/742 [==============================] - 0s 117us/step - loss: 0.0512 - acc: 0.9933 - val_loss: 0.0809 - val_acc: 0.9919\n",
      "Epoch 51/3000\n",
      "742/742 [==============================] - 0s 112us/step - loss: 0.0492 - acc: 0.9919 - val_loss: 0.0811 - val_acc: 0.9919\n",
      "Epoch 52/3000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 0.0480 - acc: 0.9919 - val_loss: 0.0795 - val_acc: 0.9919\n",
      "Epoch 53/3000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.0465 - acc: 0.9919 - val_loss: 0.0783 - val_acc: 0.9919\n",
      "Epoch 54/3000\n",
      "742/742 [==============================] - 0s 113us/step - loss: 0.0454 - acc: 0.9919 - val_loss: 0.0779 - val_acc: 0.9919\n",
      "Epoch 55/3000\n",
      "742/742 [==============================] - 0s 98us/step - loss: 0.0440 - acc: 0.9933 - val_loss: 0.0767 - val_acc: 0.9919\n",
      "Epoch 56/3000\n",
      "742/742 [==============================] - 0s 63us/step - loss: 0.0433 - acc: 0.9919 - val_loss: 0.0760 - val_acc: 0.9919\n",
      "Epoch 57/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 0.0421 - acc: 0.9933 - val_loss: 0.0756 - val_acc: 0.9919\n",
      "Epoch 58/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.0412 - acc: 0.9919 - val_loss: 0.0753 - val_acc: 0.9919\n",
      "Epoch 59/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0399 - acc: 0.9933 - val_loss: 0.0743 - val_acc: 0.9919\n",
      "Epoch 60/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0390 - acc: 0.9933 - val_loss: 0.0745 - val_acc: 0.9919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 0.0379 - acc: 0.9933 - val_loss: 0.0732 - val_acc: 0.9919\n",
      "Epoch 62/3000\n",
      "742/742 [==============================] - 0s 97us/step - loss: 0.0371 - acc: 0.9933 - val_loss: 0.0744 - val_acc: 0.9919\n",
      "Epoch 63/3000\n",
      "742/742 [==============================] - 0s 112us/step - loss: 0.0365 - acc: 0.9933 - val_loss: 0.0728 - val_acc: 0.9919\n",
      "Epoch 64/3000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 0.0358 - acc: 0.9933 - val_loss: 0.0722 - val_acc: 0.9919\n",
      "Epoch 65/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.0347 - acc: 0.9933 - val_loss: 0.0715 - val_acc: 0.9919\n",
      "Epoch 66/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.0340 - acc: 0.9933 - val_loss: 0.0717 - val_acc: 0.9919\n",
      "Epoch 67/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.0331 - acc: 0.9933 - val_loss: 0.0710 - val_acc: 0.9919\n",
      "Epoch 68/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0324 - acc: 0.9933 - val_loss: 0.0706 - val_acc: 0.9919\n",
      "Epoch 69/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 0.0316 - acc: 0.9933 - val_loss: 0.0702 - val_acc: 0.9919\n",
      "Epoch 70/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0309 - acc: 0.9933 - val_loss: 0.0707 - val_acc: 0.9919\n",
      "Epoch 71/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0303 - acc: 0.9933 - val_loss: 0.0702 - val_acc: 0.9919\n",
      "Epoch 72/3000\n",
      "742/742 [==============================] - 0s 102us/step - loss: 0.0297 - acc: 0.9933 - val_loss: 0.0698 - val_acc: 0.9919\n",
      "Epoch 73/3000\n",
      "742/742 [==============================] - 0s 104us/step - loss: 0.0291 - acc: 0.9933 - val_loss: 0.0697 - val_acc: 0.9919\n",
      "Epoch 74/3000\n",
      "742/742 [==============================] - 0s 93us/step - loss: 0.0284 - acc: 0.9933 - val_loss: 0.0696 - val_acc: 0.9919\n",
      "Epoch 75/3000\n",
      "742/742 [==============================] - 0s 104us/step - loss: 0.0280 - acc: 0.9933 - val_loss: 0.0694 - val_acc: 0.9919\n",
      "Epoch 76/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 0.0274 - acc: 0.9933 - val_loss: 0.0689 - val_acc: 0.9919\n",
      "Epoch 77/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 0.0270 - acc: 0.9933 - val_loss: 0.0693 - val_acc: 0.9919\n",
      "Epoch 78/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0263 - acc: 0.9933 - val_loss: 0.0690 - val_acc: 0.9919\n",
      "Epoch 79/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 0.0259 - acc: 0.9933 - val_loss: 0.0687 - val_acc: 0.9919\n",
      "Epoch 80/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0254 - acc: 0.9946 - val_loss: 0.0688 - val_acc: 0.9919\n",
      "Epoch 81/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0249 - acc: 0.9946 - val_loss: 0.0685 - val_acc: 0.9919\n",
      "Epoch 82/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0244 - acc: 0.9933 - val_loss: 0.0684 - val_acc: 0.9919\n",
      "Epoch 83/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0241 - acc: 0.9946 - val_loss: 0.0687 - val_acc: 0.9919\n",
      "Epoch 84/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0235 - acc: 0.9946 - val_loss: 0.0688 - val_acc: 0.9919\n",
      "Epoch 85/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 0.0230 - acc: 0.9946 - val_loss: 0.0679 - val_acc: 0.9919\n",
      "Epoch 86/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0227 - acc: 0.9946 - val_loss: 0.0678 - val_acc: 0.9919\n",
      "Epoch 87/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0223 - acc: 0.9946 - val_loss: 0.0677 - val_acc: 0.9919\n",
      "Epoch 88/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 0.0219 - acc: 0.9946 - val_loss: 0.0678 - val_acc: 0.9919\n",
      "Epoch 89/3000\n",
      "742/742 [==============================] - 0s 100us/step - loss: 0.0214 - acc: 0.9946 - val_loss: 0.0693 - val_acc: 0.9919\n",
      "Epoch 90/3000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.0213 - acc: 0.9946 - val_loss: 0.0677 - val_acc: 0.9919\n",
      "Epoch 91/3000\n",
      "742/742 [==============================] - 0s 100us/step - loss: 0.0207 - acc: 0.9946 - val_loss: 0.0678 - val_acc: 0.9919\n",
      "Epoch 92/3000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.0203 - acc: 0.9946 - val_loss: 0.0677 - val_acc: 0.9919\n",
      "Epoch 93/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.0200 - acc: 0.9946 - val_loss: 0.0675 - val_acc: 0.9919\n",
      "Epoch 94/3000\n",
      "742/742 [==============================] - 0s 100us/step - loss: 0.0196 - acc: 0.9946 - val_loss: 0.0674 - val_acc: 0.9919\n",
      "Epoch 95/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 0.0194 - acc: 0.9946 - val_loss: 0.0674 - val_acc: 0.9919\n",
      "Epoch 96/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 0.0190 - acc: 0.9946 - val_loss: 0.0675 - val_acc: 0.9919\n",
      "Epoch 97/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.0187 - acc: 0.9946 - val_loss: 0.0675 - val_acc: 0.9919\n",
      "Epoch 98/3000\n",
      "742/742 [==============================] - 0s 102us/step - loss: 0.0184 - acc: 0.9946 - val_loss: 0.0676 - val_acc: 0.9919\n",
      "Epoch 99/3000\n",
      "742/742 [==============================] - 0s 105us/step - loss: 0.0181 - acc: 0.9946 - val_loss: 0.0675 - val_acc: 0.9919\n",
      "Epoch 100/3000\n",
      "742/742 [==============================] - 0s 97us/step - loss: 0.0178 - acc: 0.9960 - val_loss: 0.0675 - val_acc: 0.9919\n",
      "Epoch 101/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 0.0175 - acc: 0.9973 - val_loss: 0.0675 - val_acc: 0.9919\n",
      "Epoch 102/3000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.0172 - acc: 0.9960 - val_loss: 0.0675 - val_acc: 0.9919\n",
      "Epoch 103/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 0.0170 - acc: 0.9960 - val_loss: 0.0676 - val_acc: 0.9919\n",
      "Epoch 104/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.0168 - acc: 0.9973 - val_loss: 0.0676 - val_acc: 0.9919\n",
      "Epoch 105/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.0165 - acc: 0.9946 - val_loss: 0.0677 - val_acc: 0.9919\n",
      "Epoch 106/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 0.0163 - acc: 0.9973 - val_loss: 0.0675 - val_acc: 0.9919\n",
      "Epoch 107/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 0.0159 - acc: 0.9973 - val_loss: 0.0675 - val_acc: 0.9919\n",
      "Epoch 108/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0157 - acc: 0.9973 - val_loss: 0.0674 - val_acc: 0.9919\n",
      "Epoch 109/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 0.0155 - acc: 0.9973 - val_loss: 0.0676 - val_acc: 0.9919\n",
      "Epoch 110/3000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 0.0152 - acc: 0.9973 - val_loss: 0.0676 - val_acc: 0.9919\n",
      "Epoch 111/3000\n",
      "742/742 [==============================] - 0s 98us/step - loss: 0.0150 - acc: 0.9973 - val_loss: 0.0675 - val_acc: 0.9919\n",
      "Epoch 112/3000\n",
      "742/742 [==============================] - 0s 102us/step - loss: 0.0148 - acc: 0.9973 - val_loss: 0.0675 - val_acc: 0.9919\n",
      "Epoch 113/3000\n",
      "742/742 [==============================] - 0s 98us/step - loss: 0.0145 - acc: 0.9973 - val_loss: 0.0677 - val_acc: 0.9919\n",
      "Epoch 114/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0143 - acc: 0.9973 - val_loss: 0.0678 - val_acc: 0.9919\n",
      "Epoch 115/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0141 - acc: 0.9973 - val_loss: 0.0678 - val_acc: 0.9919\n",
      "Epoch 116/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0139 - acc: 0.9973 - val_loss: 0.0678 - val_acc: 0.9919\n",
      "Epoch 117/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0137 - acc: 0.9973 - val_loss: 0.0678 - val_acc: 0.9919\n",
      "Epoch 118/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 0.0135 - acc: 0.9973 - val_loss: 0.0677 - val_acc: 0.9919\n",
      "Epoch 119/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0133 - acc: 0.9973 - val_loss: 0.0678 - val_acc: 0.9919\n",
      "Epoch 120/3000\n",
      "742/742 [==============================] - 0s 85us/step - loss: 0.0133 - acc: 0.9973 - val_loss: 0.0680 - val_acc: 0.9919\n",
      "Epoch 121/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 77us/step - loss: 0.0129 - acc: 0.9973 - val_loss: 0.0679 - val_acc: 0.9919\n",
      "Epoch 122/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0128 - acc: 0.9973 - val_loss: 0.0679 - val_acc: 0.9919\n",
      "Epoch 123/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.0126 - acc: 0.9973 - val_loss: 0.0680 - val_acc: 0.9919\n",
      "Epoch 124/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0125 - acc: 0.9973 - val_loss: 0.0681 - val_acc: 0.9919\n",
      "Epoch 125/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0123 - acc: 0.9973 - val_loss: 0.0683 - val_acc: 0.9919\n",
      "Epoch 126/3000\n",
      "742/742 [==============================] - 0s 65us/step - loss: 0.0121 - acc: 0.9973 - val_loss: 0.0695 - val_acc: 0.9919\n",
      "Epoch 127/3000\n",
      "742/742 [==============================] - 0s 67us/step - loss: 0.0121 - acc: 0.9973 - val_loss: 0.0687 - val_acc: 0.9919\n",
      "Epoch 128/3000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.0117 - acc: 0.9973 - val_loss: 0.0686 - val_acc: 0.9919\n",
      "Epoch 00128: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping  \n",
    "from decimal import ROUND_UP\n",
    "from keras import optimizers\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "rmsp=optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "adagrad=optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
    "adad=optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "adam=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "adamax=optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "nadam=optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "from keras.callbacks import EarlyStopping  \n",
    "from decimal import ROUND_UP\n",
    "max_features = X_train.shape[1]\n",
    "m = Sequential()\n",
    "m.add(Dense(39, input_shape=(dims,)))\n",
    "m.add(Activation('elu'))\n",
    "m.add(Dense(25))\n",
    "m.add(Activation('relu'))\n",
    "m.add(Dense(10))\n",
    "m.add(Activation('softmax'))\n",
    "#m.add(Round())\n",
    "m.compile(loss='categorical_crossentropy', optimizer=adagrad,metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1, mode='auto')\n",
    "hist4=m.fit(X_train_scaled,\n",
    "          Y_train,\n",
    "          batch_size=32,\n",
    "          epochs=3000, verbose=1,\n",
    "          validation_data=(X_test_scaled, Y_test),\n",
    "          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 742 samples, validate on 248 samples\n",
      "Epoch 1/3000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 1.8787 - acc: 0.4744 - val_loss: 1.5170 - val_acc: 0.5242\n",
      "Epoch 2/3000\n",
      "742/742 [==============================] - 0s 99us/step - loss: 1.3909 - acc: 0.4757 - val_loss: 1.1721 - val_acc: 0.5242\n",
      "Epoch 3/3000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 1.1455 - acc: 0.4771 - val_loss: 1.0133 - val_acc: 0.5242\n",
      "Epoch 4/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 1.0142 - acc: 0.4987 - val_loss: 0.9179 - val_acc: 0.5524\n",
      "Epoch 5/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 0.9296 - acc: 0.5889 - val_loss: 0.8492 - val_acc: 0.7298\n",
      "Epoch 6/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 0.8619 - acc: 0.8086 - val_loss: 0.7939 - val_acc: 0.8508\n",
      "Epoch 7/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 0.8018 - acc: 0.8464 - val_loss: 0.7369 - val_acc: 0.8790\n",
      "Epoch 8/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 0.7432 - acc: 0.8666 - val_loss: 0.6824 - val_acc: 0.8871\n",
      "Epoch 9/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 0.6850 - acc: 0.8693 - val_loss: 0.6285 - val_acc: 0.8871\n",
      "Epoch 10/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 0.6308 - acc: 0.8679 - val_loss: 0.5806 - val_acc: 0.8871\n",
      "Epoch 11/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 0.5813 - acc: 0.8693 - val_loss: 0.5349 - val_acc: 0.8871\n",
      "Epoch 12/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.5378 - acc: 0.8693 - val_loss: 0.4979 - val_acc: 0.8871\n",
      "Epoch 13/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 0.5001 - acc: 0.8693 - val_loss: 0.4632 - val_acc: 0.8871\n",
      "Epoch 14/3000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.4674 - acc: 0.8706 - val_loss: 0.4367 - val_acc: 0.8911\n",
      "Epoch 15/3000\n",
      "742/742 [==============================] - 0s 117us/step - loss: 0.4401 - acc: 0.8706 - val_loss: 0.4125 - val_acc: 0.8911\n",
      "Epoch 16/3000\n",
      "742/742 [==============================] - 0s 116us/step - loss: 0.4165 - acc: 0.8706 - val_loss: 0.3908 - val_acc: 0.8911\n",
      "Epoch 17/3000\n",
      "742/742 [==============================] - 0s 113us/step - loss: 0.3960 - acc: 0.8774 - val_loss: 0.3683 - val_acc: 0.8911\n",
      "Epoch 18/3000\n",
      "742/742 [==============================] - 0s 124us/step - loss: 0.3736 - acc: 0.8760 - val_loss: 0.3614 - val_acc: 0.8911\n",
      "Epoch 19/3000\n",
      "742/742 [==============================] - 0s 100us/step - loss: 0.3604 - acc: 0.8774 - val_loss: 0.3478 - val_acc: 0.8911\n",
      "Epoch 20/3000\n",
      "742/742 [==============================] - 0s 105us/step - loss: 0.3487 - acc: 0.8774 - val_loss: 0.3371 - val_acc: 0.8911\n",
      "Epoch 21/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 0.3383 - acc: 0.8827 - val_loss: 0.3308 - val_acc: 0.8992\n",
      "Epoch 22/3000\n",
      "742/742 [==============================] - 0s 100us/step - loss: 0.3282 - acc: 0.8801 - val_loss: 0.3184 - val_acc: 0.8911\n",
      "Epoch 23/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 0.3182 - acc: 0.8801 - val_loss: 0.3094 - val_acc: 0.8952\n",
      "Epoch 24/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 0.3090 - acc: 0.8841 - val_loss: 0.3022 - val_acc: 0.9073\n",
      "Epoch 25/3000\n",
      "742/742 [==============================] - 0s 85us/step - loss: 0.3010 - acc: 0.8976 - val_loss: 0.2943 - val_acc: 0.9113\n",
      "Epoch 26/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.2912 - acc: 0.8908 - val_loss: 0.2836 - val_acc: 0.9113\n",
      "Epoch 27/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 0.2819 - acc: 0.8962 - val_loss: 0.2776 - val_acc: 0.9274\n",
      "Epoch 28/3000\n",
      "742/742 [==============================] - 0s 98us/step - loss: 0.2737 - acc: 0.9097 - val_loss: 0.2703 - val_acc: 0.9274\n",
      "Epoch 29/3000\n",
      "742/742 [==============================] - 0s 106us/step - loss: 0.2659 - acc: 0.9016 - val_loss: 0.2612 - val_acc: 0.9274\n",
      "Epoch 30/3000\n",
      "742/742 [==============================] - 0s 94us/step - loss: 0.2575 - acc: 0.9191 - val_loss: 0.2538 - val_acc: 0.9274\n",
      "Epoch 31/3000\n",
      "742/742 [==============================] - 0s 110us/step - loss: 0.2483 - acc: 0.9111 - val_loss: 0.2433 - val_acc: 0.9274\n",
      "Epoch 32/3000\n",
      "742/742 [==============================] - 0s 100us/step - loss: 0.2406 - acc: 0.9191 - val_loss: 0.2388 - val_acc: 0.9315\n",
      "Epoch 33/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 0.2312 - acc: 0.9205 - val_loss: 0.2279 - val_acc: 0.9274\n",
      "Epoch 34/3000\n",
      "742/742 [==============================] - ETA: 0s - loss: 0.2748 - acc: 0.937 - 0s 81us/step - loss: 0.2242 - acc: 0.9137 - val_loss: 0.2200 - val_acc: 0.9274\n",
      "Epoch 35/3000\n",
      "742/742 [==============================] - 0s 85us/step - loss: 0.2164 - acc: 0.9299 - val_loss: 0.2148 - val_acc: 0.9315\n",
      "Epoch 36/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 0.2070 - acc: 0.9245 - val_loss: 0.2055 - val_acc: 0.9315\n",
      "Epoch 37/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 0.1993 - acc: 0.9232 - val_loss: 0.1975 - val_acc: 0.9315\n",
      "Epoch 38/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 0.1908 - acc: 0.9272 - val_loss: 0.1918 - val_acc: 0.9315\n",
      "Epoch 39/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.1824 - acc: 0.9367 - val_loss: 0.1812 - val_acc: 0.9315\n",
      "Epoch 40/3000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 0.1750 - acc: 0.9326 - val_loss: 0.1740 - val_acc: 0.9315\n",
      "Epoch 41/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.1673 - acc: 0.9380 - val_loss: 0.1662 - val_acc: 0.9355\n",
      "Epoch 42/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 0.1599 - acc: 0.9353 - val_loss: 0.1596 - val_acc: 0.9476\n",
      "Epoch 43/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.1525 - acc: 0.9501 - val_loss: 0.1527 - val_acc: 0.9516\n",
      "Epoch 44/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.1455 - acc: 0.9461 - val_loss: 0.1450 - val_acc: 0.9637\n",
      "Epoch 45/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 0.1383 - acc: 0.9461 - val_loss: 0.1380 - val_acc: 0.9798\n",
      "Epoch 46/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 0.1311 - acc: 0.9784 - val_loss: 0.1312 - val_acc: 0.9839\n",
      "Epoch 47/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 0.1239 - acc: 0.9757 - val_loss: 0.1237 - val_acc: 0.9798\n",
      "Epoch 48/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 0.1174 - acc: 0.9811 - val_loss: 0.1166 - val_acc: 0.9798\n",
      "Epoch 49/3000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 0.1108 - acc: 0.9825 - val_loss: 0.1101 - val_acc: 0.9879\n",
      "Epoch 50/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.1048 - acc: 0.9852 - val_loss: 0.1041 - val_acc: 0.9879\n",
      "Epoch 51/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0984 - acc: 0.9852 - val_loss: 0.0980 - val_acc: 0.9879\n",
      "Epoch 52/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0927 - acc: 0.9852 - val_loss: 0.0919 - val_acc: 0.9879\n",
      "Epoch 53/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.0870 - acc: 0.9865 - val_loss: 0.0865 - val_acc: 0.9879\n",
      "Epoch 54/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0817 - acc: 0.9879 - val_loss: 0.0818 - val_acc: 0.9919\n",
      "Epoch 55/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 0.0773 - acc: 0.9879 - val_loss: 0.0772 - val_acc: 0.9919\n",
      "Epoch 56/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 0.0724 - acc: 0.9919 - val_loss: 0.0713 - val_acc: 0.9919\n",
      "Epoch 57/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0676 - acc: 0.9906 - val_loss: 0.0669 - val_acc: 0.9919\n",
      "Epoch 58/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0633 - acc: 0.9919 - val_loss: 0.0629 - val_acc: 0.9919\n",
      "Epoch 59/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0594 - acc: 0.9946 - val_loss: 0.0590 - val_acc: 0.9960\n",
      "Epoch 60/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.0563 - acc: 0.9906 - val_loss: 0.0564 - val_acc: 0.9960\n",
      "Epoch 61/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0526 - acc: 0.9973 - val_loss: 0.0519 - val_acc: 0.9960\n",
      "Epoch 62/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0489 - acc: 0.9973 - val_loss: 0.0491 - val_acc: 0.9960\n",
      "Epoch 63/3000\n",
      "742/742 [==============================] - 0s 66us/step - loss: 0.0459 - acc: 0.9960 - val_loss: 0.0456 - val_acc: 0.9960\n",
      "Epoch 64/3000\n",
      "742/742 [==============================] - 0s 72us/step - loss: 0.0433 - acc: 0.9960 - val_loss: 0.0434 - val_acc: 0.9960\n",
      "Epoch 65/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0407 - acc: 0.9987 - val_loss: 0.0406 - val_acc: 0.9960\n",
      "Epoch 66/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0383 - acc: 0.9987 - val_loss: 0.0378 - val_acc: 0.9960\n",
      "Epoch 67/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0360 - acc: 0.9987 - val_loss: 0.0364 - val_acc: 0.9960\n",
      "Epoch 68/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 0.0338 - acc: 0.9987 - val_loss: 0.0337 - val_acc: 0.9960\n",
      "Epoch 69/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0318 - acc: 0.9987 - val_loss: 0.0320 - val_acc: 0.9960\n",
      "Epoch 70/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0299 - acc: 0.9987 - val_loss: 0.0298 - val_acc: 0.9960\n",
      "Epoch 71/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0281 - acc: 0.9987 - val_loss: 0.0281 - val_acc: 0.9960\n",
      "Epoch 72/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 0.0264 - acc: 0.9987 - val_loss: 0.0267 - val_acc: 0.9960\n",
      "Epoch 73/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0252 - acc: 0.9987 - val_loss: 0.0251 - val_acc: 0.9960\n",
      "Epoch 74/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0235 - acc: 0.9987 - val_loss: 0.0238 - val_acc: 0.9960\n",
      "Epoch 75/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0222 - acc: 1.0000 - val_loss: 0.0225 - val_acc: 1.0000\n",
      "Epoch 76/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 0.0210 - acc: 0.9987 - val_loss: 0.0215 - val_acc: 1.0000\n",
      "Epoch 77/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0199 - acc: 1.0000 - val_loss: 0.0201 - val_acc: 0.9960\n",
      "Epoch 78/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0187 - acc: 1.0000 - val_loss: 0.0191 - val_acc: 1.0000\n",
      "Epoch 79/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0178 - acc: 1.0000 - val_loss: 0.0183 - val_acc: 1.0000\n",
      "Epoch 80/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.0168 - acc: 1.0000 - val_loss: 0.0171 - val_acc: 1.0000\n",
      "Epoch 81/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0159 - acc: 1.0000 - val_loss: 0.0164 - val_acc: 1.0000\n",
      "Epoch 82/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.0156 - val_acc: 1.0000\n",
      "Epoch 83/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 0.0151 - val_acc: 1.0000\n",
      "Epoch 84/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.0139 - val_acc: 1.0000\n",
      "Epoch 85/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 0.0135 - val_acc: 1.0000\n",
      "Epoch 86/3000\n",
      "742/742 [==============================] - 0s 90us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 1.0000\n",
      "Epoch 87/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.0123 - val_acc: 1.0000\n",
      "Epoch 88/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.0118 - val_acc: 1.0000\n",
      "Epoch 89/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 1.0000\n",
      "Epoch 90/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 1.0000\n",
      "Epoch 91/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 92/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 1.0000\n",
      "Epoch 93/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 1.0000\n",
      "Epoch 94/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 1.0000\n",
      "Epoch 95/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 1.0000\n",
      "Epoch 96/3000\n",
      "742/742 [==============================] - 0s 86us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 1.0000\n",
      "Epoch 97/3000\n",
      "742/742 [==============================] - 0s 106us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 1.0000\n",
      "Epoch 98/3000\n",
      "742/742 [==============================] - 0s 97us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 1.0000\n",
      "Epoch 99/3000\n",
      "742/742 [==============================] - 0s 108us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 1.0000\n",
      "Epoch 100/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 0.9960\n",
      "Epoch 101/3000\n",
      "742/742 [==============================] - 0s 102us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0093 - val_acc: 0.9960\n",
      "Epoch 102/3000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 0.9960\n",
      "Epoch 103/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 0.9960\n",
      "Epoch 104/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 0.9960\n",
      "Epoch 105/3000\n",
      "742/742 [==============================] - 0s 73us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 0.9960\n",
      "Epoch 106/3000\n",
      "742/742 [==============================] - 0s 104us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 0.9960\n",
      "Epoch 107/3000\n",
      "742/742 [==============================] - 0s 106us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 0.9960\n",
      "Epoch 108/3000\n",
      "742/742 [==============================] - 0s 106us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 0.9960\n",
      "Epoch 109/3000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 0.9960\n",
      "Epoch 110/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 0.9960\n",
      "Epoch 111/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 0.9960\n",
      "Epoch 112/3000\n",
      "742/742 [==============================] - 0s 88us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 0.9960\n",
      "Epoch 113/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 0.9960\n",
      "Epoch 114/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 0.9960\n",
      "Epoch 115/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 0.9960\n",
      "Epoch 116/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0101 - val_acc: 0.9960\n",
      "Epoch 117/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 0.9960\n",
      "Epoch 118/3000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 0.9960\n",
      "Epoch 119/3000\n",
      "742/742 [==============================] - 0s 77us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 0.9960\n",
      "Epoch 120/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 73us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0111 - val_acc: 0.9960\n",
      "Epoch 121/3000\n",
      "742/742 [==============================] - 0s 78us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0109 - val_acc: 0.9960\n",
      "Epoch 122/3000\n",
      "742/742 [==============================] - 0s 131us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 0.9960\n",
      "Epoch 123/3000\n",
      "742/742 [==============================] - 0s 166us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 0.9960\n",
      "Epoch 00123: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping  \n",
    "from decimal import ROUND_UP\n",
    "from keras import optimizers\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "rmsp=optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "adagrad=optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
    "adad=optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "adam=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "adamax=optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "nadam=optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "from keras.callbacks import EarlyStopping  \n",
    "from decimal import ROUND_UP\n",
    "max_features = X_train.shape[1]\n",
    "m = Sequential()\n",
    "m.add(Dense(39, input_shape=(dims,)))\n",
    "m.add(Activation('elu'))\n",
    "m.add(Dense(25))\n",
    "m.add(Activation('relu'))\n",
    "m.add(Dense(10))\n",
    "m.add(Activation('softmax'))\n",
    "#m.add(Round())\n",
    "m.compile(loss='categorical_crossentropy', optimizer=adamax,metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1, mode='auto')\n",
    "hist5=m.fit(X_train_scaled,\n",
    "          Y_train,\n",
    "          batch_size=32,\n",
    "          epochs=3000, verbose=1,\n",
    "          validation_data=(X_test_scaled, Y_test),\n",
    "          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 742 samples, validate on 248 samples\n",
      "Epoch 1/3000\n",
      "742/742 [==============================] - 1s 1ms/step - loss: 2.0033 - acc: 0.4744 - val_loss: 1.6557 - val_acc: 0.5242\n",
      "Epoch 2/3000\n",
      "742/742 [==============================] - 0s 107us/step - loss: 1.3920 - acc: 0.4987 - val_loss: 1.0228 - val_acc: 0.5766\n",
      "Epoch 3/3000\n",
      "742/742 [==============================] - 0s 92us/step - loss: 0.8698 - acc: 0.8261 - val_loss: 0.6335 - val_acc: 0.8831\n",
      "Epoch 4/3000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.5345 - acc: 0.8598 - val_loss: 0.4856 - val_acc: 0.9073\n",
      "Epoch 5/3000\n",
      "742/742 [==============================] - 0s 85us/step - loss: 0.3935 - acc: 0.8639 - val_loss: 0.3597 - val_acc: 0.9032\n",
      "Epoch 6/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 0.3091 - acc: 0.8881 - val_loss: 0.2728 - val_acc: 0.8831\n",
      "Epoch 7/3000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.2417 - acc: 0.9030 - val_loss: 0.2174 - val_acc: 0.8952\n",
      "Epoch 8/3000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.1817 - acc: 0.9501 - val_loss: 0.1665 - val_acc: 0.9839\n",
      "Epoch 9/3000\n",
      "742/742 [==============================] - 0s 89us/step - loss: 0.1350 - acc: 0.9744 - val_loss: 0.1279 - val_acc: 0.9919\n",
      "Epoch 10/3000\n",
      "742/742 [==============================] - 0s 98us/step - loss: 0.1040 - acc: 0.9798 - val_loss: 0.1450 - val_acc: 0.9879\n",
      "Epoch 11/3000\n",
      "742/742 [==============================] - 0s 106us/step - loss: 0.0849 - acc: 0.9879 - val_loss: 0.0980 - val_acc: 0.9919\n",
      "Epoch 12/3000\n",
      "742/742 [==============================] - 0s 84us/step - loss: 0.0666 - acc: 0.9919 - val_loss: 0.0934 - val_acc: 0.9919\n",
      "Epoch 13/3000\n",
      "742/742 [==============================] - 0s 79us/step - loss: 0.0575 - acc: 0.9933 - val_loss: 0.0683 - val_acc: 0.9919\n",
      "Epoch 14/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 0.0474 - acc: 0.9933 - val_loss: 0.0633 - val_acc: 0.9919\n",
      "Epoch 15/3000\n",
      "742/742 [==============================] - 0s 85us/step - loss: 0.0413 - acc: 0.9933 - val_loss: 0.0603 - val_acc: 0.9919\n",
      "Epoch 16/3000\n",
      "742/742 [==============================] - 0s 116us/step - loss: 0.0354 - acc: 0.9933 - val_loss: 0.0575 - val_acc: 0.9919\n",
      "Epoch 17/3000\n",
      "742/742 [==============================] - 0s 125us/step - loss: 0.0306 - acc: 0.9933 - val_loss: 0.0565 - val_acc: 0.9919\n",
      "Epoch 18/3000\n",
      "742/742 [==============================] - 0s 120us/step - loss: 0.0265 - acc: 0.9946 - val_loss: 0.0623 - val_acc: 0.9919\n",
      "Epoch 19/3000\n",
      "742/742 [==============================] - 0s 113us/step - loss: 0.0239 - acc: 0.9960 - val_loss: 0.0575 - val_acc: 0.9919\n",
      "Epoch 20/3000\n",
      "742/742 [==============================] - 0s 115us/step - loss: 0.0211 - acc: 0.9973 - val_loss: 0.0555 - val_acc: 0.9919\n",
      "Epoch 21/3000\n",
      "742/742 [==============================] - 0s 136us/step - loss: 0.0190 - acc: 0.9973 - val_loss: 0.0547 - val_acc: 0.9919\n",
      "Epoch 22/3000\n",
      "742/742 [==============================] - 0s 81us/step - loss: 0.0169 - acc: 0.9973 - val_loss: 0.0555 - val_acc: 0.9919\n",
      "Epoch 23/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0153 - acc: 0.9973 - val_loss: 0.0561 - val_acc: 0.9919\n",
      "Epoch 24/3000\n",
      "742/742 [==============================] - 0s 48us/step - loss: 0.0138 - acc: 0.9973 - val_loss: 0.0579 - val_acc: 0.9919\n",
      "Epoch 25/3000\n",
      "742/742 [==============================] - 0s 87us/step - loss: 0.0127 - acc: 0.9973 - val_loss: 0.0562 - val_acc: 0.9919\n",
      "Epoch 26/3000\n",
      "742/742 [==============================] - 0s 85us/step - loss: 0.0114 - acc: 0.9973 - val_loss: 0.0563 - val_acc: 0.9919\n",
      "Epoch 27/3000\n",
      "742/742 [==============================] - 0s 82us/step - loss: 0.0102 - acc: 0.9973 - val_loss: 0.0566 - val_acc: 0.9919\n",
      "Epoch 28/3000\n",
      "742/742 [==============================] - 0s 71us/step - loss: 0.0095 - acc: 0.9973 - val_loss: 0.0567 - val_acc: 0.9919\n",
      "Epoch 29/3000\n",
      "742/742 [==============================] - 0s 70us/step - loss: 0.0087 - acc: 0.9973 - val_loss: 0.0573 - val_acc: 0.9919\n",
      "Epoch 30/3000\n",
      "742/742 [==============================] - 0s 69us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.0566 - val_acc: 0.9919\n",
      "Epoch 31/3000\n",
      "742/742 [==============================] - 0s 75us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0571 - val_acc: 0.9919\n",
      "Epoch 32/3000\n",
      "742/742 [==============================] - 0s 74us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0583 - val_acc: 0.9960\n",
      "Epoch 33/3000\n",
      "742/742 [==============================] - 0s 113us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0574 - val_acc: 0.9919\n",
      "Epoch 34/3000\n",
      "742/742 [==============================] - 0s 109us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0576 - val_acc: 0.9960\n",
      "Epoch 35/3000\n",
      "742/742 [==============================] - 0s 105us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0579 - val_acc: 0.9960\n",
      "Epoch 36/3000\n",
      "742/742 [==============================] - 0s 120us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0585 - val_acc: 0.9960\n",
      "Epoch 37/3000\n",
      "742/742 [==============================] - 0s 110us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0585 - val_acc: 0.9960\n",
      "Epoch 38/3000\n",
      "742/742 [==============================] - 0s 110us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0589 - val_acc: 0.9960\n",
      "Epoch 39/3000\n",
      "742/742 [==============================] - 0s 102us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0590 - val_acc: 0.9960\n",
      "Epoch 40/3000\n",
      "742/742 [==============================] - 0s 96us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0599 - val_acc: 0.9960\n",
      "Epoch 41/3000\n",
      "742/742 [==============================] - 0s 98us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0599 - val_acc: 0.9960\n",
      "Epoch 00041: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping  \n",
    "from decimal import ROUND_UP\n",
    "from keras import optimizers\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "rmsp=optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "adagrad=optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
    "adad=optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "adam=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "adamax=optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "nadam=optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "from keras.callbacks import EarlyStopping  \n",
    "from decimal import ROUND_UP\n",
    "max_features = X_train.shape[1]\n",
    "m = Sequential()\n",
    "m.add(Dense(39, input_shape=(dims,)))\n",
    "m.add(Activation('elu'))\n",
    "m.add(Dense(25))\n",
    "m.add(Activation('relu'))\n",
    "m.add(Dense(10))\n",
    "m.add(Activation('softmax'))\n",
    "#m.add(Round())\n",
    "m.compile(loss='categorical_crossentropy', optimizer=adad,metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1, mode='auto')\n",
    "hist6=m.fit(X_train_scaled,\n",
    "          Y_train,\n",
    "          batch_size=32,\n",
    "          epochs=3000, verbose=1,\n",
    "          validation_data=(X_test_scaled, Y_test),\n",
    "          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a3237f20b8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a321bfe898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist2.history['loss'])\n",
    "plt.plot(hist3.history['loss'])\n",
    "plt.plot(hist4.history['loss'])\n",
    "plt.plot(hist5.history['loss'])\n",
    "plt.plot(hist6.history['loss'])\n",
    "plt.savefig('loss with diff. optimizers.fig', format='eps', dpi=1000)\n",
    "plt.savefig('loss with diff. optimizers.eps', format='eps', dpi=1000)\n",
    "plt.legend(['adam','sgd','rmsp','adagrad','adamax','adad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEBGRuP8HMFhgQkN3zUMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a323454748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation Loss')\n",
    "#plt.plot(hist1.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "#plt.plot(hist2.history['loss'])\n",
    "plt.plot(hist2.history['val_loss'])\n",
    "#plt.plot(hist3.history['loss'])\n",
    "plt.plot(hist3.history['val_loss'])\n",
    "#plt.plot(hist4.history['loss'])\n",
    "plt.plot(hist4.history['val_loss'])\n",
    "#plt.plot(hist5.history['loss'])\n",
    "plt.plot(hist5.history['val_loss'])\n",
    "#plt.plot(hist6.history['loss'])\n",
    "plt.plot(hist6.history['val_loss'])\n",
    "plt.legend(['adam','sgd','rmsp','adagrad','adamax','adad'])\n",
    "plt.savefig('Validation loss with diff. optimizers.fig', format='eps', dpi=1000)\n",
    "plt.savefig('Validation loss with diff. optimizers.eps', format='eps', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a323432470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.plot(hist1.history['acc'])\n",
    "#plt.plot(hist1.history['val_loss'])\n",
    "plt.plot(hist2.history['acc'])\n",
    "#plt.plot(hist2.history['val_loss'])\n",
    "plt.plot(hist3.history['acc'])\n",
    "#plt.plot(hist3.history['val_loss'])\n",
    "plt.plot(hist4.history['acc'])\n",
    "#plt.plot(hist4.history['val_loss'])\n",
    "plt.plot(hist5.history['acc'])\n",
    "#plt.plot(hist5.history['val_loss'])\n",
    "plt.plot(hist6.history['acc'])\n",
    "#plt.plot(hist6.history['val_loss'])\n",
    "plt.legend(['adam','sgd','rmsp','adagrad','adamax','adad'])\n",
    "plt.savefig('training accuracy with diff. optimizers.fig', format='eps', dpi=1000)\n",
    "plt.savefig('training accuracy with diff. optimizers.eps', format='eps', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a32387c5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.plot(hist1.history['val_acc'])\n",
    "plt.plot(hist2.history['val_acc'])\n",
    "plt.plot(hist3.history['val_acc'])\n",
    "plt.plot(hist4.history['val_acc'])\n",
    "plt.plot(hist5.history['val_acc'])\n",
    "plt.legend(['adam','sgd','rmsp','adagrad','adamax','adad'])\n",
    "plt.savefig('validation accuracy with diff. optimizers.fig', format='eps', dpi=1000)\n",
    "plt.savefig('validation accuracy with diff. optimizers.eps', format='eps', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
